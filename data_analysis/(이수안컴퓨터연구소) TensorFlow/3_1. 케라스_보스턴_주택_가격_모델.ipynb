{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gj-RA7rQLSC4"
      },
      "source": [
        "# 케라스 보스턴 주택 가격 모델"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1rSC60ILf0U"
      },
      "source": [
        "### modules import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "bmYcVLNsmFR_"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf \n",
        "from tensorflow.keras.datasets.boston_housing import load_data\n",
        "from tensorflow.keras.layers import Dense \n",
        "from tensorflow.keras.models import Sequential \n",
        "from tensorflow.keras.optimizers import Adam \n",
        "from tensorflow.keras.utils import plot_model \n",
        "\n",
        "from sklearn.model_selection import train_test_split \n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt \n",
        "plt.style.use('seaborn-white')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbRqQY1aMMTU"
      },
      "source": [
        "### 데이터 로드\n",
        "- 데이터의 수가 상당히 적기 때문에 테스트 데이터의 비율을 20%로 지정\n",
        "\n",
        "- 13개의 특성을 가짐\n",
        "\n",
        "- 각각의 특성이 모두 다른 스케일, 즉 단위가 모두 다름\n",
        "  - 범죄율: 0~1 사이의 값\n",
        "  - 방의 개수 3~9 사이의 값\n",
        "\n",
        "- 정답 레이블은 주택 가격의 중간가격($1000 단위)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "AWHBrPVTMGyu"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/boston_housing.npz\n",
            "57026/57026 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "tf.random.set_seed(111)\n",
        "\n",
        "(x_train_full, y_train_full), (x_test, y_test) = load_data(path='boston_housing.npz',\n",
        "                                                           test_split=0.2,\n",
        "                                                           seed=111)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCTcnMT6Mgx9"
      },
      "source": [
        "### 데이터 확인"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "MdisxCBbMbRh"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "학습 데이터: (404, 13)\t레이블: (404,)\n",
            "테스트 데이터: (102, 13)\t레이블: (102,)\n"
          ]
        }
      ],
      "source": [
        "print('학습 데이터: {}\\t레이블: {}'.format(x_train_full.shape, y_train_full.shape))\n",
        "print('테스트 데이터: {}\\t레이블: {}'.format(x_test.shape, y_test.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "vjEoDJ6fM4I-"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2.8750e-02 2.8000e+01 1.5040e+01 0.0000e+00 4.6400e-01 6.2110e+00\n",
            " 2.8900e+01 3.6659e+00 4.0000e+00 2.7000e+02 1.8200e+01 3.9633e+02\n",
            " 6.2100e+00]\n"
          ]
        }
      ],
      "source": [
        "print(x_train_full[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "U-V0pQdbNSso"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "25.0\n"
          ]
        }
      ],
      "source": [
        "print(y_train_full[0])  # $25.0 ---> $25,000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_ZK_dJdOlCu"
      },
      "source": [
        "### 데이터 전처리\n",
        "- Standardization\n",
        "\n",
        "- 특성의 단위가 모두 다르기 때문에 **동일한 범위로 조정**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "DjRcDM_CNV--"
      },
      "outputs": [],
      "source": [
        "mean = np.mean(x_train_full, axis=0)\n",
        "std = np.std(x_train_full,axis=0)\n",
        "\n",
        "x_train_preprocessed = (x_train_full - mean) /std\n",
        "x_test = (x_test - mean) / std \n",
        "\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train_preprocessed, y_train_full,\n",
        "                                                  test_size=0.3,\n",
        "                                                  random_state=111)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "M1fl37t9PR0G"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "학습 데이터: (404, 13)\t레이블: (404,)\n",
            "학습 데이터: (282, 13)\t레이블: (282,)\n",
            "검증 데이터: (122, 13)\t레이블: (122,)\n",
            "테스트 데이터: (102, 13)\t레이블: (102,)\n"
          ]
        }
      ],
      "source": [
        "print('학습 데이터: {}\\t레이블: {}'.format(x_train_full.shape, y_train_full.shape))\n",
        "print('학습 데이터: {}\\t레이블: {}'.format(x_train.shape, y_train.shape))\n",
        "print('검증 데이터: {}\\t레이블: {}'.format(x_val.shape, y_val.shape))\n",
        "print('테스트 데이터: {}\\t레이블: {}'.format(x_test.shape, y_test.shape))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTcwvMqdPynu"
      },
      "source": [
        "### 모델 구성\n",
        "- 학습 데이터가 매우 적은 경우에 모델의 깊이를 깊게 할수록  \n",
        "  과대적합(Overfitting)이 일어날 확률이 높음"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "1P7pAnqUPcCf"
      },
      "outputs": [],
      "source": [
        "model = Sequential([Dense(100, activation='relu', input_shape=(13, ), name='Dense1'),\n",
        "                    Dense(64, activation='relu', name='Dense2'),\n",
        "                    Dense(32, activation='relu', name='Dense3'),\n",
        "                    Dense(1, name='output')])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "dRi6Vd8WQYyj"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Dense1 (Dense)              (None, 100)               1400      \n",
            "                                                                 \n",
            " Dense2 (Dense)              (None, 64)                6464      \n",
            "                                                                 \n",
            " Dense3 (Dense)              (None, 32)                2080      \n",
            "                                                                 \n",
            " output (Dense)              (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9,977\n",
            "Trainable params: 9,977\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "M-dFvQRGQalM"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
          ]
        }
      ],
      "source": [
        "plot_model(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0m05yRQmQmFA"
      },
      "source": [
        "### 모델 컴파일(compile)\n",
        "\n",
        "- 회귀 문제에서는 주로 평균제곱오차(MSE, Mean Squared Error)를 손실함수로,  \n",
        "  평균절대오차(MAE, Mean Absolute Error)를 평가지표로 많이 사용!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "_Z2IMfH3QkGv"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='mse',\n",
        "              optimizer=Adam(learning_rate=1e-2),\n",
        "              metrics=['mae'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6YhN4fzmRQpY"
      },
      "source": [
        "### 모델 학습"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "jGA9gPIERPxF"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "9/9 [==============================] - 1s 20ms/step - loss: 415.9695 - mae: 18.2318 - val_loss: 94.9696 - val_mae: 8.0243\n",
            "Epoch 2/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 84.8042 - mae: 6.8105 - val_loss: 65.1927 - val_mae: 6.6496\n",
            "Epoch 3/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 46.5302 - mae: 5.2406 - val_loss: 38.7048 - val_mae: 4.7977\n",
            "Epoch 4/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 28.6627 - mae: 4.0903 - val_loss: 26.2360 - val_mae: 3.7657\n",
            "Epoch 5/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 22.0629 - mae: 3.4667 - val_loss: 15.7666 - val_mae: 3.1707\n",
            "Epoch 6/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 17.3924 - mae: 2.9792 - val_loss: 15.3478 - val_mae: 3.1316\n",
            "Epoch 7/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 16.8162 - mae: 2.9127 - val_loss: 15.9743 - val_mae: 2.9992\n",
            "Epoch 8/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 15.3924 - mae: 2.7072 - val_loss: 12.2143 - val_mae: 2.6175\n",
            "Epoch 9/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 12.7876 - mae: 2.4409 - val_loss: 11.0389 - val_mae: 2.6686\n",
            "Epoch 10/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 12.7007 - mae: 2.5218 - val_loss: 12.5162 - val_mae: 2.7006\n",
            "Epoch 11/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 12.3575 - mae: 2.4485 - val_loss: 10.5087 - val_mae: 2.4834\n",
            "Epoch 12/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 11.1979 - mae: 2.4269 - val_loss: 10.9973 - val_mae: 2.6142\n",
            "Epoch 13/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 10.5248 - mae: 2.2674 - val_loss: 10.0912 - val_mae: 2.4562\n",
            "Epoch 14/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 10.1358 - mae: 2.2662 - val_loss: 10.3380 - val_mae: 2.5040\n",
            "Epoch 15/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 9.3257 - mae: 2.1539 - val_loss: 9.6606 - val_mae: 2.4588\n",
            "Epoch 16/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 9.3303 - mae: 2.1729 - val_loss: 10.5813 - val_mae: 2.5517\n",
            "Epoch 17/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 9.7755 - mae: 2.1735 - val_loss: 9.4242 - val_mae: 2.3908\n",
            "Epoch 18/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 9.5996 - mae: 2.2355 - val_loss: 8.2237 - val_mae: 2.2617\n",
            "Epoch 19/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 8.2826 - mae: 2.0465 - val_loss: 9.1007 - val_mae: 2.3387\n",
            "Epoch 20/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 7.9992 - mae: 2.0330 - val_loss: 8.9484 - val_mae: 2.3220\n",
            "Epoch 21/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 8.3176 - mae: 2.1033 - val_loss: 8.7216 - val_mae: 2.3829\n",
            "Epoch 22/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 7.7987 - mae: 1.9778 - val_loss: 9.8106 - val_mae: 2.3562\n",
            "Epoch 23/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 7.4769 - mae: 1.9410 - val_loss: 8.6228 - val_mae: 2.2314\n",
            "Epoch 24/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 7.5567 - mae: 2.0394 - val_loss: 9.7323 - val_mae: 2.5049\n",
            "Epoch 25/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 8.0976 - mae: 2.0867 - val_loss: 9.9632 - val_mae: 2.3686\n",
            "Epoch 26/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 8.4932 - mae: 2.1176 - val_loss: 8.5990 - val_mae: 2.3151\n",
            "Epoch 27/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 7.7467 - mae: 2.0479 - val_loss: 8.3722 - val_mae: 2.2681\n",
            "Epoch 28/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 6.3316 - mae: 1.8377 - val_loss: 8.8793 - val_mae: 2.2594\n",
            "Epoch 29/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 6.0765 - mae: 1.8029 - val_loss: 8.5136 - val_mae: 2.3240\n",
            "Epoch 30/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 5.8097 - mae: 1.8244 - val_loss: 9.5123 - val_mae: 2.3470\n",
            "Epoch 31/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 6.0769 - mae: 1.7998 - val_loss: 8.3393 - val_mae: 2.2718\n",
            "Epoch 32/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 5.3340 - mae: 1.7749 - val_loss: 11.0156 - val_mae: 2.4808\n",
            "Epoch 33/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 5.7179 - mae: 1.8046 - val_loss: 9.4861 - val_mae: 2.3388\n",
            "Epoch 34/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 5.1151 - mae: 1.7045 - val_loss: 7.9618 - val_mae: 2.1304\n",
            "Epoch 35/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 5.1672 - mae: 1.7146 - val_loss: 7.7900 - val_mae: 2.1576\n",
            "Epoch 36/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 4.8258 - mae: 1.6373 - val_loss: 8.7396 - val_mae: 2.1697\n",
            "Epoch 37/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 4.4089 - mae: 1.5893 - val_loss: 7.8798 - val_mae: 2.0819\n",
            "Epoch 38/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 4.3985 - mae: 1.5936 - val_loss: 10.6094 - val_mae: 2.4132\n",
            "Epoch 39/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 4.7419 - mae: 1.6846 - val_loss: 9.0275 - val_mae: 2.2828\n",
            "Epoch 40/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 4.5067 - mae: 1.6106 - val_loss: 8.9114 - val_mae: 2.1927\n",
            "Epoch 41/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 3.8431 - mae: 1.4842 - val_loss: 9.4121 - val_mae: 2.1782\n",
            "Epoch 42/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 4.0459 - mae: 1.5642 - val_loss: 8.3637 - val_mae: 2.1802\n",
            "Epoch 43/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 4.0257 - mae: 1.5203 - val_loss: 9.0844 - val_mae: 2.1436\n",
            "Epoch 44/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 3.9101 - mae: 1.4742 - val_loss: 9.6411 - val_mae: 2.3290\n",
            "Epoch 45/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 4.9993 - mae: 1.6692 - val_loss: 10.9313 - val_mae: 2.5059\n",
            "Epoch 46/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 4.8030 - mae: 1.6878 - val_loss: 10.1459 - val_mae: 2.2793\n",
            "Epoch 47/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 4.3333 - mae: 1.5592 - val_loss: 8.8598 - val_mae: 2.1249\n",
            "Epoch 48/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 4.1183 - mae: 1.5929 - val_loss: 11.5964 - val_mae: 2.3942\n",
            "Epoch 49/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 3.8885 - mae: 1.5248 - val_loss: 8.0664 - val_mae: 2.2269\n",
            "Epoch 50/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 4.3241 - mae: 1.6118 - val_loss: 8.8501 - val_mae: 2.2138\n",
            "Epoch 51/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 4.5983 - mae: 1.6170 - val_loss: 8.1130 - val_mae: 2.1426\n",
            "Epoch 52/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 4.4026 - mae: 1.5879 - val_loss: 9.0783 - val_mae: 2.2215\n",
            "Epoch 53/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 3.6613 - mae: 1.4843 - val_loss: 10.3618 - val_mae: 2.3264\n",
            "Epoch 54/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 3.5244 - mae: 1.4121 - val_loss: 9.6903 - val_mae: 2.2166\n",
            "Epoch 55/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 3.3937 - mae: 1.3443 - val_loss: 8.5627 - val_mae: 2.1594\n",
            "Epoch 56/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 3.0560 - mae: 1.3637 - val_loss: 8.5849 - val_mae: 2.1803\n",
            "Epoch 57/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 3.0003 - mae: 1.3293 - val_loss: 10.1706 - val_mae: 2.2238\n",
            "Epoch 58/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 3.0125 - mae: 1.2933 - val_loss: 8.9764 - val_mae: 2.1716\n",
            "Epoch 59/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 3.0606 - mae: 1.3054 - val_loss: 10.9329 - val_mae: 2.4272\n",
            "Epoch 60/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 3.0919 - mae: 1.2958 - val_loss: 9.7550 - val_mae: 2.3803\n",
            "Epoch 61/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 3.0547 - mae: 1.2942 - val_loss: 10.0351 - val_mae: 2.2889\n",
            "Epoch 62/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 2.8638 - mae: 1.2925 - val_loss: 10.3150 - val_mae: 2.3011\n",
            "Epoch 63/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 2.7777 - mae: 1.2618 - val_loss: 12.9614 - val_mae: 2.4391\n",
            "Epoch 64/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 2.9582 - mae: 1.2981 - val_loss: 10.6196 - val_mae: 2.2280\n",
            "Epoch 65/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 3.0525 - mae: 1.3119 - val_loss: 9.5609 - val_mae: 2.2851\n",
            "Epoch 66/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 3.1849 - mae: 1.3546 - val_loss: 8.5960 - val_mae: 2.1483\n",
            "Epoch 67/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 3.3246 - mae: 1.4025 - val_loss: 8.0525 - val_mae: 2.1901\n",
            "Epoch 68/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 3.3442 - mae: 1.3381 - val_loss: 8.5848 - val_mae: 2.1549\n",
            "Epoch 69/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 2.7898 - mae: 1.2603 - val_loss: 8.7729 - val_mae: 2.0423\n",
            "Epoch 70/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 2.7014 - mae: 1.2595 - val_loss: 12.3077 - val_mae: 2.5084\n",
            "Epoch 71/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 2.9321 - mae: 1.2668 - val_loss: 10.0146 - val_mae: 2.2083\n",
            "Epoch 72/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 3.0210 - mae: 1.2847 - val_loss: 11.4752 - val_mae: 2.5994\n",
            "Epoch 73/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 3.1851 - mae: 1.3506 - val_loss: 8.3316 - val_mae: 2.1757\n",
            "Epoch 74/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 2.7190 - mae: 1.2586 - val_loss: 9.9139 - val_mae: 2.2989\n",
            "Epoch 75/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 2.8341 - mae: 1.3137 - val_loss: 9.2689 - val_mae: 2.1605\n",
            "Epoch 76/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 2.5373 - mae: 1.1972 - val_loss: 10.6243 - val_mae: 2.3990\n",
            "Epoch 77/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 2.6502 - mae: 1.2461 - val_loss: 10.0634 - val_mae: 2.3145\n",
            "Epoch 78/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 2.5868 - mae: 1.2128 - val_loss: 12.7084 - val_mae: 2.5030\n",
            "Epoch 79/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 2.5682 - mae: 1.1876 - val_loss: 8.6957 - val_mae: 2.1354\n",
            "Epoch 80/300\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 2.7757 - mae: 1.2479 - val_loss: 15.1070 - val_mae: 2.6964\n",
            "Epoch 81/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 4.3310 - mae: 1.5206 - val_loss: 9.4923 - val_mae: 2.2399\n",
            "Epoch 82/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 4.9868 - mae: 1.5124 - val_loss: 19.2607 - val_mae: 3.0288\n",
            "Epoch 83/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.1357 - mae: 1.8478 - val_loss: 12.9047 - val_mae: 2.5322\n",
            "Epoch 84/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.4079 - mae: 1.5991 - val_loss: 9.9733 - val_mae: 2.2569\n",
            "Epoch 85/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 5.0906 - mae: 1.7522 - val_loss: 13.4217 - val_mae: 2.9200\n",
            "Epoch 86/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 5.8470 - mae: 1.8385 - val_loss: 10.9309 - val_mae: 2.3215\n",
            "Epoch 87/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 3.6699 - mae: 1.4742 - val_loss: 12.0615 - val_mae: 2.6189\n",
            "Epoch 88/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 3.4831 - mae: 1.4541 - val_loss: 11.3070 - val_mae: 2.5745\n",
            "Epoch 89/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 3.8647 - mae: 1.5103 - val_loss: 11.7822 - val_mae: 2.4631\n",
            "Epoch 90/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 4.6849 - mae: 1.6296 - val_loss: 9.3830 - val_mae: 2.3765\n",
            "Epoch 91/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 3.8988 - mae: 1.4351 - val_loss: 9.6629 - val_mae: 2.2748\n",
            "Epoch 92/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 2.4691 - mae: 1.2412 - val_loss: 9.0600 - val_mae: 2.2777\n",
            "Epoch 93/300\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 2.5241 - mae: 1.2247 - val_loss: 11.8827 - val_mae: 2.4449\n",
            "Epoch 94/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 2.4372 - mae: 1.1726 - val_loss: 9.2619 - val_mae: 2.1841\n",
            "Epoch 95/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 2.3980 - mae: 1.1406 - val_loss: 10.6436 - val_mae: 2.2413\n",
            "Epoch 96/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 2.1127 - mae: 1.0753 - val_loss: 10.3442 - val_mae: 2.2905\n",
            "Epoch 97/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 2.3094 - mae: 1.1790 - val_loss: 9.4826 - val_mae: 2.3540\n",
            "Epoch 98/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 2.4851 - mae: 1.1642 - val_loss: 10.4724 - val_mae: 2.3119\n",
            "Epoch 99/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 2.6725 - mae: 1.2496 - val_loss: 8.6796 - val_mae: 2.2256\n",
            "Epoch 100/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 2.4124 - mae: 1.1629 - val_loss: 10.3963 - val_mae: 2.3049\n",
            "Epoch 101/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 2.3285 - mae: 1.1529 - val_loss: 8.3116 - val_mae: 2.1020\n",
            "Epoch 102/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 1.9881 - mae: 1.0563 - val_loss: 9.4197 - val_mae: 2.3426\n",
            "Epoch 103/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 2.3778 - mae: 1.1716 - val_loss: 9.7637 - val_mae: 2.2839\n",
            "Epoch 104/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 2.4101 - mae: 1.1749 - val_loss: 8.7815 - val_mae: 2.2146\n",
            "Epoch 105/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 2.0909 - mae: 1.0809 - val_loss: 9.3475 - val_mae: 2.2039\n",
            "Epoch 106/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 2.0501 - mae: 1.0831 - val_loss: 10.1902 - val_mae: 2.3871\n",
            "Epoch 107/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 2.4272 - mae: 1.1936 - val_loss: 8.7964 - val_mae: 2.1561\n",
            "Epoch 108/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 1.7379 - mae: 0.9621 - val_loss: 8.6027 - val_mae: 2.1303\n",
            "Epoch 109/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 1.5909 - mae: 0.9267 - val_loss: 8.8886 - val_mae: 2.1728\n",
            "Epoch 110/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 1.4815 - mae: 0.8746 - val_loss: 9.0941 - val_mae: 2.1368\n",
            "Epoch 111/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 1.6313 - mae: 0.9665 - val_loss: 8.6429 - val_mae: 2.1775\n",
            "Epoch 112/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 1.6082 - mae: 0.9222 - val_loss: 8.6404 - val_mae: 2.1478\n",
            "Epoch 113/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 1.5652 - mae: 0.9285 - val_loss: 8.4669 - val_mae: 2.1192\n",
            "Epoch 114/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 1.6653 - mae: 0.9425 - val_loss: 10.5746 - val_mae: 2.2531\n",
            "Epoch 115/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 1.5846 - mae: 0.9666 - val_loss: 7.4877 - val_mae: 2.0052\n",
            "Epoch 116/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 1.6194 - mae: 0.9577 - val_loss: 9.2475 - val_mae: 2.2500\n",
            "Epoch 117/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 1.6256 - mae: 0.9515 - val_loss: 9.7053 - val_mae: 2.2622\n",
            "Epoch 118/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 1.4862 - mae: 0.9248 - val_loss: 8.3738 - val_mae: 2.1023\n",
            "Epoch 119/300\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 1.6138 - mae: 0.9494 - val_loss: 10.3602 - val_mae: 2.5476\n",
            "Epoch 120/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 2.3921 - mae: 1.1750 - val_loss: 9.0639 - val_mae: 2.3238\n",
            "Epoch 121/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 1.5375 - mae: 0.9253 - val_loss: 8.7715 - val_mae: 2.1977\n",
            "Epoch 122/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 1.5838 - mae: 0.9678 - val_loss: 11.5202 - val_mae: 2.3746\n",
            "Epoch 123/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 2.3091 - mae: 1.1229 - val_loss: 10.1946 - val_mae: 2.4691\n",
            "Epoch 124/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 2.2666 - mae: 1.1626 - val_loss: 9.6559 - val_mae: 2.2019\n",
            "Epoch 125/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 1.8306 - mae: 1.0491 - val_loss: 10.4089 - val_mae: 2.3972\n",
            "Epoch 126/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 1.8685 - mae: 1.0153 - val_loss: 9.3766 - val_mae: 2.2792\n",
            "Epoch 127/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 1.9673 - mae: 1.1020 - val_loss: 11.9579 - val_mae: 2.3558\n",
            "Epoch 128/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 1.8938 - mae: 1.0342 - val_loss: 9.1321 - val_mae: 2.1661\n",
            "Epoch 129/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 2.3863 - mae: 1.0690 - val_loss: 10.2928 - val_mae: 2.4206\n",
            "Epoch 130/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 2.2745 - mae: 1.1700 - val_loss: 8.7448 - val_mae: 2.2081\n",
            "Epoch 131/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 3.0041 - mae: 1.3135 - val_loss: 10.5587 - val_mae: 2.4175\n",
            "Epoch 132/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 2.1724 - mae: 1.1049 - val_loss: 11.5163 - val_mae: 2.3628\n",
            "Epoch 133/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 1.5048 - mae: 0.9328 - val_loss: 9.6717 - val_mae: 2.3786\n",
            "Epoch 134/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 1.4628 - mae: 0.8926 - val_loss: 11.2898 - val_mae: 2.3044\n",
            "Epoch 135/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 1.3499 - mae: 0.8680 - val_loss: 10.1979 - val_mae: 2.3198\n",
            "Epoch 136/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 1.2873 - mae: 0.8453 - val_loss: 9.5624 - val_mae: 2.2385\n",
            "Epoch 137/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 1.4561 - mae: 0.8823 - val_loss: 9.3976 - val_mae: 2.2184\n",
            "Epoch 138/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 1.8276 - mae: 1.0100 - val_loss: 10.6435 - val_mae: 2.2876\n",
            "Epoch 139/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 2.0014 - mae: 1.0917 - val_loss: 10.3079 - val_mae: 2.3189\n",
            "Epoch 140/300\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 1.7488 - mae: 1.0134 - val_loss: 12.5840 - val_mae: 2.5394\n",
            "Epoch 141/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 1.9920 - mae: 1.0907 - val_loss: 11.5152 - val_mae: 2.5497\n",
            "Epoch 142/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 1.6271 - mae: 1.0039 - val_loss: 10.0409 - val_mae: 2.2702\n",
            "Epoch 143/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 1.5482 - mae: 0.9378 - val_loss: 11.0193 - val_mae: 2.3478\n",
            "Epoch 144/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 1.3508 - mae: 0.8825 - val_loss: 11.5996 - val_mae: 2.3761\n",
            "Epoch 145/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 1.9028 - mae: 1.0957 - val_loss: 10.0536 - val_mae: 2.3109\n",
            "Epoch 146/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 1.8148 - mae: 1.0280 - val_loss: 11.1757 - val_mae: 2.3446\n",
            "Epoch 147/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 1.4042 - mae: 0.9245 - val_loss: 10.5141 - val_mae: 2.3301\n",
            "Epoch 148/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 1.6917 - mae: 0.9955 - val_loss: 11.3696 - val_mae: 2.5065\n",
            "Epoch 149/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 1.6992 - mae: 1.0135 - val_loss: 10.3388 - val_mae: 2.2511\n",
            "Epoch 150/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 1.4882 - mae: 0.9096 - val_loss: 11.3421 - val_mae: 2.4637\n",
            "Epoch 151/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 1.6148 - mae: 0.9953 - val_loss: 11.8218 - val_mae: 2.6434\n",
            "Epoch 152/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 2.5476 - mae: 1.3037 - val_loss: 9.1601 - val_mae: 2.2348\n",
            "Epoch 153/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 1.8736 - mae: 1.0080 - val_loss: 11.7952 - val_mae: 2.4576\n",
            "Epoch 154/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 1.7614 - mae: 0.9675 - val_loss: 12.2600 - val_mae: 2.4829\n",
            "Epoch 155/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 1.3797 - mae: 0.8434 - val_loss: 8.8847 - val_mae: 2.1771\n",
            "Epoch 156/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 1.3828 - mae: 0.8420 - val_loss: 10.3883 - val_mae: 2.3132\n",
            "Epoch 157/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 1.7639 - mae: 0.9925 - val_loss: 10.7934 - val_mae: 2.4834\n",
            "Epoch 158/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 2.2162 - mae: 1.1453 - val_loss: 10.1537 - val_mae: 2.3120\n",
            "Epoch 159/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 1.8838 - mae: 1.0237 - val_loss: 11.1776 - val_mae: 2.4530\n",
            "Epoch 160/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 1.5569 - mae: 0.9226 - val_loss: 9.5578 - val_mae: 2.3170\n",
            "Epoch 161/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 1.6677 - mae: 0.9801 - val_loss: 11.6743 - val_mae: 2.4081\n",
            "Epoch 162/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 1.5525 - mae: 0.9732 - val_loss: 10.8465 - val_mae: 2.3447\n",
            "Epoch 163/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 1.8872 - mae: 1.0484 - val_loss: 11.7063 - val_mae: 2.3343\n",
            "Epoch 164/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 1.3980 - mae: 0.9160 - val_loss: 11.1047 - val_mae: 2.3553\n",
            "Epoch 165/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 1.1684 - mae: 0.8346 - val_loss: 10.2639 - val_mae: 2.2943\n",
            "Epoch 166/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 1.3364 - mae: 0.8843 - val_loss: 9.7383 - val_mae: 2.2552\n",
            "Epoch 167/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 1.0651 - mae: 0.7649 - val_loss: 10.8146 - val_mae: 2.2512\n",
            "Epoch 168/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 1.0432 - mae: 0.7869 - val_loss: 10.6775 - val_mae: 2.3051\n",
            "Epoch 169/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.8366 - mae: 0.6806 - val_loss: 10.6030 - val_mae: 2.2671\n",
            "Epoch 170/300\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.7895 - mae: 0.6600 - val_loss: 10.4324 - val_mae: 2.3407\n",
            "Epoch 171/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.9845 - mae: 0.7537 - val_loss: 9.5512 - val_mae: 2.2553\n",
            "Epoch 172/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.9348 - mae: 0.7294 - val_loss: 9.2536 - val_mae: 2.2926\n",
            "Epoch 173/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.9118 - mae: 0.7262 - val_loss: 9.9868 - val_mae: 2.2698\n",
            "Epoch 174/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.9302 - mae: 0.7165 - val_loss: 8.9733 - val_mae: 2.2172\n",
            "Epoch 175/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 1.1559 - mae: 0.8027 - val_loss: 11.0223 - val_mae: 2.3987\n",
            "Epoch 176/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 1.2626 - mae: 0.8504 - val_loss: 10.1732 - val_mae: 2.3172\n",
            "Epoch 177/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 1.1283 - mae: 0.7908 - val_loss: 10.7623 - val_mae: 2.2807\n",
            "Epoch 178/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 1.5098 - mae: 0.9249 - val_loss: 10.4997 - val_mae: 2.2962\n",
            "Epoch 179/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 2.0055 - mae: 1.1060 - val_loss: 11.3344 - val_mae: 2.3768\n",
            "Epoch 180/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 2.5030 - mae: 1.2179 - val_loss: 10.7495 - val_mae: 2.3541\n",
            "Epoch 181/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 2.2889 - mae: 1.2116 - val_loss: 11.1000 - val_mae: 2.4328\n",
            "Epoch 182/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 2.1167 - mae: 1.1417 - val_loss: 12.8185 - val_mae: 2.4721\n",
            "Epoch 183/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 1.9424 - mae: 1.1375 - val_loss: 10.0849 - val_mae: 2.2287\n",
            "Epoch 184/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 2.2580 - mae: 1.1139 - val_loss: 12.6941 - val_mae: 2.5224\n",
            "Epoch 185/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 1.8575 - mae: 1.0654 - val_loss: 11.1987 - val_mae: 2.3368\n",
            "Epoch 186/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 1.6929 - mae: 1.0109 - val_loss: 11.8629 - val_mae: 2.4672\n",
            "Epoch 187/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 1.3946 - mae: 0.9123 - val_loss: 9.6184 - val_mae: 2.2302\n",
            "Epoch 188/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 1.0165 - mae: 0.7784 - val_loss: 11.0870 - val_mae: 2.4347\n",
            "Epoch 189/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 1.2321 - mae: 0.8587 - val_loss: 9.9089 - val_mae: 2.3510\n",
            "Epoch 190/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 1.9434 - mae: 1.0955 - val_loss: 11.8560 - val_mae: 2.4653\n",
            "Epoch 191/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 1.8142 - mae: 1.0730 - val_loss: 10.8462 - val_mae: 2.3588\n",
            "Epoch 192/300\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 1.7589 - mae: 1.0428 - val_loss: 11.6559 - val_mae: 2.4945\n",
            "Epoch 193/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 1.5351 - mae: 0.9715 - val_loss: 11.4785 - val_mae: 2.5235\n",
            "Epoch 194/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 2.1982 - mae: 1.1794 - val_loss: 9.8360 - val_mae: 2.3626\n",
            "Epoch 195/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 1.8079 - mae: 1.0415 - val_loss: 9.6046 - val_mae: 2.3714\n",
            "Epoch 196/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 1.8969 - mae: 1.0762 - val_loss: 11.7998 - val_mae: 2.4910\n",
            "Epoch 197/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 1.6147 - mae: 0.9769 - val_loss: 11.0065 - val_mae: 2.3725\n",
            "Epoch 198/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 1.4220 - mae: 0.8743 - val_loss: 12.1106 - val_mae: 2.3856\n",
            "Epoch 199/300\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 1.1344 - mae: 0.8134 - val_loss: 11.0804 - val_mae: 2.2788\n",
            "Epoch 200/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 1.2304 - mae: 0.8744 - val_loss: 12.4929 - val_mae: 2.4389\n",
            "Epoch 201/300\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.9389 - mae: 0.7374 - val_loss: 9.7296 - val_mae: 2.2387\n",
            "Epoch 202/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.9793 - mae: 0.7268 - val_loss: 11.5053 - val_mae: 2.3516\n",
            "Epoch 203/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 1.0304 - mae: 0.7596 - val_loss: 11.3690 - val_mae: 2.2933\n",
            "Epoch 204/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.9418 - mae: 0.7619 - val_loss: 11.8093 - val_mae: 2.3081\n",
            "Epoch 205/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.8701 - mae: 0.7108 - val_loss: 11.6601 - val_mae: 2.3921\n",
            "Epoch 206/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.9585 - mae: 0.7562 - val_loss: 10.0841 - val_mae: 2.2391\n",
            "Epoch 207/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.9357 - mae: 0.7412 - val_loss: 11.2412 - val_mae: 2.3348\n",
            "Epoch 208/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.8800 - mae: 0.7076 - val_loss: 9.3122 - val_mae: 2.1665\n",
            "Epoch 209/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.7236 - mae: 0.6510 - val_loss: 10.2780 - val_mae: 2.2670\n",
            "Epoch 210/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6802 - mae: 0.6295 - val_loss: 11.5058 - val_mae: 2.3866\n",
            "Epoch 211/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.8318 - mae: 0.6668 - val_loss: 10.9035 - val_mae: 2.3205\n",
            "Epoch 212/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.9756 - mae: 0.7988 - val_loss: 11.0468 - val_mae: 2.3591\n",
            "Epoch 213/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.8203 - mae: 0.6820 - val_loss: 10.6150 - val_mae: 2.3617\n",
            "Epoch 214/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.9192 - mae: 0.7313 - val_loss: 10.8004 - val_mae: 2.4599\n",
            "Epoch 215/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 1.2013 - mae: 0.8509 - val_loss: 9.8775 - val_mae: 2.3491\n",
            "Epoch 216/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 1.0980 - mae: 0.8072 - val_loss: 10.8462 - val_mae: 2.3487\n",
            "Epoch 217/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 1.1231 - mae: 0.7809 - val_loss: 9.5168 - val_mae: 2.2966\n",
            "Epoch 218/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 1.1425 - mae: 0.8050 - val_loss: 13.1846 - val_mae: 2.5152\n",
            "Epoch 219/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.9882 - mae: 0.7643 - val_loss: 10.2259 - val_mae: 2.2806\n",
            "Epoch 220/300\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.9393 - mae: 0.7350 - val_loss: 10.9789 - val_mae: 2.3760\n",
            "Epoch 221/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.7609 - mae: 0.6777 - val_loss: 9.6976 - val_mae: 2.2750\n",
            "Epoch 222/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6235 - mae: 0.5962 - val_loss: 11.6784 - val_mae: 2.3450\n",
            "Epoch 223/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.7358 - mae: 0.6420 - val_loss: 9.6074 - val_mae: 2.3213\n",
            "Epoch 224/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.8257 - mae: 0.6871 - val_loss: 10.4559 - val_mae: 2.3044\n",
            "Epoch 225/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 1.0107 - mae: 0.7825 - val_loss: 9.8298 - val_mae: 2.3050\n",
            "Epoch 226/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 1.0113 - mae: 0.7880 - val_loss: 10.1658 - val_mae: 2.3148\n",
            "Epoch 227/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 1.0085 - mae: 0.7669 - val_loss: 10.6101 - val_mae: 2.2848\n",
            "Epoch 228/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.8165 - mae: 0.6713 - val_loss: 11.5124 - val_mae: 2.3752\n",
            "Epoch 229/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.7173 - mae: 0.6447 - val_loss: 9.6611 - val_mae: 2.2752\n",
            "Epoch 230/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6201 - mae: 0.5951 - val_loss: 10.6575 - val_mae: 2.2904\n",
            "Epoch 231/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.7195 - mae: 0.6381 - val_loss: 10.4170 - val_mae: 2.2995\n",
            "Epoch 232/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6019 - mae: 0.5918 - val_loss: 12.8635 - val_mae: 2.4570\n",
            "Epoch 233/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.6201 - mae: 0.5877 - val_loss: 10.9777 - val_mae: 2.3257\n",
            "Epoch 234/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.5586 - mae: 0.5682 - val_loss: 11.0788 - val_mae: 2.4036\n",
            "Epoch 235/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6949 - mae: 0.6243 - val_loss: 10.2183 - val_mae: 2.3217\n",
            "Epoch 236/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 1.1269 - mae: 0.8175 - val_loss: 11.2079 - val_mae: 2.4391\n",
            "Epoch 237/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 1.2062 - mae: 0.8394 - val_loss: 10.2628 - val_mae: 2.2526\n",
            "Epoch 238/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.8087 - mae: 0.6794 - val_loss: 10.4235 - val_mae: 2.3100\n",
            "Epoch 239/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6428 - mae: 0.6138 - val_loss: 9.5257 - val_mae: 2.2329\n",
            "Epoch 240/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6198 - mae: 0.6022 - val_loss: 10.2635 - val_mae: 2.2770\n",
            "Epoch 241/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.5557 - mae: 0.5642 - val_loss: 10.4423 - val_mae: 2.2858\n",
            "Epoch 242/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6272 - mae: 0.6004 - val_loss: 9.3903 - val_mae: 2.2796\n",
            "Epoch 243/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6914 - mae: 0.6230 - val_loss: 10.7937 - val_mae: 2.3030\n",
            "Epoch 244/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.8637 - mae: 0.6745 - val_loss: 10.0137 - val_mae: 2.2617\n",
            "Epoch 245/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 1.0336 - mae: 0.7676 - val_loss: 10.7485 - val_mae: 2.3151\n",
            "Epoch 246/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6955 - mae: 0.6317 - val_loss: 10.4541 - val_mae: 2.3023\n",
            "Epoch 247/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6361 - mae: 0.5946 - val_loss: 10.7727 - val_mae: 2.3072\n",
            "Epoch 248/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.5798 - mae: 0.5882 - val_loss: 10.3218 - val_mae: 2.3050\n",
            "Epoch 249/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.5190 - mae: 0.5499 - val_loss: 9.3287 - val_mae: 2.1946\n",
            "Epoch 250/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6074 - mae: 0.5909 - val_loss: 10.8518 - val_mae: 2.3362\n",
            "Epoch 251/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.7970 - mae: 0.6803 - val_loss: 12.3924 - val_mae: 2.5823\n",
            "Epoch 252/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 1.4590 - mae: 0.9600 - val_loss: 11.4351 - val_mae: 2.4586\n",
            "Epoch 253/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 1.0479 - mae: 0.7754 - val_loss: 10.5682 - val_mae: 2.2872\n",
            "Epoch 254/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.8552 - mae: 0.7309 - val_loss: 12.3688 - val_mae: 2.4902\n",
            "Epoch 255/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 1.5879 - mae: 0.9948 - val_loss: 11.4627 - val_mae: 2.4110\n",
            "Epoch 256/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 1.4971 - mae: 0.9761 - val_loss: 10.9443 - val_mae: 2.3179\n",
            "Epoch 257/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 2.0265 - mae: 1.1178 - val_loss: 13.1335 - val_mae: 2.5881\n",
            "Epoch 258/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 1.1714 - mae: 0.8389 - val_loss: 10.7468 - val_mae: 2.3756\n",
            "Epoch 259/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 1.2870 - mae: 0.8607 - val_loss: 12.4525 - val_mae: 2.4842\n",
            "Epoch 260/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 1.1704 - mae: 0.8541 - val_loss: 8.8398 - val_mae: 2.1429\n",
            "Epoch 261/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 1.3175 - mae: 0.8641 - val_loss: 13.5402 - val_mae: 2.5093\n",
            "Epoch 262/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 1.1396 - mae: 0.8079 - val_loss: 13.4014 - val_mae: 2.4755\n",
            "Epoch 263/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.8231 - mae: 0.6965 - val_loss: 11.3725 - val_mae: 2.2996\n",
            "Epoch 264/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.7745 - mae: 0.6836 - val_loss: 10.4987 - val_mae: 2.2873\n",
            "Epoch 265/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.8097 - mae: 0.6972 - val_loss: 10.2379 - val_mae: 2.2760\n",
            "Epoch 266/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.5057 - mae: 0.5176 - val_loss: 11.6787 - val_mae: 2.4379\n",
            "Epoch 267/300\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.5934 - mae: 0.5837 - val_loss: 9.5092 - val_mae: 2.2337\n",
            "Epoch 268/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.7523 - mae: 0.6137 - val_loss: 13.0054 - val_mae: 2.4990\n",
            "Epoch 269/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6207 - mae: 0.5719 - val_loss: 9.8599 - val_mae: 2.2388\n",
            "Epoch 270/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6362 - mae: 0.5803 - val_loss: 12.5673 - val_mae: 2.3916\n",
            "Epoch 271/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.7024 - mae: 0.6288 - val_loss: 9.3391 - val_mae: 2.2436\n",
            "Epoch 272/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.9684 - mae: 0.7211 - val_loss: 13.5171 - val_mae: 2.5129\n",
            "Epoch 273/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.9824 - mae: 0.7575 - val_loss: 10.2733 - val_mae: 2.4033\n",
            "Epoch 274/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 1.5616 - mae: 0.9644 - val_loss: 9.6830 - val_mae: 2.4256\n",
            "Epoch 275/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 2.0209 - mae: 1.0128 - val_loss: 10.0891 - val_mae: 2.4142\n",
            "Epoch 276/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 1.5703 - mae: 0.9672 - val_loss: 11.0824 - val_mae: 2.5162\n",
            "Epoch 277/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 1.2293 - mae: 0.8689 - val_loss: 9.6260 - val_mae: 2.4384\n",
            "Epoch 278/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 1.0591 - mae: 0.7827 - val_loss: 11.7291 - val_mae: 2.4377\n",
            "Epoch 279/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.9544 - mae: 0.7340 - val_loss: 9.5678 - val_mae: 2.2859\n",
            "Epoch 280/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.9341 - mae: 0.7475 - val_loss: 13.2593 - val_mae: 2.5384\n",
            "Epoch 281/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.8546 - mae: 0.7097 - val_loss: 10.6777 - val_mae: 2.2978\n",
            "Epoch 282/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.9673 - mae: 0.7632 - val_loss: 11.1019 - val_mae: 2.4898\n",
            "Epoch 283/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 1.2581 - mae: 0.8787 - val_loss: 12.1610 - val_mae: 2.4786\n",
            "Epoch 284/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 1.2652 - mae: 0.8720 - val_loss: 8.9535 - val_mae: 2.3024\n",
            "Epoch 285/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.9428 - mae: 0.7384 - val_loss: 10.6660 - val_mae: 2.4834\n",
            "Epoch 286/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 1.2526 - mae: 0.8361 - val_loss: 11.6942 - val_mae: 2.4880\n",
            "Epoch 287/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 1.5070 - mae: 0.9399 - val_loss: 9.6962 - val_mae: 2.4049\n",
            "Epoch 288/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.2279 - mae: 0.8847 - val_loss: 11.6205 - val_mae: 2.4277\n",
            "Epoch 289/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.1737 - mae: 0.8210 - val_loss: 9.6973 - val_mae: 2.2044\n",
            "Epoch 290/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.7788 - mae: 0.6723 - val_loss: 10.0439 - val_mae: 2.2939\n",
            "Epoch 291/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.7549 - mae: 0.6723 - val_loss: 9.0692 - val_mae: 2.2688\n",
            "Epoch 292/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.7031 - mae: 0.6445 - val_loss: 11.0868 - val_mae: 2.4769\n",
            "Epoch 293/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.7439 - mae: 0.6718 - val_loss: 9.1215 - val_mae: 2.3197\n",
            "Epoch 294/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6910 - mae: 0.5983 - val_loss: 9.5098 - val_mae: 2.2927\n",
            "Epoch 295/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.5841 - mae: 0.5901 - val_loss: 9.7794 - val_mae: 2.2399\n",
            "Epoch 296/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.5154 - mae: 0.5603 - val_loss: 9.7990 - val_mae: 2.3133\n",
            "Epoch 297/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.5142 - mae: 0.5400 - val_loss: 10.1310 - val_mae: 2.3838\n",
            "Epoch 298/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.4318 - mae: 0.5092 - val_loss: 10.0758 - val_mae: 2.3070\n",
            "Epoch 299/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.4787 - mae: 0.5070 - val_loss: 10.4870 - val_mae: 2.3702\n",
            "Epoch 300/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.3847 - mae: 0.4751 - val_loss: 9.4262 - val_mae: 2.2634\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(x_train, y_train, epochs=300,\n",
        "                    validation_data=(x_val, y_val))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1erMMEoeR0rB"
      },
      "source": [
        "### 모델 평가 \n",
        "- `evaluate()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Jo0n0SaZRbD1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 0s 1ms/step - loss: 15.8466 - mae: 2.6733\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[15.846640586853027, 2.673264503479004]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.evaluate(x_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "dl98Ql_8nvf3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dict_keys(['loss', 'mae', 'val_loss', 'val_mae'])\n"
          ]
        }
      ],
      "source": [
        "print(history.history.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NOgcoBclnsJ7"
      },
      "outputs": [],
      "source": [
        "history_dict = history.history\n",
        "\n",
        "loss = history_dict['loss']\n",
        "val_loss = history_dict['val_loss']\n",
        "\n",
        "epochs = range(1, len(loss) + 1)\n",
        "fig = plt.figure(figsize=(12, 6))\n",
        "\n",
        "ax1 = fig.add_subplot(1,2,1)\n",
        "ax1.plot(epochs, loss, color='blue', label='train_loss')\n",
        "ax1.plot(epochs, val_loss, color='red', label='val_loss')\n",
        "ax1.set_title('Train and Validation Loss')\n",
        "ax1.set_xlabel('Epochs')\n",
        "ax1.set_ylabel('Loss')\n",
        "ax1.grid()\n",
        "ax1.legend()\n",
        "\n",
        "mae = history_dict['mae']\n",
        "val_mae = history_dict['val_mae']\n",
        "\n",
        "ax2 = fig.add_subplot(1,2,2)\n",
        "ax2.plot(epochs, mae, color='blue', label='train_mae')\n",
        "ax2.plot(epochs, val_mae, color='red', label='val_mae')\n",
        "ax2.set_title('Train and Validation MAE')\n",
        "ax2.set_xlabel('Epochs')\n",
        "ax2.set_ylabel('MAE')\n",
        "ax2.grid()\n",
        "ax2.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VtICFsIvVpF2"
      },
      "source": [
        "### K-Fold 교차 검증\n",
        "\n",
        "- 데이터셋의 크기가 매우 작은 경우에  \n",
        "  [훈련, 검증, 테스트] 데이터로 나누게 되면 과소적합이 일어날 확률이 높음\n",
        "\n",
        "- 이를 해결하기 위해 K-Fold 교차 검증 실행\n",
        "  <br>\n",
        "\n",
        "  <img src=\"https://scikit-learn.org/stable/_images/grid_search_cross_validation.png\" width=\"600\">\n",
        "\n",
        "  <sub>출처: https://scikit-learn.org/stable/modules/cross_validation.html</sub>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "giNUN6mwWSDO"
      },
      "source": [
        "### 모델 재구성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PIFRNBlYWzBc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "60EvVZ9qR5v6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7HiJbnWrWkXY"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xS3uTP6oXDzr"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2iMCmLyLYI2l"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OE_0YHP-YUHU"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NJB6bWP_Y80O"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qjwxuiq4cITg"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "263930470851f494f0ed2879c35b57985588df20f9e529b86e97dd5eb9ddc466"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
