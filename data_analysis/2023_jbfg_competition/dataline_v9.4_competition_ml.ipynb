{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JBFG Data Analysis Competition\n",
    "- Null 처리방식 : 2번"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Library for Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl  \n",
    "import missingno as msno\n",
    "import warnings\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "# import plotly.figure_factory as ff\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.offline as pyo\n",
    "pyo.init_notebook_mode()\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "%matplotlib inline\n",
    "\n",
    "mpl.rc('font', family='Malgun Gothic')  # 한글 폰트 설정\n",
    "                                        # 윈도우 폰트 위치 - C:\\Windows\\Fonts\n",
    "plt.figure(figsize=(10,6))              # 그래프 사이즈 설정\n",
    "sns.set(font='Malgun Gothic', rc={'axes.unicode_minus':False}, style='darkgrid') # 마이너스 처리\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 컬럼 데이터 및 Null 건수 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def change_format(df, column, format):\n",
    "    if format == 'comma':\n",
    "        df[column] = df[column].apply(lambda x: f\"{x:,}\")\n",
    "    elif format == 'percent':\n",
    "        df[column] = df[column].apply(lambda x: f\"{x:.2%}\")\n",
    "        \n",
    "    return df\n",
    "\n",
    "\n",
    "def count_column_na_count(df, column):\n",
    "    '''\n",
    "    '''\n",
    "    column_na_counts = df[column].size, df[column].count(), df[column].isnull().sum()\n",
    "    column_na_counts_df = pd.Series(column_na_counts).to_frame().T\n",
    "    column_na_counts_df.columns = ['tot_counts', 'data_counts', 'null_counts']\n",
    "    column_na_counts_df['data_percents'] = column_na_counts_df['data_counts'].values/column_na_counts_df['tot_counts'].values\n",
    "    column_na_counts_df['null_percents'] = column_na_counts_df['null_counts'].values/column_na_counts_df['tot_counts'].values\n",
    "\n",
    "\n",
    "    column_na_counts_df = change_format(column_na_counts_df, 'tot_counts', 'comma')\n",
    "    column_na_counts_df = change_format(column_na_counts_df, 'data_counts','comma')\n",
    "    column_na_counts_df = change_format(column_na_counts_df, 'null_counts','comma')\n",
    "    column_na_counts_df = change_format(column_na_counts_df, 'data_percents', 'percent')\n",
    "    column_na_counts_df = change_format(column_na_counts_df, 'null_percents', 'percent')\n",
    "\n",
    "    print(column_na_counts_df.to_string(index=False))\n",
    "    print('-'*70)\n",
    "\n",
    "\n",
    "def count_column_data_count(df, column):\n",
    "    ''' \n",
    "    '''\n",
    "    # column_data_countcounts = df.groupby(column)['is_churned'].value_counts().unstack()\n",
    "\n",
    "\n",
    "    column_counts = df.groupby(column)['is_churned'].value_counts().unstack()\n",
    "    column_counts = column_counts.rename(columns={0: 'exist_counts', 1: 'churned_counts'})\n",
    "    column_counts['total_counts'] =  column_counts['exist_counts'] + column_counts['churned_counts']\n",
    "    column_counts = column_counts.fillna(0)\n",
    "\n",
    "    column_percents = df.groupby(column)['is_churned'].value_counts(normalize=True).unstack()\n",
    "    column_percents = column_percents.rename(columns={0: 'exist_percents', 1: 'churned_percents'})\n",
    "    column_percents = column_percents.fillna(0)\n",
    "\n",
    "\n",
    "    column_count_percent = pd.concat([column_counts, column_percents], axis=1)\n",
    "    column_count_percent = column_count_percent.reset_index()\n",
    "    column_count_percent = column_count_percent.sort_values(by='churned_percents', ascending=False)\n",
    "\n",
    "    \n",
    "    column_count_percent = change_format(column_count_percent, 'exist_counts', 'comma')\n",
    "    column_count_percent = change_format(column_count_percent, 'churned_counts', 'comma')\n",
    "    column_count_percent = change_format(column_count_percent, 'total_counts', 'comma')\n",
    "    column_count_percent = change_format(column_count_percent, 'exist_percents', 'percent')\n",
    "    column_count_percent = change_format(column_count_percent, 'churned_percents', 'percent')\n",
    "    \n",
    "\n",
    "    print(column_count_percent.to_string(index=False))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning\n",
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Library and Data Loading, Function Definition for Machine Learning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split,cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.metrics import f1_score, confusion_matrix, precision_recall_curve, roc_curve\n",
    "\n",
    "# import scikitplot as skplt\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.feature_selection import RFE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function Definition"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_churner_df = pd.read_csv(\"./data/bank_churner.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 전처리(Pre-Processing)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 불필요한 컬럼 삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_churner_df = ml_churner_df.drop('cstno', axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 전처리 함수 정의"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 결측(Null) 데이터 확인 및 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tot_column_counts(df):\n",
    "    ''' \n",
    "    '''\n",
    "    data_counts = df.count()\n",
    "    null_counts = df.isnull().sum()\n",
    "    tot_counts_df = pd.concat([data_counts, null_counts], axis=1)\n",
    "    tot_counts_df = tot_counts_df.rename(columns={0: 'data_counts', 1: 'null_counts'})\n",
    "    tot_counts_df.insert(0,'tot_counts', tot_counts_df['data_counts'] + tot_counts_df['null_counts'])\n",
    "    tot_counts_df['data_percents'] = tot_counts_df['data_counts'].values / tot_counts_df['tot_counts'].values\n",
    "    tot_counts_df['null_percents'] = tot_counts_df['null_counts'].values / tot_counts_df['tot_counts'].values\n",
    "    tot_counts_df = tot_counts_df.sort_values(by='null_percents', ascending=False)\n",
    "\n",
    "    tot_counts_df = change_format(tot_counts_df, 'tot_counts', 'comma')\n",
    "    tot_counts_df = change_format(tot_counts_df, 'data_counts','comma')\n",
    "    tot_counts_df = change_format(tot_counts_df, 'null_counts','comma')\n",
    "    tot_counts_df = change_format(tot_counts_df, 'data_percents', 'percent')\n",
    "    tot_counts_df = change_format(tot_counts_df, 'null_percents', 'percent')\n",
    "\n",
    "    tot_counts_df = tot_counts_df.reset_index()\n",
    "\n",
    "    print(tot_counts_df.to_string(index=False))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 원-핫(One-Hot) 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def encode_onehot(df):\n",
    "    # sex                    7293 non-null   object \n",
    "    # education              8101 non-null   object \n",
    "    # marital_stat           8101 non-null   object \n",
    "    # imcome_cat             6482 non-null   object \n",
    "    # card_type              8101 non-null   object \n",
    "\n",
    "    # # ml_churner_df = pd.concat([ml_churner_df, pd.get_dummies(ml_churner_df['sex'])], axis=1)\n",
    "    # df = pd.concat([df, pd.get_dummies(df['education']).drop(columns=['Unknown'])], axis=1)\n",
    "    # df = pd.concat([df, pd.get_dummies(df['marital_stat']).drop(columns=['Unknown'])], axis=1)\n",
    "    # # ml_churner_df = pd.concat([ml_churner_df, pd.get_dummies(ml_churner_df['imcome_cat']).drop(columns=['Unknown'])], axis=1)\n",
    "    # df = pd.concat([df, pd.get_dummies(df['card_type'])], axis=1)\n",
    "    # # ml_churner_df.drop(columns = ['sex', 'education', 'marital_stat', 'imcome_cat', 'card_type'], inplace=True)\n",
    "    # df.drop(columns = ['education', 'marital_stat', 'card_type'], inplace=True)\n",
    "    \n",
    "    catcols = df.select_dtypes(exclude = ['int64','float64']).columns\n",
    "    df = pd.get_dummies(df, columns = catcols)\n",
    "    \n",
    "    return df, catcols\n",
    "\n",
    "# ml_churner_df = pd.read_csv(\"./data/bank_churner.csv\")\n",
    "# ml_churner_df = ml_churner_df.drop('cstno', axis=1)\n",
    "\n",
    "# ddf, catcols = encode_onehot(ml_churner_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 학습에 사용될 중요 Feature 식별"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_feature(df, model):\n",
    "\n",
    "    #Set the random seed for reproducibility\n",
    "    np.random.seed(42)\n",
    "\n",
    "    #Define a list of available models for selection\n",
    "    available_models = {\n",
    "        'ExtraTrees': ExtraTreesClassifier(n_estimators=100),\n",
    "        'RandomForest': RandomForestClassifier(n_estimators=100),\n",
    "        'SVM': SVC(kernel='linear'),\n",
    "        'KNN': KNeighborsClassifier(n_neighbors=5),\n",
    "        'LASSO': Lasso(alpha=0.01),  # Agrega LASSO aquí\n",
    "        'RFE': RFE(estimator=RandomForestClassifier(n_estimators=100), n_features_to_select=13)\n",
    "    }\n",
    "\n",
    "    # Choose the desired model for feature selection\n",
    "    chosen_model = model\n",
    "\n",
    "    # Create the selected model\n",
    "    clf = available_models[chosen_model]\n",
    "\n",
    "    #Train the model with the data\n",
    "    clf = clf.fit(df.values, y)\n",
    "\n",
    "    # Obtain feature importances from the model\n",
    "    feature_importances = clf.feature_importances_\n",
    "\n",
    "    # Create a SelectFromModel object with the trained classifier\n",
    "    model = SelectFromModel(clf, prefit=True)\n",
    "\n",
    "    #Transform the original features to obtain the selected ones\n",
    "\n",
    "    X_df = model.transform(df.values)\n",
    "\n",
    "    selected_feature_indices = model.get_support(indices=True)\n",
    "\n",
    "    #Get the indices of the selected features\n",
    "    selected_columns = df.columns[selected_feature_indices]\n",
    "    \n",
    "    return X_df, selected_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proc_smote(X_new, y):\n",
    "    #Model Training\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    # Split the data into training and test sets\n",
    "    X_train, X_test, y_train, y_test=train_test_split(X_new,y,test_size=0.25,stratify=y,random_state=0)\n",
    "\n",
    "\n",
    "    from imblearn.over_sampling import SMOTE\n",
    "    X_train,X_test,y_train,y_test=train_test_split(X_new,y,test_size=0.25,stratify=y,random_state=0)\n",
    "\n",
    "    sm = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "    X_train, y_train=sm.fit_resample(X_train,y_train)\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proc_normalization(X_train, X_test):\n",
    "    #Normalization\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    sc=StandardScaler()\n",
    "    X_train=sc.fit_transform(X_train)\n",
    "    X_test=sc.transform(X_test)\n",
    "    \n",
    "    return X_train, X_test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델별 학습 및 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_predict(proc_type, drop_no, model_comparison, X_train, y_train, X_test, y_test):\n",
    "    #Training with different models\n",
    "    #entrenamiento con distintos modelos\n",
    "    from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from lightgbm import LGBMClassifier\n",
    "    from xgboost import XGBClassifier\n",
    "\n",
    "    #Create a list of tuples with the model name and the classifier instance\n",
    "    # Crear una lista de tuplas con el nombre del modelo y la instancia del clasificador\n",
    "    models = [\n",
    "        # ('Logistic Regression', LogisticRegression()),\n",
    "        # ('Decision Tree', DecisionTreeClassifier(criterion='entropy', random_state=0)),\n",
    "        # ('KNN', KNeighborsClassifier(n_neighbors=5)),\n",
    "        # ('Naive Bayes', GaussianNB()),\n",
    "        # ('Random Forest', RandomForestClassifier(n_estimators=10, criterion='entropy', random_state=0)),\n",
    "        # ('LightGBM', LGBMClassifier(n_estimators=500, random_state=42, boosting_type='GOSS')),\n",
    "        ('LightGBM', LGBMClassifier(n_estimators=500, random_state=42, boosting_type='GOSS')),\n",
    "        ('Xg Boost', XGBClassifier(n_estimators=500, random_state=42, use_label_encoder=False,  eval_metric='logloss')),\n",
    "    ]\n",
    "\n",
    "\n",
    "    for model_name, classifier in models:\n",
    "        #Fit the model using the training set\n",
    "        classifier.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "        #Make predictions on the test set\n",
    "        y_pred = classifier.predict(X_test)\n",
    "        pred_proba = classifier.predict_proba(X_test)[:, 1]\n",
    "\n",
    "        \n",
    "        #Calculate model metrics\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        #f1 = f1_score(y_pred, y_test, average='weighted')\n",
    "        f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "        ## 확인 필요 ??? \n",
    "        accuracies = cross_val_score(estimator=classifier, X=X_test, y=y_test, cv=5, scoring=\"recall\")\n",
    "        cv_accuracy = accuracies.mean()\n",
    "        cv_std = accuracies.std()\n",
    "        accuracy_class_0 = accuracy_score(y_test[y_test == 0], y_pred[y_test == 0])\n",
    "        accuracy_class_1 = accuracy_score(y_test[y_test == 1], y_pred[y_test == 1], )\n",
    "        roc_auc = roc_auc_score(y_test, pred_proba)\n",
    "        \n",
    "        #Print model metrics\n",
    "        # print(\"-\" * 30)\n",
    "        # print(f\"Model: {model_name}\")\n",
    "        # print(\"-\" * 30)\n",
    "        # print(f\"Model Accuracy: {accuracy * 100:.2f}%\")\n",
    "        # print(f\"Model F1-Score: {f1 * 100:.2f}%\")\n",
    "        # print(f\"Cross Val Accuracy: {cv_accuracy * 100:.2f}%\")\n",
    "        # print(f\"Cross Val Standard Deviation: {cv_std * 100:.2f}%\")\n",
    "\n",
    "\n",
    "        #Add metrics to the models comparison dictionary\n",
    "        model_comparison[f'{model_name}_{proc_type}_{drop_no}'] = [accuracy, accuracy_class_0, accuracy_class_1, f1, cv_accuracy, cv_std, roc_auc]\n",
    "        # print(classification_report(y_pred, y_test, zero_division=1))\n",
    "        # print(\"-\" * 60)\n",
    "\n",
    "        \n",
    "        # get_clf_eval(y_test, y_pred, pred_proba)\n",
    "        \n",
    "        # precision_recall_curve_plot(y_test, pred_proba)\n",
    "        # roc_curve_plot(y_test , pred_proba)\n",
    "        \n",
    "        # print(\"-\" * 100)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습 및 예측 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_eval_result(model_comparison):\n",
    "    import pandas as pd\n",
    "\n",
    "    # MODEL COMPARISSON\n",
    "\n",
    "    Model_com_df=pd.DataFrame(model_comparison).T\n",
    "    Model_com_df.columns=['Model Accuracy','Model Accuracy-0','Model Accuracy-1','Model F1-Score','CV Accuracy','CV std', 'AUC']\n",
    "    Model_com_df=Model_com_df.sort_values(by='AUC',ascending=False)\n",
    "    # display(Model_com_df.style.format(\"{:.2%}\").background_gradient(cmap='magma'))\n",
    "\n",
    "\n",
    "    Model_com_df = pd.DataFrame(model_comparison).T\n",
    "    Model_com_df.columns = ['Model Accuracy', 'Model Accuracy-No', 'Model Accuracy-Yes', 'Model F1-Score', 'CV Accuracy', 'CV std', 'AUC']\n",
    "    Model_com_df = Model_com_df.sort_values(by='AUC', ascending=False)\n",
    "\n",
    "    def highlight_below_75(s):\n",
    "        if s.name != 'CV std' and isinstance(s, pd.Series) and s.dtype == 'float64':\n",
    "            return ['color: red' if value < 0.75 else 'color: black' for value in s]\n",
    "        else:\n",
    "            return ['color: black'] * len(s)\n",
    "\n",
    "    styled_df = Model_com_df.iloc[:10,:].style.highlight_max(axis=0).apply(highlight_below_75, subset=pd.IndexSlice[:, :'CV Accuracy']).format(\"{:.2%}\", subset=pd.IndexSlice[:, :'CV Accuracy'])\n",
    "    display(styled_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 메인 처리 for 예측"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 메인 처리 함수"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 메인 처리 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_null_column(df, drop_list):\n",
    "    \n",
    "    for col_name in drop_list:\n",
    "        # print(col_name, type(col_name))\n",
    "        df = df.drop(col_name, axis=1)\n",
    "        df.dropna(axis=0, inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "from itertools import combinations\n",
    "\n",
    "# result_list = []\n",
    "# drop_target_columns = ['sex','imcome_cat', 'tot_amt_ratio_q4_q1', 'mean_util_pct', 'tot_trans_cnt_for_12m','age','mean_open_to_buy','tot_trans_amt_for_12m']\n",
    "# for j in range(1, len(drop_target_columns)+1):\n",
    "#     for i in combinations(drop_target_columns, j):\n",
    "#         result_list.append(list(i))\n",
    "\n",
    "# for no, drop_column in enumerate(result_list):\n",
    "#     ml_churner_df = pd.read_csv(\"./data/bank_churner.csv\")\n",
    "#     ml_churner_df = ml_churner_df.drop('cstno', axis=1)\n",
    "\n",
    "#     ml_churner_df = drop_null_column(ml_churner_df, drop_column)\n",
    "#     print(f'구분 : {no}, 남은 갯수: {len(ml_churner_df)}, Drop Col:{drop_column}')\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "model_comparison = {}  #Dictionary to store the comparison metrics of models\n",
    "model_eval_comparison = {}                        \n",
    "    \n",
    "# -----------\n",
    "# 예측\n",
    "# -----------\n",
    "\n",
    "# 데이터 로드 및 고객번호 삭제\n",
    "# ml_churner_df = pd.read_csv(\"./data/bank_churner.csv\")\n",
    "# ml_churner_df = ml_churner_df.drop('cstno', axis=1)\n",
    "\n",
    "# Null 처리\n",
    "'''\n",
    "result_list = []\n",
    "drop_target_columns = ['sex','imcome_cat', 'tot_amt_ratio_q4_q1', 'mean_util_pct', 'tot_trans_cnt_for_12m','age','mean_open_to_buy','tot_trans_amt_for_12m']\n",
    "# drop_target_columns = ['sex','imcome_cat']\n",
    "#drop_target_columns = ['sex','imcome_cat']\n",
    "for j in range(1, len(drop_target_columns)+1):\n",
    "    for i in combinations(drop_target_columns, j):\n",
    "        result_list.append(list(i))\n",
    "'''\n",
    "\n",
    "# result_list = [['tot_amt_ratio_q4_q1']\n",
    "# ,['mean_util_pct']\n",
    "# ,['sex', 'age']\n",
    "# ,['sex', 'mean_open_to_buy']\n",
    "# ,['tot_amt_ratio_q4_q1', 'mean_util_pct']\n",
    "# ,['tot_amt_ratio_q4_q1', 'age']\n",
    "# ,['tot_amt_ratio_q4_q1', 'mean_open_to_buy']\n",
    "# ,['mean_util_pct', 'age']\n",
    "# ,['sex', 'imcome_cat', 'mean_open_to_buy']\n",
    "# ,['imcome_cat', 'mean_util_pct', 'mean_open_to_buy']\n",
    "# ,['tot_amt_ratio_q4_q1', 'mean_util_pct', 'age']\n",
    "# ,['tot_amt_ratio_q4_q1', 'mean_util_pct', 'mean_open_to_buy']\n",
    "# ,['tot_amt_ratio_q4_q1', 'tot_trans_cnt_for_12m', 'mean_open_to_buy']\n",
    "# ,['mean_util_pct', 'age', 'mean_open_to_buy']\n",
    "# ,['sex', 'imcome_cat', 'age', 'mean_open_to_buy']\n",
    "# ,['sex', 'mean_util_pct', 'age', 'mean_open_to_buy']\n",
    "# ,['tot_amt_ratio_q4_q1', 'mean_util_pct', 'age', 'mean_open_to_buy']\n",
    "# ,['sex', 'imcome_cat', 'mean_util_pct', 'age', 'mean_open_to_buy']\n",
    "# ]\n",
    "\n",
    "ml_churner_df = pd.read_csv(\"./data/bank_churner.csv\")\n",
    "ml_churner_df = ml_churner_df.drop('cstno', axis=1)\n",
    "ml_churner_df = ml_churner_df.drop('sex', axis=1)\n",
    "ml_churner_df['imcome_cat']=ml_churner_df['imcome_cat'].replace({'Less than $40K':40000, '$40K - $60K':50000, '$60K - $80K':70000, '$80K - $120K':100000, '$120K +':120000, 'Unknown':63000})\n",
    "\n",
    "# ml_churner_df = ml_churner_df.groupby('age').apply(lambda x: x.fillna(x.mean(numeric_only=True)))\n",
    "ml_churner_df = ml_churner_df.fillna(ml_churner_df.mean(numeric_only=True))\n",
    "ml_churner_df.dropna(axis=0, inplace=True)\n",
    "\n",
    "# ml_churner_df = drop_null_column(ml_churner_df, 'aaa')\n",
    "after_null_drop_cnt = len(ml_churner_df)\n",
    "\n",
    "ml_churner_df, catcols = encode_onehot(ml_churner_df)  \n",
    "\n",
    "\n",
    "#We create our feature matrix and our target variable vector.\n",
    "X=ml_churner_df.drop(['is_churned'],axis=1)\n",
    "y=ml_churner_df['is_churned']\n",
    "\n",
    "X_new, selected_columns = select_feature(X, 'ExtraTrees')\n",
    "# display(selected_columns)\n",
    "\n",
    "X_train, y_train, X_test, y_test = proc_smote(X_new, y)\n",
    "X_train_org = X_train.copy()\n",
    "\n",
    "X_train, X_test = proc_normalization(X_train, X_test)    \n",
    "\n",
    "drop_no = 1\n",
    "drop_column = 'abc'\n",
    "print(f'구분: {drop_no}, X_train 건수: {len(X_new)}, X_train_SMOTE 건수: {len(X_train)}, After Drop 건수: {after_null_drop_cnt}, Drop Col:{drop_column}')\n",
    "\n",
    "# display(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
    "proc_type='P'\n",
    "fit_predict(proc_type, drop_no, model_comparison, X_train, y_train, X_test, y_test)\n",
    "\n",
    "# print_eval_result(model_comparison)\n",
    "\n",
    "\n",
    "\n",
    "# -----------\n",
    "# 평가\n",
    "# -----------\n",
    "test_df = pd.read_csv(\"./data/test_churner.csv\")\n",
    "test_df = test_df.drop('cstno', axis=1)\n",
    "\n",
    "\n",
    "test_df, catcols = encode_onehot(test_df)  \n",
    "\n",
    "    \n",
    "#We create our feature matrix and our target variable vector.\n",
    "X=test_df.drop(['is_churned'],axis=1)\n",
    "y=test_df['is_churned']\n",
    "y_test = y\n",
    "\n",
    "# display(selected_columns)\n",
    "X_new = X[selected_columns]\n",
    "\n",
    "\n",
    "X_train_temp, X_test = proc_normalization(X_train_org, X_new.values)   \n",
    "\n",
    "\n",
    "# display(X_test.shape)\n",
    "\n",
    "# display(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
    "proc_type='E'\n",
    "fit_predict(proc_type, drop_no, model_eval_comparison, X_train, y_train, X_test, y_test)\n",
    "\n",
    "# print_eval_result(model_eval_comparison)\n",
    "print('종료')\n",
    "print('-'*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_eval_result(model_comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_eval_result(model_eval_comparison)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 최종 테스트 데이터로 평가\n",
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 평가(학습 및 예측 결과)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 메인 처리 for 평가"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 고객 이탈 예측 분석\n",
    "LightGBM은 91%의 가장 높은 Attrited Customer Recall과 89%의 정밀도를 가지고 있음\n",
    "고객 이탈을 사전에 방지하기 위해서 LightGBM 모델을 사용하는 것이 적합함"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
