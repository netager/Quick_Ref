{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JBFG Data Analysis Competition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# #!pip install watermark\n",
    "# %load_ext watermark\n",
    "# %watermark -a 'DataLine' -nmv --packages numpy,pandas,sklearn,imblearn,tensorflow,plotly,matplotlib,seaborn,missingno,lightgbm\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 컬럼 데이터 및 Null 건수 확인"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning\n",
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "import time\n",
    "import datetime\n",
    "import joblib\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\n",
    "from lightgbm import LGBMClassifier, LGBMRegressor\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, GridSearchCV"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function Definition"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### encode_onehot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원-핫 인코딩 처리 \n",
    "# ----------------\n",
    "def encode_onehot(df):\n",
    "    '''\n",
    "        데이터프레임의 object type 컬럼을 원-핫 인코딩하는 함수\n",
    "        \n",
    "        Args:\n",
    "            df (df) : DataFrame\n",
    "        Return:\n",
    "            DataFrame\n",
    "    '''\n",
    "    catcols = df.select_dtypes(exclude = ['int64','float64']).columns\n",
    "    df = pd.get_dummies(df, columns = catcols)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### proc_split_smote()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def proc_split_smote(X_new, y):\n",
    "    #Model Training\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from imblearn.over_sampling import SMOTE\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size=0.25, stratify=y, random_state=0)\n",
    "\n",
    "    sm = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "    X_train, y_train=sm.fit_resample(X_train,y_train)\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### proc_feature_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proc_feature_split(X_new, y):\n",
    "    #Model Training\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from imblearn.over_sampling import SMOTE\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size=0.25, stratify=y, random_state=0)\n",
    "\n",
    "    sm = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "    X_train, y_train=sm.fit_resample(X_train,y_train)\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### proc_standardization() - 표준화 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "def proc_standardization(X_train, X_test, X_eval):\n",
    "    scaler  = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test  = scaler.transform(X_test)\n",
    "    X_eval  = scaler.transform(X_eval)\n",
    "    \n",
    "    return X_train, X_test, X_eval"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### select_feature()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 중요 Feature 식별\n",
    "# ----------------\n",
    "def select_feature(df, y_labels, chosen_model):\n",
    "\n",
    "    np.random.seed(42)    \n",
    "    \n",
    "    available_models = {\n",
    "    'ExtraTrees': ExtraTreesClassifier(n_estimators=700),\n",
    "    'RandomForest': RandomForestClassifier(n_estimators=700),\n",
    "    'LGBMC': LGBMClassifier(n_estimators=700, random_state=42, boosting_type='GOSS'),\n",
    "    'LGBMR': LGBMRegressor(),\n",
    "    'Xg Boost':XGBClassifier(booster='gbtree', importance_type='gain', eval_metric='auc'),\n",
    "    }\n",
    "\n",
    "    # Create the selected model\n",
    "    clf = available_models[chosen_model]\n",
    "\n",
    "    clf = clf.fit(df, y_labels)                                     # Train\n",
    "\n",
    "    if chosen_model == 'LGBMC' or chosen_model == 'LGBMR': \n",
    "        feature_importances = clf.booster_.feature_importance(importance_type=\"gain\")\n",
    "    else:        \n",
    "        feature_importances = clf.feature_importances_\n",
    "\n",
    "\n",
    "    chosen_model = SelectFromModel(clf, prefit=True)\n",
    "    X_df = chosen_model.transform(df.values) \n",
    "    selected_feature_indices = chosen_model.get_support(indices=True)\n",
    "\n",
    "    selected_columns = df.columns[selected_feature_indices]         # Get the indices of the selected features\n",
    "    \n",
    "    return X_df, selected_columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### fit_predict_eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 예측 및 평가\n",
    "# -----------\n",
    "def fit_predict_eval(models, model_comparison, X_train, y_train, X_test, y_test):\n",
    "   \n",
    "    # 초기화\n",
    "    # ------\n",
    "    best_roc_auc = 0\n",
    "    \n",
    "    # Define Models\n",
    "    # ------------- \n",
    "    # No: 1 origin\n",
    "    # models = [\n",
    "    #     ('LogisticRegression', LogisticRegression()),\n",
    "    #     ('DecisionTree', DecisionTreeClassifier(criterion='entropy', random_state=0)),\n",
    "    #     ('ExtraTrees', ExtraTreesClassifier(n_estimators=700)),\n",
    "    #     ('KNN', KNeighborsClassifier(n_neighbors=5)),\n",
    "    #     ('NaiveBayes', GaussianNB()),\n",
    "    #     ('RandomForest', RandomForestClassifier(n_estimators=700, criterion='entropy', random_state=0)),\n",
    "    #     ('LightGBM', LGBMClassifier(n_estimators=700, random_state=42, boosting_type='GOSS')),\n",
    "    #     ('XgBoost', XGBClassifier(n_estimators=700, random_state=42, eval_metric='auc')),\n",
    "    # ]\n",
    "\n",
    "    \n",
    "    # Model Fit and Testing\n",
    "    # ---------------------\n",
    "    for model_name, classifier in models:\n",
    "        start_time = time.time()\n",
    "\n",
    "\n",
    "        # 학습\n",
    "        # ----            \n",
    "        classifier.fit(X_train, y_train)\n",
    "        \n",
    "        \n",
    "        # 학습된 모델 저장하기 - 필요한 경우 향후 사용할 예정\n",
    "        # -----------------------------------------------\n",
    "        # file_name = f'./models/{model_name}.pkl'\n",
    "        # joblib.dump(classifier, file_name)\n",
    "\n",
    "\n",
    "        # 예측\n",
    "        # ---- \n",
    "        y_pred = classifier.predict(X_test)\n",
    "\n",
    "\n",
    "        # 평가\n",
    "        # ---- \n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        accuracy_class_0 = accuracy_score(y_test[y_test == 0], y_pred[y_test == 0])\n",
    "        accuracy_class_1 = accuracy_score(y_test[y_test == 1], y_pred[y_test == 1], )\n",
    "\n",
    "        precision = precision_score(y_test , y_pred)\n",
    "        recall = recall_score(y_test , y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        \n",
    "        skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "        auces = cross_val_score(estimator=classifier, X=X_train, y=y_train, cv=skf, scoring=\"roc_auc\")\n",
    "        cv_auc = auces.mean()\n",
    "        cv_std = auces.std()\n",
    "        \n",
    "        pred_proba = classifier.predict_proba(X_test)[:, 1]        \n",
    "        roc_auc = roc_auc_score(y_test, pred_proba)\n",
    "        \n",
    "        \n",
    "        # 예측 평가 결과 저장\n",
    "        # -----------------\n",
    "        model_comparison[f'{model_name}'] = [accuracy, accuracy_class_0, accuracy_class_1, precision, recall, f1, cv_auc, cv_std, roc_auc]\n",
    "        \n",
    "        \n",
    "        # Best ROC_AUC Value Return\n",
    "        # -------------------------\n",
    "        if roc_auc > best_roc_auc:\n",
    "            best_roc_auc = roc_auc\n",
    "            \n",
    "        \n",
    "        # Print Log\n",
    "        # ---------    \n",
    "        cur_datetime = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "        end_time = time.time()\n",
    "        delta_time = end_time - start_time\n",
    "        print(f'Model Name: [{model_name:<18}], {cur_datetime}, {str(datetime.timedelta(seconds=delta_time)).split(\".\")[0]},  BEST AUC: {best_roc_auc:0.6f}, AUC: {roc_auc:0.6f}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### print_eval_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_eval_result(model_comparison):\n",
    "\n",
    "    # # MODEL COMPARISSON\n",
    "    # Model_com_df=pd.DataFrame(model_comparison).T\n",
    "    # Model_com_df.columns=['Accuracy','Accuracy-0','Accuracy-1', 'Precision', 'Recall', 'F1-Score','CV AUC','CV std', 'AUC']\n",
    "    # Model_com_df=Model_com_df.sort_values(by='AUC',ascending=False)\n",
    "    # # display(Model_com_df.style.format(\"{:.2%}\").background_gradient(cmap='magma'))\n",
    "\n",
    "    Model_com_df = pd.DataFrame(model_comparison).T\n",
    "    Model_com_df.columns = ['Accuracy', 'Accuracy-No', 'Accuracy-Yes', 'Precision', 'Recall', 'F1-Score', 'CV AUC', 'CV std', 'AUC']\n",
    "    Model_com_df = Model_com_df.sort_values(by='AUC', ascending=False)\n",
    "\n",
    "    def highlight_below_75(s):\n",
    "        if s.name != 'CV std' and isinstance(s, pd.Series) and s.dtype == 'float64':\n",
    "            return ['color: red' if value < 0.75 else 'color: black' for value in s]\n",
    "        else:\n",
    "            return ['color: black'] * len(s)\n",
    "\n",
    "    # styled_df = Model_com_df.iloc[:10,:].style.highlight_max(axis=0).apply(highlight_below_75, subset=pd.IndexSlice[:, :'CV AUC']).format(\"{:.2%}\", subset=pd.IndexSlice[:, :'CV AUC'])\n",
    "    styled_df = Model_com_df.style.highlight_max(axis=0).apply(highlight_below_75, subset=pd.IndexSlice[:, :'CV AUC']).format(\"{:.2%}\", subset=pd.IndexSlice[:, :'CV AUC'])\n",
    "    display(styled_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### data_transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def data_transform(df):\n",
    "\n",
    "    # 데이터 변환\n",
    "    # ------------------- \n",
    "    df = df.drop('cstno', axis=1)\n",
    "    df = df.drop('sex', axis=1)\n",
    "    df['imcome_cat']=df['imcome_cat'].replace({'Less than $40K':40000, '$40K - $60K':50000, '$60K - $80K':70000, '$80K - $120K':100000, '$120K +':120000, 'Unknown':63000})\n",
    "\n",
    "   \n",
    "    # 결측치 처리\n",
    "    # ----------\n",
    "    df = df.groupby(['marital_stat']).apply(lambda x: x.fillna(x.mean(numeric_only=True)))\n",
    "    df = df.reset_index(drop=True)\n",
    "    df.dropna(axis=0, inplace=True)\n",
    "\n",
    "\n",
    "    # One-Hot Encoding\n",
    "    # ----------------\n",
    "    df = encode_onehot(df)     \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test_transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_transform(source_df, eval_df):\n",
    "\n",
    "    # 데이터 변환\n",
    "    # -----------\n",
    "    source_df = data_transform(source_df)\n",
    "    eval_df = data_transform(eval_df)\n",
    "\n",
    "        \n",
    "    # 테스트 및 평가를 위한 데이터 분리\n",
    "    # -------------------------------\n",
    "    X_Features = source_df.drop(['is_churned'], axis=1)\n",
    "    y_labels = source_df['is_churned']\n",
    "\n",
    "    X_eval=eval_df.drop(['is_churned'], axis=1)\n",
    "    y_eval=eval_df['is_churned'].values\n",
    "\n",
    "\n",
    "    # 중요 Feature Column 선택\n",
    "    # -----------------------\n",
    "    X_Features_new, selected_columns = select_feature(X_Features, y_labels, 'RandomForest')\n",
    "    X_eval = X_eval[selected_columns]\n",
    "\n",
    "\n",
    "    # Train and Test 데이터 생성 및 가공\n",
    "    # ---------------------------------\n",
    "    X_train, y_train, X_test, y_test = proc_split_smote(X_Features_new, y_labels.values)\n",
    "    \n",
    "\n",
    "    # standardization ~ StandardScaler 적용\n",
    "    # -----------------------------------\n",
    "    X_train, X_test, X_eval = proc_standardization(X_train, X_test, X_eval.values) \n",
    "    \n",
    "    return X_train, y_train, X_test, y_test, X_eval, y_eval \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습 및 Test 평가"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터 로딩 및 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 경진대회를 위해 주최측에서 제공한 데이터(EDA 및 ML 학습을 위한 데이터)\n",
    "bank_churner_df = pd.read_csv(\"./data/bank_churner.csv\")\n",
    "\n",
    "\n",
    " # 평가를 위한 데이터 로드 - 평가자님 평가데이터 경로를 입력해 주세요!!! - 평가 결과는 평가결과 출력을 확인\n",
    "eval_churner_df = pd.read_csv(\"./data/eval_churner.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 초기화 및 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# 평가결과 저장소 초기화\n",
    "# --------------------\n",
    "model_test_comparison = {}                        \n",
    "model_eval_comparison = {}                        \n",
    "\n",
    "\n",
    "# 사용할 모델 정의\n",
    "models = [\n",
    "    # ('LogisticRegression', LogisticRegression(random_state=42)),\n",
    "    # ('DecisionTree', DecisionTreeClassifier(criterion='entropy', random_state=42)),\n",
    "    # ('ExtraTrees', ExtraTreesClassifier(n_estimators=700, random_state=42)),\n",
    "    # ('RandomForest', RandomForestClassifier(n_estimators=700, criterion='entropy', random_state=42)),\n",
    "    # ('KNN', KNeighborsClassifier(n_neighbors=5)),\n",
    "    # ('NaiveBayes', GaussianNB()),\n",
    "    ('LightGBM', LGBMClassifier(n_estimators=700, random_state=42, boosting_type='GOSS')),\n",
    "    ('XgBoost', XGBClassifier(n_estimators=700, random_state=42, eval_metric='auc')),\n",
    "    # ('XgBoost', XGBClassifier(n_estimators=700, random_state=42, eval_metric='auc')),\n",
    "    # ('LightGBM', LGBMClassifier(n_estimators=700, random_state=42, boosting_type='GOSS')),\n",
    "    \n",
    "]\n",
    "\n",
    "# 전처리 \n",
    "# -----\n",
    "X_train, y_train, X_test, y_test, X_eval, y_eval = test_transform(bank_churner_df, eval_churner_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 예측 및 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Name: [LightGBM          ], 2023-09-20 22:32:38, 0:00:04,  BEST AUC: 0.973968, AUC: 0.973968\n",
      "Model Name: [XgBoost           ], 2023-09-20 22:32:49, 0:00:10,  BEST AUC: 0.973968, AUC: 0.969663\n"
     ]
    }
   ],
   "source": [
    "# Pridict 및 Test 평가\n",
    "# --------------------\n",
    "fit_predict_eval(models, model_test_comparison, X_train, y_train, X_test, y_test)\n",
    "\n",
    "# print_eval_result(model_test_comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_070e8_row0_col0, #T_070e8_row0_col1, #T_070e8_row0_col2, #T_070e8_row0_col3, #T_070e8_row0_col4, #T_070e8_row0_col5, #T_070e8_row0_col6 {\n",
       "  background-color: yellow;\n",
       "  color: black;\n",
       "}\n",
       "#T_070e8_row0_col7, #T_070e8_row0_col8 {\n",
       "  background-color: yellow;\n",
       "}\n",
       "#T_070e8_row1_col0, #T_070e8_row1_col1, #T_070e8_row1_col2, #T_070e8_row1_col3, #T_070e8_row1_col4, #T_070e8_row1_col5, #T_070e8_row1_col6 {\n",
       "  color: black;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_070e8\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_070e8_level0_col0\" class=\"col_heading level0 col0\" >Accuracy</th>\n",
       "      <th id=\"T_070e8_level0_col1\" class=\"col_heading level0 col1\" >Accuracy-No</th>\n",
       "      <th id=\"T_070e8_level0_col2\" class=\"col_heading level0 col2\" >Accuracy-Yes</th>\n",
       "      <th id=\"T_070e8_level0_col3\" class=\"col_heading level0 col3\" >Precision</th>\n",
       "      <th id=\"T_070e8_level0_col4\" class=\"col_heading level0 col4\" >Recall</th>\n",
       "      <th id=\"T_070e8_level0_col5\" class=\"col_heading level0 col5\" >F1-Score</th>\n",
       "      <th id=\"T_070e8_level0_col6\" class=\"col_heading level0 col6\" >CV AUC</th>\n",
       "      <th id=\"T_070e8_level0_col7\" class=\"col_heading level0 col7\" >CV std</th>\n",
       "      <th id=\"T_070e8_level0_col8\" class=\"col_heading level0 col8\" >AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_070e8_level0_row0\" class=\"row_heading level0 row0\" >LightGBM</th>\n",
       "      <td id=\"T_070e8_row0_col0\" class=\"data row0 col0\" >94.47%</td>\n",
       "      <td id=\"T_070e8_row0_col1\" class=\"data row0 col1\" >97.47%</td>\n",
       "      <td id=\"T_070e8_row0_col2\" class=\"data row0 col2\" >78.77%</td>\n",
       "      <td id=\"T_070e8_row0_col3\" class=\"data row0 col3\" >85.62%</td>\n",
       "      <td id=\"T_070e8_row0_col4\" class=\"data row0 col4\" >78.77%</td>\n",
       "      <td id=\"T_070e8_row0_col5\" class=\"data row0 col5\" >82.05%</td>\n",
       "      <td id=\"T_070e8_row0_col6\" class=\"data row0 col6\" >99.65%</td>\n",
       "      <td id=\"T_070e8_row0_col7\" class=\"data row0 col7\" >0.000764</td>\n",
       "      <td id=\"T_070e8_row0_col8\" class=\"data row0 col8\" >0.973968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_070e8_level0_row1\" class=\"row_heading level0 row1\" >XgBoost</th>\n",
       "      <td id=\"T_070e8_row1_col0\" class=\"data row1 col0\" >93.78%</td>\n",
       "      <td id=\"T_070e8_row1_col1\" class=\"data row1 col1\" >97.30%</td>\n",
       "      <td id=\"T_070e8_row1_col2\" class=\"data row1 col2\" >75.38%</td>\n",
       "      <td id=\"T_070e8_row1_col3\" class=\"data row1 col3\" >84.19%</td>\n",
       "      <td id=\"T_070e8_row1_col4\" class=\"data row1 col4\" >75.38%</td>\n",
       "      <td id=\"T_070e8_row1_col5\" class=\"data row1 col5\" >79.55%</td>\n",
       "      <td id=\"T_070e8_row1_col6\" class=\"data row1 col6\" >99.56%</td>\n",
       "      <td id=\"T_070e8_row1_col7\" class=\"data row1 col7\" >0.000744</td>\n",
       "      <td id=\"T_070e8_row1_col8\" class=\"data row1 col8\" >0.969663</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x26e157b1370>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_eval_result(model_test_comparison)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 평가자 확인 - Hidden Data 적용 후 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Name: [LightGBM          ], 2023-09-20 22:32:52, 0:00:03,  BEST AUC: 0.991247, AUC: 0.991247\n",
      "Model Name: [XgBoost           ], 2023-09-20 22:33:04, 0:00:11,  BEST AUC: 0.991247, AUC: 0.988054\n"
     ]
    }
   ],
   "source": [
    "# 예측 및 평가 수행\n",
    "fit_predict_eval(models, model_eval_comparison, X_train, y_train, X_eval, y_eval)\n",
    "\n",
    "# print_eval_result(model_eval_comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_7bba9_row0_col0, #T_7bba9_row0_col1, #T_7bba9_row0_col2, #T_7bba9_row0_col3, #T_7bba9_row0_col4, #T_7bba9_row0_col5, #T_7bba9_row0_col6 {\n",
       "  background-color: yellow;\n",
       "  color: black;\n",
       "}\n",
       "#T_7bba9_row0_col7, #T_7bba9_row0_col8 {\n",
       "  background-color: yellow;\n",
       "}\n",
       "#T_7bba9_row1_col0, #T_7bba9_row1_col1, #T_7bba9_row1_col2, #T_7bba9_row1_col3, #T_7bba9_row1_col4, #T_7bba9_row1_col5, #T_7bba9_row1_col6 {\n",
       "  color: black;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_7bba9\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_7bba9_level0_col0\" class=\"col_heading level0 col0\" >Accuracy</th>\n",
       "      <th id=\"T_7bba9_level0_col1\" class=\"col_heading level0 col1\" >Accuracy-No</th>\n",
       "      <th id=\"T_7bba9_level0_col2\" class=\"col_heading level0 col2\" >Accuracy-Yes</th>\n",
       "      <th id=\"T_7bba9_level0_col3\" class=\"col_heading level0 col3\" >Precision</th>\n",
       "      <th id=\"T_7bba9_level0_col4\" class=\"col_heading level0 col4\" >Recall</th>\n",
       "      <th id=\"T_7bba9_level0_col5\" class=\"col_heading level0 col5\" >F1-Score</th>\n",
       "      <th id=\"T_7bba9_level0_col6\" class=\"col_heading level0 col6\" >CV AUC</th>\n",
       "      <th id=\"T_7bba9_level0_col7\" class=\"col_heading level0 col7\" >CV std</th>\n",
       "      <th id=\"T_7bba9_level0_col8\" class=\"col_heading level0 col8\" >AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_7bba9_level0_row0\" class=\"row_heading level0 row0\" >LightGBM</th>\n",
       "      <td id=\"T_7bba9_row0_col0\" class=\"data row0 col0\" >96.69%</td>\n",
       "      <td id=\"T_7bba9_row0_col1\" class=\"data row0 col1\" >98.00%</td>\n",
       "      <td id=\"T_7bba9_row0_col2\" class=\"data row0 col2\" >89.91%</td>\n",
       "      <td id=\"T_7bba9_row0_col3\" class=\"data row0 col3\" >89.63%</td>\n",
       "      <td id=\"T_7bba9_row0_col4\" class=\"data row0 col4\" >89.91%</td>\n",
       "      <td id=\"T_7bba9_row0_col5\" class=\"data row0 col5\" >89.77%</td>\n",
       "      <td id=\"T_7bba9_row0_col6\" class=\"data row0 col6\" >99.65%</td>\n",
       "      <td id=\"T_7bba9_row0_col7\" class=\"data row0 col7\" >0.000764</td>\n",
       "      <td id=\"T_7bba9_row0_col8\" class=\"data row0 col8\" >0.991247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7bba9_level0_row1\" class=\"row_heading level0 row1\" >XgBoost</th>\n",
       "      <td id=\"T_7bba9_row1_col0\" class=\"data row1 col0\" >95.90%</td>\n",
       "      <td id=\"T_7bba9_row1_col1\" class=\"data row1 col1\" >97.29%</td>\n",
       "      <td id=\"T_7bba9_row1_col2\" class=\"data row1 col2\" >88.69%</td>\n",
       "      <td id=\"T_7bba9_row1_col3\" class=\"data row1 col3\" >86.31%</td>\n",
       "      <td id=\"T_7bba9_row1_col4\" class=\"data row1 col4\" >88.69%</td>\n",
       "      <td id=\"T_7bba9_row1_col5\" class=\"data row1 col5\" >87.48%</td>\n",
       "      <td id=\"T_7bba9_row1_col6\" class=\"data row1 col6\" >99.56%</td>\n",
       "      <td id=\"T_7bba9_row1_col7\" class=\"data row1 col7\" >0.000744</td>\n",
       "      <td id=\"T_7bba9_row1_col8\" class=\"data row1 col8\" >0.988054</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x26e1580beb0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_eval_result(model_eval_comparison)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 전처리 방법 및 각종 튜닝값 적용을 위한 상세 테스트"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Machine Learning시 중요 컬럼 선택 관련 Classifier 선택\n",
    "- ExtraTrees, RandomForest 사용시 다른 Classifier 보다 좋은 결과를 보여서 RandomForest 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_feature_model():\n",
    "    models = ['ExtraTrees', 'RandomForest', 'LGBMC', 'LGBMR', 'Xg Boost']\n",
    "    for model in models: \n",
    "        start_time = time.time()\n",
    "\n",
    "        bank_churner_df = pd.read_csv(\"./data/bank_churner.csv\")        \n",
    "        eval_churner_df = pd.read_csv(\"./data/test_churner.csv\")\n",
    "\n",
    "\n",
    "        # 데이터 변환\n",
    "        # -----------\n",
    "        bank_churner_df = data_transform(bank_churner_df)\n",
    "        eval_churner_df = data_transform(eval_churner_df)\n",
    "\n",
    "\n",
    "        # 테스트 및 평가를 위한 데이터 분리\n",
    "        # -------------------------------\n",
    "        X_Features = bank_churner_df.drop(['is_churned'],axis=1)\n",
    "        y_labels = bank_churner_df['is_churned']\n",
    "\n",
    "        X_eval=eval_churner_df.drop(['is_churned'],axis=1)\n",
    "        y_eval=eval_churner_df['is_churned']\n",
    "\n",
    "\n",
    "        # 중요 Feature Column 선택\n",
    "        # -----------------------\n",
    "        X_Features_new, selected_columns = select_feature(X_Features, y_labels, model)\n",
    "        X_eval = X_eval[selected_columns]\n",
    "        \n",
    "\n",
    "        # 로그 출력\n",
    "        # --------\n",
    "        cur_datetime = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "        end_time = time.time()\n",
    "        delta_time = end_time - start_time\n",
    "        \n",
    "        # print(f'{cur_datetime}, {str(datetime.timedelta(seconds=delta_time)).split(\".\")[0]}, model: {model}, X_Features_new: {X_Features_new.shape}, X_eval: {X_eval.shape}, selected_columns_len: {len(selected_columns)}, selected_columns: {selected_columns}')\n",
    "        print(f'{cur_datetime}, {str(datetime.timedelta(seconds=delta_time)).split(\".\")[0]}, model: {model}, X_Features_new: {X_Features_new.shape}, X_eval: {X_eval.shape}, selected_columns_len: {len(selected_columns)}')\n",
    "\n",
    "# select_feature_model()    \n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Light GBM 파라미터 튜닝\n",
    "- Light GBM을 이용한 경우 좋은 결과가 있어 파라미터 튜닝을 세부적으로 수행 함.\n",
    "    - 튜닝 파라미터 결과 : learning_rate: 0.14061, max_depth: 106, min_child_samples: 64, num_leaves: 41, 'subsample': 0.94623\n",
    "- 튜닝을 진행했지만 이전보다 좋은 결과가 나오지 않음\n",
    "    - 튜닝 적용후 ROC AUC: 0.9892"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Best 튜닝 파라미터 적용하여 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's auc: 0.947246\ttraining's binary_logloss: 0.606997\tvalid_1's auc: 0.874619\tvalid_1's binary_logloss: 0.617885\n",
      "[2]\ttraining's auc: 0.954415\ttraining's binary_logloss: 0.540712\tvalid_1's auc: 0.886997\tvalid_1's binary_logloss: 0.560624\n",
      "[3]\ttraining's auc: 0.966035\ttraining's binary_logloss: 0.484324\tvalid_1's auc: 0.896198\tvalid_1's binary_logloss: 0.51372\n",
      "[4]\ttraining's auc: 0.972323\ttraining's binary_logloss: 0.43683\tvalid_1's auc: 0.90156\tvalid_1's binary_logloss: 0.474998\n",
      "[5]\ttraining's auc: 0.976108\ttraining's binary_logloss: 0.398234\tvalid_1's auc: 0.907363\tvalid_1's binary_logloss: 0.442518\n",
      "[6]\ttraining's auc: 0.980323\ttraining's binary_logloss: 0.361964\tvalid_1's auc: 0.914306\tvalid_1's binary_logloss: 0.411141\n",
      "[7]\ttraining's auc: 0.981715\ttraining's binary_logloss: 0.33415\tvalid_1's auc: 0.915475\tvalid_1's binary_logloss: 0.388344\n",
      "[8]\ttraining's auc: 0.983032\ttraining's binary_logloss: 0.309046\tvalid_1's auc: 0.916774\tvalid_1's binary_logloss: 0.367435\n",
      "[9]\ttraining's auc: 0.984475\ttraining's binary_logloss: 0.287502\tvalid_1's auc: 0.919848\tvalid_1's binary_logloss: 0.349682\n",
      "[10]\ttraining's auc: 0.98667\ttraining's binary_logloss: 0.266846\tvalid_1's auc: 0.929547\tvalid_1's binary_logloss: 0.330441\n",
      "[11]\ttraining's auc: 0.988273\ttraining's binary_logloss: 0.248174\tvalid_1's auc: 0.931304\tvalid_1's binary_logloss: 0.316052\n",
      "[12]\ttraining's auc: 0.989474\ttraining's binary_logloss: 0.233282\tvalid_1's auc: 0.932781\tvalid_1's binary_logloss: 0.304647\n",
      "[13]\ttraining's auc: 0.990297\ttraining's binary_logloss: 0.218713\tvalid_1's auc: 0.934448\tvalid_1's binary_logloss: 0.292916\n",
      "[14]\ttraining's auc: 0.991049\ttraining's binary_logloss: 0.206788\tvalid_1's auc: 0.936095\tvalid_1's binary_logloss: 0.283212\n",
      "[15]\ttraining's auc: 0.992143\ttraining's binary_logloss: 0.19314\tvalid_1's auc: 0.941116\tvalid_1's binary_logloss: 0.270831\n",
      "[16]\ttraining's auc: 0.993223\ttraining's binary_logloss: 0.179707\tvalid_1's auc: 0.946912\tvalid_1's binary_logloss: 0.2578\n",
      "[17]\ttraining's auc: 0.993886\ttraining's binary_logloss: 0.168883\tvalid_1's auc: 0.948639\tvalid_1's binary_logloss: 0.249319\n",
      "[18]\ttraining's auc: 0.994378\ttraining's binary_logloss: 0.159742\tvalid_1's auc: 0.951223\tvalid_1's binary_logloss: 0.240701\n",
      "[19]\ttraining's auc: 0.994843\ttraining's binary_logloss: 0.151114\tvalid_1's auc: 0.952564\tvalid_1's binary_logloss: 0.233409\n",
      "[20]\ttraining's auc: 0.995291\ttraining's binary_logloss: 0.142672\tvalid_1's auc: 0.954754\tvalid_1's binary_logloss: 0.225656\n",
      "[21]\ttraining's auc: 0.995654\ttraining's binary_logloss: 0.135419\tvalid_1's auc: 0.955773\tvalid_1's binary_logloss: 0.220085\n",
      "[22]\ttraining's auc: 0.995912\ttraining's binary_logloss: 0.129673\tvalid_1's auc: 0.95712\tvalid_1's binary_logloss: 0.215346\n",
      "[23]\ttraining's auc: 0.996205\ttraining's binary_logloss: 0.123573\tvalid_1's auc: 0.957918\tvalid_1's binary_logloss: 0.210333\n",
      "[24]\ttraining's auc: 0.996596\ttraining's binary_logloss: 0.11683\tvalid_1's auc: 0.95907\tvalid_1's binary_logloss: 0.205625\n",
      "[25]\ttraining's auc: 0.996909\ttraining's binary_logloss: 0.110727\tvalid_1's auc: 0.960387\tvalid_1's binary_logloss: 0.200326\n",
      "[26]\ttraining's auc: 0.997182\ttraining's binary_logloss: 0.105486\tvalid_1's auc: 0.962176\tvalid_1's binary_logloss: 0.1951\n",
      "[27]\ttraining's auc: 0.997397\ttraining's binary_logloss: 0.100973\tvalid_1's auc: 0.962838\tvalid_1's binary_logloss: 0.191595\n",
      "[28]\ttraining's auc: 0.997603\ttraining's binary_logloss: 0.0963879\tvalid_1's auc: 0.963238\tvalid_1's binary_logloss: 0.188969\n",
      "[29]\ttraining's auc: 0.997788\ttraining's binary_logloss: 0.0921636\tvalid_1's auc: 0.964338\tvalid_1's binary_logloss: 0.185227\n",
      "[30]\ttraining's auc: 0.997959\ttraining's binary_logloss: 0.0883221\tvalid_1's auc: 0.965112\tvalid_1's binary_logloss: 0.182156\n",
      "[31]\ttraining's auc: 0.998159\ttraining's binary_logloss: 0.0843875\tvalid_1's auc: 0.965895\tvalid_1's binary_logloss: 0.178901\n",
      "[32]\ttraining's auc: 0.998297\ttraining's binary_logloss: 0.0811944\tvalid_1's auc: 0.966684\tvalid_1's binary_logloss: 0.176483\n",
      "[33]\ttraining's auc: 0.998426\ttraining's binary_logloss: 0.0781379\tvalid_1's auc: 0.967319\tvalid_1's binary_logloss: 0.174182\n",
      "[34]\ttraining's auc: 0.998557\ttraining's binary_logloss: 0.0752805\tvalid_1's auc: 0.967908\tvalid_1's binary_logloss: 0.171846\n",
      "[35]\ttraining's auc: 0.998667\ttraining's binary_logloss: 0.0726844\tvalid_1's auc: 0.968308\tvalid_1's binary_logloss: 0.170197\n",
      "[36]\ttraining's auc: 0.998769\ttraining's binary_logloss: 0.0701982\tvalid_1's auc: 0.968887\tvalid_1's binary_logloss: 0.16827\n",
      "[37]\ttraining's auc: 0.998855\ttraining's binary_logloss: 0.0677051\tvalid_1's auc: 0.96943\tvalid_1's binary_logloss: 0.166039\n",
      "[38]\ttraining's auc: 0.998964\ttraining's binary_logloss: 0.0652674\tvalid_1's auc: 0.969772\tvalid_1's binary_logloss: 0.164433\n",
      "[39]\ttraining's auc: 0.999073\ttraining's binary_logloss: 0.0626461\tvalid_1's auc: 0.969953\tvalid_1's binary_logloss: 0.163111\n",
      "[40]\ttraining's auc: 0.999138\ttraining's binary_logloss: 0.0608223\tvalid_1's auc: 0.969972\tvalid_1's binary_logloss: 0.162315\n",
      "[41]\ttraining's auc: 0.999206\ttraining's binary_logloss: 0.0588584\tvalid_1's auc: 0.97028\tvalid_1's binary_logloss: 0.160823\n",
      "[42]\ttraining's auc: 0.999267\ttraining's binary_logloss: 0.0572143\tvalid_1's auc: 0.970428\tvalid_1's binary_logloss: 0.159737\n",
      "[43]\ttraining's auc: 0.999303\ttraining's binary_logloss: 0.0555383\tvalid_1's auc: 0.970727\tvalid_1's binary_logloss: 0.158616\n",
      "[44]\ttraining's auc: 0.999353\ttraining's binary_logloss: 0.0536517\tvalid_1's auc: 0.970781\tvalid_1's binary_logloss: 0.15799\n",
      "[45]\ttraining's auc: 0.999398\ttraining's binary_logloss: 0.0520058\tvalid_1's auc: 0.971112\tvalid_1's binary_logloss: 0.157014\n",
      "[46]\ttraining's auc: 0.999435\ttraining's binary_logloss: 0.0505508\tvalid_1's auc: 0.971675\tvalid_1's binary_logloss: 0.155339\n",
      "[47]\ttraining's auc: 0.999501\ttraining's binary_logloss: 0.0490968\tvalid_1's auc: 0.971881\tvalid_1's binary_logloss: 0.154634\n",
      "[48]\ttraining's auc: 0.999528\ttraining's binary_logloss: 0.0478123\tvalid_1's auc: 0.972172\tvalid_1's binary_logloss: 0.153909\n",
      "[49]\ttraining's auc: 0.999575\ttraining's binary_logloss: 0.0463266\tvalid_1's auc: 0.972414\tvalid_1's binary_logloss: 0.153111\n",
      "[50]\ttraining's auc: 0.999613\ttraining's binary_logloss: 0.0450448\tvalid_1's auc: 0.972387\tvalid_1's binary_logloss: 0.152951\n",
      "[51]\ttraining's auc: 0.999651\ttraining's binary_logloss: 0.0439072\tvalid_1's auc: 0.972355\tvalid_1's binary_logloss: 0.152845\n",
      "[52]\ttraining's auc: 0.999686\ttraining's binary_logloss: 0.0425149\tvalid_1's auc: 0.972548\tvalid_1's binary_logloss: 0.15205\n",
      "[53]\ttraining's auc: 0.999705\ttraining's binary_logloss: 0.0413625\tvalid_1's auc: 0.972631\tvalid_1's binary_logloss: 0.151525\n",
      "[54]\ttraining's auc: 0.999737\ttraining's binary_logloss: 0.0403173\tvalid_1's auc: 0.972802\tvalid_1's binary_logloss: 0.150782\n",
      "[55]\ttraining's auc: 0.999757\ttraining's binary_logloss: 0.0394312\tvalid_1's auc: 0.972887\tvalid_1's binary_logloss: 0.150647\n",
      "[56]\ttraining's auc: 0.999785\ttraining's binary_logloss: 0.0383018\tvalid_1's auc: 0.972932\tvalid_1's binary_logloss: 0.150231\n",
      "[57]\ttraining's auc: 0.999807\ttraining's binary_logloss: 0.0372351\tvalid_1's auc: 0.972901\tvalid_1's binary_logloss: 0.150205\n",
      "[58]\ttraining's auc: 0.999828\ttraining's binary_logloss: 0.0362336\tvalid_1's auc: 0.972908\tvalid_1's binary_logloss: 0.150216\n",
      "[59]\ttraining's auc: 0.99985\ttraining's binary_logloss: 0.0352837\tvalid_1's auc: 0.972859\tvalid_1's binary_logloss: 0.150364\n",
      "[60]\ttraining's auc: 0.999862\ttraining's binary_logloss: 0.0342989\tvalid_1's auc: 0.972693\tvalid_1's binary_logloss: 0.150722\n",
      "[61]\ttraining's auc: 0.999877\ttraining's binary_logloss: 0.033471\tvalid_1's auc: 0.972584\tvalid_1's binary_logloss: 0.150929\n",
      "[62]\ttraining's auc: 0.999884\ttraining's binary_logloss: 0.0326933\tvalid_1's auc: 0.97265\tvalid_1's binary_logloss: 0.150949\n",
      "[63]\ttraining's auc: 0.999897\ttraining's binary_logloss: 0.0319419\tvalid_1's auc: 0.972802\tvalid_1's binary_logloss: 0.150625\n",
      "[64]\ttraining's auc: 0.999918\ttraining's binary_logloss: 0.0310714\tvalid_1's auc: 0.973004\tvalid_1's binary_logloss: 0.150323\n",
      "[65]\ttraining's auc: 0.999927\ttraining's binary_logloss: 0.0303329\tvalid_1's auc: 0.973073\tvalid_1's binary_logloss: 0.150025\n",
      "[66]\ttraining's auc: 0.999936\ttraining's binary_logloss: 0.0294322\tvalid_1's auc: 0.973087\tvalid_1's binary_logloss: 0.15012\n",
      "[67]\ttraining's auc: 0.999943\ttraining's binary_logloss: 0.0287153\tvalid_1's auc: 0.972941\tvalid_1's binary_logloss: 0.150333\n",
      "[68]\ttraining's auc: 0.999952\ttraining's binary_logloss: 0.028063\tvalid_1's auc: 0.972689\tvalid_1's binary_logloss: 0.150981\n",
      "[69]\ttraining's auc: 0.999956\ttraining's binary_logloss: 0.0274254\tvalid_1's auc: 0.972854\tvalid_1's binary_logloss: 0.150502\n",
      "[70]\ttraining's auc: 0.99996\ttraining's binary_logloss: 0.0268151\tvalid_1's auc: 0.973089\tvalid_1's binary_logloss: 0.149882\n",
      "[71]\ttraining's auc: 0.999967\ttraining's binary_logloss: 0.0261514\tvalid_1's auc: 0.973201\tvalid_1's binary_logloss: 0.150091\n",
      "[72]\ttraining's auc: 0.999972\ttraining's binary_logloss: 0.025479\tvalid_1's auc: 0.97342\tvalid_1's binary_logloss: 0.149291\n",
      "[73]\ttraining's auc: 0.999977\ttraining's binary_logloss: 0.0248132\tvalid_1's auc: 0.973592\tvalid_1's binary_logloss: 0.148854\n",
      "[74]\ttraining's auc: 0.99998\ttraining's binary_logloss: 0.0242129\tvalid_1's auc: 0.97365\tvalid_1's binary_logloss: 0.148701\n",
      "[75]\ttraining's auc: 0.999982\ttraining's binary_logloss: 0.0236679\tvalid_1's auc: 0.973941\tvalid_1's binary_logloss: 0.148134\n",
      "[76]\ttraining's auc: 0.999986\ttraining's binary_logloss: 0.0230907\tvalid_1's auc: 0.973717\tvalid_1's binary_logloss: 0.148568\n",
      "[77]\ttraining's auc: 0.999987\ttraining's binary_logloss: 0.0224995\tvalid_1's auc: 0.973619\tvalid_1's binary_logloss: 0.148755\n",
      "[78]\ttraining's auc: 0.99999\ttraining's binary_logloss: 0.022047\tvalid_1's auc: 0.973458\tvalid_1's binary_logloss: 0.149466\n",
      "[79]\ttraining's auc: 0.999991\ttraining's binary_logloss: 0.0215951\tvalid_1's auc: 0.973247\tvalid_1's binary_logloss: 0.149797\n",
      "[80]\ttraining's auc: 0.999992\ttraining's binary_logloss: 0.021046\tvalid_1's auc: 0.973154\tvalid_1's binary_logloss: 0.150023\n",
      "[81]\ttraining's auc: 0.999994\ttraining's binary_logloss: 0.0206378\tvalid_1's auc: 0.973223\tvalid_1's binary_logloss: 0.150271\n",
      "[82]\ttraining's auc: 0.999996\ttraining's binary_logloss: 0.020071\tvalid_1's auc: 0.973458\tvalid_1's binary_logloss: 0.149641\n",
      "[83]\ttraining's auc: 0.999997\ttraining's binary_logloss: 0.0196596\tvalid_1's auc: 0.973447\tvalid_1's binary_logloss: 0.149943\n",
      "[84]\ttraining's auc: 0.999997\ttraining's binary_logloss: 0.0191064\tvalid_1's auc: 0.973455\tvalid_1's binary_logloss: 0.150063\n",
      "[85]\ttraining's auc: 0.999998\ttraining's binary_logloss: 0.0186329\tvalid_1's auc: 0.973728\tvalid_1's binary_logloss: 0.149645\n",
      "[86]\ttraining's auc: 0.999998\ttraining's binary_logloss: 0.0182014\tvalid_1's auc: 0.973514\tvalid_1's binary_logloss: 0.150524\n",
      "[87]\ttraining's auc: 0.999998\ttraining's binary_logloss: 0.0177279\tvalid_1's auc: 0.973594\tvalid_1's binary_logloss: 0.150707\n",
      "[88]\ttraining's auc: 0.999998\ttraining's binary_logloss: 0.0172252\tvalid_1's auc: 0.973746\tvalid_1's binary_logloss: 0.150672\n",
      "[89]\ttraining's auc: 0.999999\ttraining's binary_logloss: 0.0168189\tvalid_1's auc: 0.973968\tvalid_1's binary_logloss: 0.150324\n",
      "[90]\ttraining's auc: 0.999999\ttraining's binary_logloss: 0.0164111\tvalid_1's auc: 0.974051\tvalid_1's binary_logloss: 0.150316\n",
      "[91]\ttraining's auc: 0.999999\ttraining's binary_logloss: 0.016067\tvalid_1's auc: 0.974093\tvalid_1's binary_logloss: 0.150628\n",
      "[92]\ttraining's auc: 0.999999\ttraining's binary_logloss: 0.0157313\tvalid_1's auc: 0.974164\tvalid_1's binary_logloss: 0.150338\n",
      "[93]\ttraining's auc: 0.999999\ttraining's binary_logloss: 0.015405\tvalid_1's auc: 0.974316\tvalid_1's binary_logloss: 0.150028\n",
      "[94]\ttraining's auc: 1\ttraining's binary_logloss: 0.0150734\tvalid_1's auc: 0.974482\tvalid_1's binary_logloss: 0.14967\n",
      "[95]\ttraining's auc: 1\ttraining's binary_logloss: 0.0147566\tvalid_1's auc: 0.974516\tvalid_1's binary_logloss: 0.149645\n",
      "[96]\ttraining's auc: 1\ttraining's binary_logloss: 0.0143896\tvalid_1's auc: 0.974571\tvalid_1's binary_logloss: 0.149855\n",
      "[97]\ttraining's auc: 1\ttraining's binary_logloss: 0.0140535\tvalid_1's auc: 0.974603\tvalid_1's binary_logloss: 0.14987\n",
      "[98]\ttraining's auc: 1\ttraining's binary_logloss: 0.0137324\tvalid_1's auc: 0.974697\tvalid_1's binary_logloss: 0.149922\n",
      "[99]\ttraining's auc: 1\ttraining's binary_logloss: 0.0133905\tvalid_1's auc: 0.974804\tvalid_1's binary_logloss: 0.149941\n",
      "[100]\ttraining's auc: 1\ttraining's binary_logloss: 0.0131006\tvalid_1's auc: 0.974988\tvalid_1's binary_logloss: 0.149798\n",
      "[101]\ttraining's auc: 1\ttraining's binary_logloss: 0.012823\tvalid_1's auc: 0.975083\tvalid_1's binary_logloss: 0.149675\n",
      "[102]\ttraining's auc: 1\ttraining's binary_logloss: 0.0125583\tvalid_1's auc: 0.97516\tvalid_1's binary_logloss: 0.150125\n",
      "[103]\ttraining's auc: 1\ttraining's binary_logloss: 0.0122704\tvalid_1's auc: 0.97514\tvalid_1's binary_logloss: 0.150282\n",
      "[104]\ttraining's auc: 1\ttraining's binary_logloss: 0.0119647\tvalid_1's auc: 0.975386\tvalid_1's binary_logloss: 0.149661\n",
      "[105]\ttraining's auc: 1\ttraining's binary_logloss: 0.0117135\tvalid_1's auc: 0.975394\tvalid_1's binary_logloss: 0.149862\n",
      "[106]\ttraining's auc: 1\ttraining's binary_logloss: 0.0114428\tvalid_1's auc: 0.975238\tvalid_1's binary_logloss: 0.15038\n",
      "[107]\ttraining's auc: 1\ttraining's binary_logloss: 0.0111597\tvalid_1's auc: 0.975329\tvalid_1's binary_logloss: 0.150363\n",
      "[108]\ttraining's auc: 1\ttraining's binary_logloss: 0.0109203\tvalid_1's auc: 0.975332\tvalid_1's binary_logloss: 0.150724\n",
      "[109]\ttraining's auc: 1\ttraining's binary_logloss: 0.010653\tvalid_1's auc: 0.975336\tvalid_1's binary_logloss: 0.151029\n",
      "[110]\ttraining's auc: 1\ttraining's binary_logloss: 0.0103988\tvalid_1's auc: 0.975236\tvalid_1's binary_logloss: 0.151646\n",
      "[111]\ttraining's auc: 1\ttraining's binary_logloss: 0.0101637\tvalid_1's auc: 0.975124\tvalid_1's binary_logloss: 0.152123\n",
      "[112]\ttraining's auc: 1\ttraining's binary_logloss: 0.00993581\tvalid_1's auc: 0.975131\tvalid_1's binary_logloss: 0.152387\n",
      "[113]\ttraining's auc: 1\ttraining's binary_logloss: 0.00970069\tvalid_1's auc: 0.975325\tvalid_1's binary_logloss: 0.151991\n",
      "[114]\ttraining's auc: 1\ttraining's binary_logloss: 0.0094808\tvalid_1's auc: 0.975216\tvalid_1's binary_logloss: 0.152732\n",
      "[115]\ttraining's auc: 1\ttraining's binary_logloss: 0.0092357\tvalid_1's auc: 0.97526\tvalid_1's binary_logloss: 0.152635\n",
      "[116]\ttraining's auc: 1\ttraining's binary_logloss: 0.00906052\tvalid_1's auc: 0.975278\tvalid_1's binary_logloss: 0.152568\n",
      "[117]\ttraining's auc: 1\ttraining's binary_logloss: 0.00886953\tvalid_1's auc: 0.975435\tvalid_1's binary_logloss: 0.15256\n",
      "[118]\ttraining's auc: 1\ttraining's binary_logloss: 0.00866003\tvalid_1's auc: 0.975567\tvalid_1's binary_logloss: 0.152482\n",
      "[119]\ttraining's auc: 1\ttraining's binary_logloss: 0.00849638\tvalid_1's auc: 0.975616\tvalid_1's binary_logloss: 0.15246\n",
      "[120]\ttraining's auc: 1\ttraining's binary_logloss: 0.00832655\tvalid_1's auc: 0.975587\tvalid_1's binary_logloss: 0.152628\n",
      "[121]\ttraining's auc: 1\ttraining's binary_logloss: 0.00812783\tvalid_1's auc: 0.97566\tvalid_1's binary_logloss: 0.152796\n",
      "[122]\ttraining's auc: 1\ttraining's binary_logloss: 0.00792884\tvalid_1's auc: 0.975473\tvalid_1's binary_logloss: 0.153546\n",
      "[123]\ttraining's auc: 1\ttraining's binary_logloss: 0.00777099\tvalid_1's auc: 0.975263\tvalid_1's binary_logloss: 0.154616\n",
      "[124]\ttraining's auc: 1\ttraining's binary_logloss: 0.00760645\tvalid_1's auc: 0.975052\tvalid_1's binary_logloss: 0.155274\n",
      "[125]\ttraining's auc: 1\ttraining's binary_logloss: 0.00745037\tvalid_1's auc: 0.975037\tvalid_1's binary_logloss: 0.155321\n",
      "[126]\ttraining's auc: 1\ttraining's binary_logloss: 0.00728707\tvalid_1's auc: 0.975137\tvalid_1's binary_logloss: 0.155183\n",
      "[127]\ttraining's auc: 1\ttraining's binary_logloss: 0.00714225\tvalid_1's auc: 0.975218\tvalid_1's binary_logloss: 0.155195\n",
      "[128]\ttraining's auc: 1\ttraining's binary_logloss: 0.00699682\tvalid_1's auc: 0.97511\tvalid_1's binary_logloss: 0.156107\n",
      "[129]\ttraining's auc: 1\ttraining's binary_logloss: 0.00685174\tvalid_1's auc: 0.974875\tvalid_1's binary_logloss: 0.156817\n",
      "[130]\ttraining's auc: 1\ttraining's binary_logloss: 0.00669731\tvalid_1's auc: 0.974867\tvalid_1's binary_logloss: 0.157066\n",
      "[131]\ttraining's auc: 1\ttraining's binary_logloss: 0.0065386\tvalid_1's auc: 0.974782\tvalid_1's binary_logloss: 0.157678\n",
      "[132]\ttraining's auc: 1\ttraining's binary_logloss: 0.00638675\tvalid_1's auc: 0.974889\tvalid_1's binary_logloss: 0.157714\n",
      "[133]\ttraining's auc: 1\ttraining's binary_logloss: 0.00625987\tvalid_1's auc: 0.974941\tvalid_1's binary_logloss: 0.157583\n",
      "[134]\ttraining's auc: 1\ttraining's binary_logloss: 0.0061156\tvalid_1's auc: 0.975034\tvalid_1's binary_logloss: 0.15751\n",
      "[135]\ttraining's auc: 1\ttraining's binary_logloss: 0.00598879\tvalid_1's auc: 0.975102\tvalid_1's binary_logloss: 0.157366\n",
      "[136]\ttraining's auc: 1\ttraining's binary_logloss: 0.005831\tvalid_1's auc: 0.975215\tvalid_1's binary_logloss: 0.15741\n",
      "[137]\ttraining's auc: 1\ttraining's binary_logloss: 0.00570097\tvalid_1's auc: 0.975081\tvalid_1's binary_logloss: 0.158236\n",
      "[138]\ttraining's auc: 1\ttraining's binary_logloss: 0.00558394\tvalid_1's auc: 0.974996\tvalid_1's binary_logloss: 0.158544\n",
      "[139]\ttraining's auc: 1\ttraining's binary_logloss: 0.00545652\tvalid_1's auc: 0.975131\tvalid_1's binary_logloss: 0.158596\n",
      "[140]\ttraining's auc: 1\ttraining's binary_logloss: 0.00535358\tvalid_1's auc: 0.975195\tvalid_1's binary_logloss: 0.159103\n",
      "[141]\ttraining's auc: 1\ttraining's binary_logloss: 0.00523959\tvalid_1's auc: 0.975383\tvalid_1's binary_logloss: 0.158886\n",
      "[142]\ttraining's auc: 1\ttraining's binary_logloss: 0.00514522\tvalid_1's auc: 0.975357\tvalid_1's binary_logloss: 0.159923\n",
      "[143]\ttraining's auc: 1\ttraining's binary_logloss: 0.00505787\tvalid_1's auc: 0.975274\tvalid_1's binary_logloss: 0.160251\n",
      "[144]\ttraining's auc: 1\ttraining's binary_logloss: 0.00494863\tvalid_1's auc: 0.975233\tvalid_1's binary_logloss: 0.160569\n",
      "[145]\ttraining's auc: 1\ttraining's binary_logloss: 0.00484055\tvalid_1's auc: 0.975242\tvalid_1's binary_logloss: 0.160782\n",
      "[146]\ttraining's auc: 1\ttraining's binary_logloss: 0.00476228\tvalid_1's auc: 0.975227\tvalid_1's binary_logloss: 0.160995\n",
      "[147]\ttraining's auc: 1\ttraining's binary_logloss: 0.00466303\tvalid_1's auc: 0.97531\tvalid_1's binary_logloss: 0.160628\n",
      "[148]\ttraining's auc: 1\ttraining's binary_logloss: 0.00456016\tvalid_1's auc: 0.975258\tvalid_1's binary_logloss: 0.160787\n",
      "[149]\ttraining's auc: 1\ttraining's binary_logloss: 0.00444127\tvalid_1's auc: 0.975262\tvalid_1's binary_logloss: 0.160928\n",
      "[150]\ttraining's auc: 1\ttraining's binary_logloss: 0.0043519\tvalid_1's auc: 0.975354\tvalid_1's binary_logloss: 0.161107\n",
      "[151]\ttraining's auc: 1\ttraining's binary_logloss: 0.00425671\tvalid_1's auc: 0.975155\tvalid_1's binary_logloss: 0.162184\n",
      "[152]\ttraining's auc: 1\ttraining's binary_logloss: 0.0041616\tvalid_1's auc: 0.975072\tvalid_1's binary_logloss: 0.163108\n",
      "[153]\ttraining's auc: 1\ttraining's binary_logloss: 0.00407586\tvalid_1's auc: 0.975003\tvalid_1's binary_logloss: 0.163557\n",
      "[154]\ttraining's auc: 1\ttraining's binary_logloss: 0.00399443\tvalid_1's auc: 0.974889\tvalid_1's binary_logloss: 0.164378\n",
      "[155]\ttraining's auc: 1\ttraining's binary_logloss: 0.00391258\tvalid_1's auc: 0.975122\tvalid_1's binary_logloss: 0.164133\n",
      "[156]\ttraining's auc: 1\ttraining's binary_logloss: 0.00383481\tvalid_1's auc: 0.975113\tvalid_1's binary_logloss: 0.164087\n",
      "[157]\ttraining's auc: 1\ttraining's binary_logloss: 0.00376403\tvalid_1's auc: 0.975162\tvalid_1's binary_logloss: 0.164116\n",
      "[158]\ttraining's auc: 1\ttraining's binary_logloss: 0.00368996\tvalid_1's auc: 0.975245\tvalid_1's binary_logloss: 0.164115\n",
      "[159]\ttraining's auc: 1\ttraining's binary_logloss: 0.00361227\tvalid_1's auc: 0.975265\tvalid_1's binary_logloss: 0.164418\n",
      "[160]\ttraining's auc: 1\ttraining's binary_logloss: 0.00353537\tvalid_1's auc: 0.975195\tvalid_1's binary_logloss: 0.164904\n",
      "[161]\ttraining's auc: 1\ttraining's binary_logloss: 0.0034517\tvalid_1's auc: 0.975242\tvalid_1's binary_logloss: 0.164975\n",
      "[162]\ttraining's auc: 1\ttraining's binary_logloss: 0.00338408\tvalid_1's auc: 0.975291\tvalid_1's binary_logloss: 0.165075\n",
      "[163]\ttraining's auc: 1\ttraining's binary_logloss: 0.00330921\tvalid_1's auc: 0.975254\tvalid_1's binary_logloss: 0.165594\n",
      "[164]\ttraining's auc: 1\ttraining's binary_logloss: 0.00324031\tvalid_1's auc: 0.975146\tvalid_1's binary_logloss: 0.166472\n",
      "[165]\ttraining's auc: 1\ttraining's binary_logloss: 0.00317704\tvalid_1's auc: 0.975191\tvalid_1's binary_logloss: 0.166713\n",
      "[166]\ttraining's auc: 1\ttraining's binary_logloss: 0.00309064\tvalid_1's auc: 0.975117\tvalid_1's binary_logloss: 0.166946\n",
      "[167]\ttraining's auc: 1\ttraining's binary_logloss: 0.00303205\tvalid_1's auc: 0.975347\tvalid_1's binary_logloss: 0.166549\n",
      "[168]\ttraining's auc: 1\ttraining's binary_logloss: 0.00296196\tvalid_1's auc: 0.975312\tvalid_1's binary_logloss: 0.166842\n",
      "[169]\ttraining's auc: 1\ttraining's binary_logloss: 0.00290357\tvalid_1's auc: 0.975323\tvalid_1's binary_logloss: 0.167348\n",
      "[170]\ttraining's auc: 1\ttraining's binary_logloss: 0.00284604\tvalid_1's auc: 0.975537\tvalid_1's binary_logloss: 0.166931\n",
      "[171]\ttraining's auc: 1\ttraining's binary_logloss: 0.0027913\tvalid_1's auc: 0.975504\tvalid_1's binary_logloss: 0.16704\n",
      "[172]\ttraining's auc: 1\ttraining's binary_logloss: 0.00273173\tvalid_1's auc: 0.975446\tvalid_1's binary_logloss: 0.167378\n",
      "[173]\ttraining's auc: 1\ttraining's binary_logloss: 0.00266812\tvalid_1's auc: 0.975381\tvalid_1's binary_logloss: 0.168141\n",
      "[174]\ttraining's auc: 1\ttraining's binary_logloss: 0.00261591\tvalid_1's auc: 0.975271\tvalid_1's binary_logloss: 0.168785\n",
      "[175]\ttraining's auc: 1\ttraining's binary_logloss: 0.00255608\tvalid_1's auc: 0.975149\tvalid_1's binary_logloss: 0.169694\n",
      "ROC AUC: 0.9892\n"
     ]
    }
   ],
   "source": [
    "# 튜닝 파라미터 적용 값\n",
    "# -------------------\n",
    "best = {'learning_rate': 0.1406105325029019, 'max_depth': 106.0, 'min_child_samples': 64.0, 'num_leaves': 41.0, 'subsample': 0.9462293554201169}\n",
    "\n",
    "\n",
    "lgbm_clf =  LGBMClassifier(n_estimators=700, num_leaves=int(best['num_leaves']),\n",
    "                           max_depth=int(best['max_depth']),\n",
    "                           min_child_samples=int(best['min_child_samples']), \n",
    "                           subsample=round(best['subsample'], 5),\n",
    "                           learning_rate=round(best['learning_rate'], 5)\n",
    "                          )\n",
    "\n",
    "\n",
    "# evaluation metric을 auc로, early stopping은 100 으로 설정하고 학습 수행.\n",
    "# --------------------------------------------------------------------- \n",
    "lgbm_clf.fit(X_train, y_train, early_stopping_rounds=100, \n",
    "            eval_metric=\"auc\",eval_set=[(X_train, y_train), (X_test, y_test)])\n",
    "\n",
    "lgbm_roc_score = roc_auc_score(y_eval, lgbm_clf.predict_proba(X_eval)[:,1])\n",
    "print('ROC AUC: {0:.4f}'.format(lgbm_roc_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_df = pd.read_csv(\"./data/bank_churner.csv\") # 학습을 위한 데이터 로드\n",
    "eval_df = pd.read_csv(\"./data/test_churner.csv\") # 평가를 위한 데이터 로드 - 평가데이터 경로를 입력해 주세요!!!\n",
    "\n",
    "# 전처리 \n",
    "# -----\n",
    "X_tr, y_tr, X_val, y_val, X_eval, y_eval = test_transform(bank_churner_df, eval_churner_df)\n",
    "\n",
    "# print(X_tr, y_tr, X_val, y_val, X_eval, y_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's auc: 0.930081\ttraining's binary_logloss: 0.63125\tvalid_1's auc: 0.848979\tvalid_1's binary_logloss: 0.639177\n",
      "[2]\ttraining's auc: 0.938565\ttraining's binary_logloss: 0.580045\tvalid_1's auc: 0.85874\tvalid_1's binary_logloss: 0.595055\n",
      "[3]\ttraining's auc: 0.944351\ttraining's binary_logloss: 0.537039\tvalid_1's auc: 0.862536\tvalid_1's binary_logloss: 0.558517\n",
      "[4]\ttraining's auc: 0.959692\ttraining's binary_logloss: 0.497042\tvalid_1's auc: 0.882825\tvalid_1's binary_logloss: 0.525363\n",
      "[5]\ttraining's auc: 0.964264\ttraining's binary_logloss: 0.46349\tvalid_1's auc: 0.892105\tvalid_1's binary_logloss: 0.497306\n",
      "[6]\ttraining's auc: 0.969688\ttraining's binary_logloss: 0.432615\tvalid_1's auc: 0.900963\tvalid_1's binary_logloss: 0.469992\n",
      "[7]\ttraining's auc: 0.972911\ttraining's binary_logloss: 0.406289\tvalid_1's auc: 0.905563\tvalid_1's binary_logloss: 0.447879\n",
      "[8]\ttraining's auc: 0.975774\ttraining's binary_logloss: 0.383196\tvalid_1's auc: 0.909381\tvalid_1's binary_logloss: 0.428017\n",
      "[9]\ttraining's auc: 0.977598\ttraining's binary_logloss: 0.361822\tvalid_1's auc: 0.914049\tvalid_1's binary_logloss: 0.409333\n",
      "[10]\ttraining's auc: 0.979611\ttraining's binary_logloss: 0.341594\tvalid_1's auc: 0.916503\tvalid_1's binary_logloss: 0.393001\n",
      "[11]\ttraining's auc: 0.98183\ttraining's binary_logloss: 0.323391\tvalid_1's auc: 0.921863\tvalid_1's binary_logloss: 0.376325\n",
      "[12]\ttraining's auc: 0.983441\ttraining's binary_logloss: 0.307818\tvalid_1's auc: 0.925875\tvalid_1's binary_logloss: 0.362826\n",
      "[13]\ttraining's auc: 0.984544\ttraining's binary_logloss: 0.292517\tvalid_1's auc: 0.927259\tvalid_1's binary_logloss: 0.350209\n",
      "[14]\ttraining's auc: 0.98634\ttraining's binary_logloss: 0.276411\tvalid_1's auc: 0.931789\tvalid_1's binary_logloss: 0.336125\n",
      "[15]\ttraining's auc: 0.98689\ttraining's binary_logloss: 0.265155\tvalid_1's auc: 0.933237\tvalid_1's binary_logloss: 0.326351\n",
      "[16]\ttraining's auc: 0.987492\ttraining's binary_logloss: 0.25402\tvalid_1's auc: 0.934377\tvalid_1's binary_logloss: 0.316512\n",
      "[17]\ttraining's auc: 0.988563\ttraining's binary_logloss: 0.240857\tvalid_1's auc: 0.939508\tvalid_1's binary_logloss: 0.303175\n",
      "[18]\ttraining's auc: 0.989623\ttraining's binary_logloss: 0.228767\tvalid_1's auc: 0.941783\tvalid_1's binary_logloss: 0.293157\n",
      "[19]\ttraining's auc: 0.990654\ttraining's binary_logloss: 0.217684\tvalid_1's auc: 0.943975\tvalid_1's binary_logloss: 0.283378\n",
      "[20]\ttraining's auc: 0.991445\ttraining's binary_logloss: 0.207643\tvalid_1's auc: 0.945591\tvalid_1's binary_logloss: 0.275636\n",
      "[21]\ttraining's auc: 0.991991\ttraining's binary_logloss: 0.198297\tvalid_1's auc: 0.94678\tvalid_1's binary_logloss: 0.267497\n",
      "[22]\ttraining's auc: 0.992434\ttraining's binary_logloss: 0.190515\tvalid_1's auc: 0.948019\tvalid_1's binary_logloss: 0.260894\n",
      "[23]\ttraining's auc: 0.992813\ttraining's binary_logloss: 0.183537\tvalid_1's auc: 0.949296\tvalid_1's binary_logloss: 0.255249\n",
      "[24]\ttraining's auc: 0.993152\ttraining's binary_logloss: 0.177252\tvalid_1's auc: 0.949804\tvalid_1's binary_logloss: 0.249888\n",
      "[25]\ttraining's auc: 0.993574\ttraining's binary_logloss: 0.170059\tvalid_1's auc: 0.950144\tvalid_1's binary_logloss: 0.244746\n",
      "[26]\ttraining's auc: 0.994006\ttraining's binary_logloss: 0.163147\tvalid_1's auc: 0.951118\tvalid_1's binary_logloss: 0.239429\n",
      "[27]\ttraining's auc: 0.994298\ttraining's binary_logloss: 0.157427\tvalid_1's auc: 0.952366\tvalid_1's binary_logloss: 0.234486\n",
      "[28]\ttraining's auc: 0.994646\ttraining's binary_logloss: 0.151566\tvalid_1's auc: 0.953284\tvalid_1's binary_logloss: 0.229309\n",
      "[29]\ttraining's auc: 0.994861\ttraining's binary_logloss: 0.146681\tvalid_1's auc: 0.955594\tvalid_1's binary_logloss: 0.22405\n",
      "[30]\ttraining's auc: 0.995101\ttraining's binary_logloss: 0.141554\tvalid_1's auc: 0.955973\tvalid_1's binary_logloss: 0.220096\n",
      "[31]\ttraining's auc: 0.995293\ttraining's binary_logloss: 0.137343\tvalid_1's auc: 0.956438\tvalid_1's binary_logloss: 0.216841\n",
      "[32]\ttraining's auc: 0.995481\ttraining's binary_logloss: 0.133628\tvalid_1's auc: 0.956787\tvalid_1's binary_logloss: 0.213937\n",
      "[33]\ttraining's auc: 0.995715\ttraining's binary_logloss: 0.129088\tvalid_1's auc: 0.957258\tvalid_1's binary_logloss: 0.210968\n",
      "[34]\ttraining's auc: 0.995893\ttraining's binary_logloss: 0.125565\tvalid_1's auc: 0.958397\tvalid_1's binary_logloss: 0.207887\n",
      "[35]\ttraining's auc: 0.99606\ttraining's binary_logloss: 0.122076\tvalid_1's auc: 0.958774\tvalid_1's binary_logloss: 0.205304\n",
      "[36]\ttraining's auc: 0.996211\ttraining's binary_logloss: 0.118531\tvalid_1's auc: 0.959101\tvalid_1's binary_logloss: 0.202402\n",
      "[37]\ttraining's auc: 0.996388\ttraining's binary_logloss: 0.115288\tvalid_1's auc: 0.959582\tvalid_1's binary_logloss: 0.200318\n",
      "[38]\ttraining's auc: 0.996574\ttraining's binary_logloss: 0.111582\tvalid_1's auc: 0.959913\tvalid_1's binary_logloss: 0.197781\n",
      "[39]\ttraining's auc: 0.996709\ttraining's binary_logloss: 0.108943\tvalid_1's auc: 0.960389\tvalid_1's binary_logloss: 0.195873\n",
      "[40]\ttraining's auc: 0.996917\ttraining's binary_logloss: 0.105701\tvalid_1's auc: 0.96098\tvalid_1's binary_logloss: 0.193415\n",
      "[41]\ttraining's auc: 0.997048\ttraining's binary_logloss: 0.10316\tvalid_1's auc: 0.961738\tvalid_1's binary_logloss: 0.190831\n",
      "[42]\ttraining's auc: 0.997223\ttraining's binary_logloss: 0.100217\tvalid_1's auc: 0.962905\tvalid_1's binary_logloss: 0.188212\n",
      "[43]\ttraining's auc: 0.997328\ttraining's binary_logloss: 0.0980462\tvalid_1's auc: 0.962927\tvalid_1's binary_logloss: 0.18693\n",
      "[44]\ttraining's auc: 0.997478\ttraining's binary_logloss: 0.095364\tvalid_1's auc: 0.96345\tvalid_1's binary_logloss: 0.185308\n",
      "[45]\ttraining's auc: 0.997571\ttraining's binary_logloss: 0.093082\tvalid_1's auc: 0.96422\tvalid_1's binary_logloss: 0.183152\n",
      "[46]\ttraining's auc: 0.997691\ttraining's binary_logloss: 0.0905847\tvalid_1's auc: 0.964882\tvalid_1's binary_logloss: 0.181082\n",
      "[47]\ttraining's auc: 0.997786\ttraining's binary_logloss: 0.0879976\tvalid_1's auc: 0.965157\tvalid_1's binary_logloss: 0.179824\n",
      "[48]\ttraining's auc: 0.997908\ttraining's binary_logloss: 0.0857496\tvalid_1's auc: 0.96593\tvalid_1's binary_logloss: 0.177666\n",
      "[49]\ttraining's auc: 0.997986\ttraining's binary_logloss: 0.0833866\tvalid_1's auc: 0.966192\tvalid_1's binary_logloss: 0.176136\n",
      "[50]\ttraining's auc: 0.998088\ttraining's binary_logloss: 0.0817855\tvalid_1's auc: 0.96651\tvalid_1's binary_logloss: 0.1752\n",
      "[51]\ttraining's auc: 0.998171\ttraining's binary_logloss: 0.0803762\tvalid_1's auc: 0.966839\tvalid_1's binary_logloss: 0.174169\n",
      "[52]\ttraining's auc: 0.998262\ttraining's binary_logloss: 0.07875\tvalid_1's auc: 0.967422\tvalid_1's binary_logloss: 0.172746\n",
      "[53]\ttraining's auc: 0.998347\ttraining's binary_logloss: 0.0772316\tvalid_1's auc: 0.967453\tvalid_1's binary_logloss: 0.171691\n",
      "[54]\ttraining's auc: 0.998422\ttraining's binary_logloss: 0.0756684\tvalid_1's auc: 0.967851\tvalid_1's binary_logloss: 0.17049\n",
      "[55]\ttraining's auc: 0.998492\ttraining's binary_logloss: 0.0741222\tvalid_1's auc: 0.96822\tvalid_1's binary_logloss: 0.169094\n",
      "[56]\ttraining's auc: 0.998571\ttraining's binary_logloss: 0.0725257\tvalid_1's auc: 0.96844\tvalid_1's binary_logloss: 0.168196\n",
      "[57]\ttraining's auc: 0.998632\ttraining's binary_logloss: 0.0712563\tvalid_1's auc: 0.968746\tvalid_1's binary_logloss: 0.166846\n",
      "[58]\ttraining's auc: 0.99869\ttraining's binary_logloss: 0.0698533\tvalid_1's auc: 0.969115\tvalid_1's binary_logloss: 0.165511\n",
      "[59]\ttraining's auc: 0.998749\ttraining's binary_logloss: 0.0684617\tvalid_1's auc: 0.968849\tvalid_1's binary_logloss: 0.165532\n",
      "[60]\ttraining's auc: 0.998796\ttraining's binary_logloss: 0.0672262\tvalid_1's auc: 0.969283\tvalid_1's binary_logloss: 0.164175\n",
      "[61]\ttraining's auc: 0.998848\ttraining's binary_logloss: 0.0659526\tvalid_1's auc: 0.969529\tvalid_1's binary_logloss: 0.163478\n",
      "[62]\ttraining's auc: 0.9989\ttraining's binary_logloss: 0.0648421\tvalid_1's auc: 0.969535\tvalid_1's binary_logloss: 0.162981\n",
      "[63]\ttraining's auc: 0.998937\ttraining's binary_logloss: 0.0638231\tvalid_1's auc: 0.969605\tvalid_1's binary_logloss: 0.162512\n",
      "[64]\ttraining's auc: 0.998985\ttraining's binary_logloss: 0.0626298\tvalid_1's auc: 0.969929\tvalid_1's binary_logloss: 0.161597\n",
      "[65]\ttraining's auc: 0.999014\ttraining's binary_logloss: 0.0616487\tvalid_1's auc: 0.969811\tvalid_1's binary_logloss: 0.161344\n",
      "[66]\ttraining's auc: 0.999059\ttraining's binary_logloss: 0.06061\tvalid_1's auc: 0.969808\tvalid_1's binary_logloss: 0.161138\n",
      "[67]\ttraining's auc: 0.999096\ttraining's binary_logloss: 0.0596434\tvalid_1's auc: 0.970164\tvalid_1's binary_logloss: 0.160211\n",
      "[68]\ttraining's auc: 0.999133\ttraining's binary_logloss: 0.0586311\tvalid_1's auc: 0.970316\tvalid_1's binary_logloss: 0.159583\n",
      "[69]\ttraining's auc: 0.999171\ttraining's binary_logloss: 0.0575731\tvalid_1's auc: 0.970412\tvalid_1's binary_logloss: 0.15904\n",
      "[70]\ttraining's auc: 0.999209\ttraining's binary_logloss: 0.0567003\tvalid_1's auc: 0.970577\tvalid_1's binary_logloss: 0.158731\n",
      "[71]\ttraining's auc: 0.999241\ttraining's binary_logloss: 0.0557519\tvalid_1's auc: 0.970801\tvalid_1's binary_logloss: 0.158112\n",
      "[72]\ttraining's auc: 0.999288\ttraining's binary_logloss: 0.0547364\tvalid_1's auc: 0.970667\tvalid_1's binary_logloss: 0.158068\n",
      "[73]\ttraining's auc: 0.999326\ttraining's binary_logloss: 0.0536496\tvalid_1's auc: 0.970589\tvalid_1's binary_logloss: 0.157777\n",
      "[74]\ttraining's auc: 0.999358\ttraining's binary_logloss: 0.052888\tvalid_1's auc: 0.970662\tvalid_1's binary_logloss: 0.157266\n",
      "[75]\ttraining's auc: 0.999383\ttraining's binary_logloss: 0.0521455\tvalid_1's auc: 0.9707\tvalid_1's binary_logloss: 0.157039\n",
      "[76]\ttraining's auc: 0.999411\ttraining's binary_logloss: 0.0512406\tvalid_1's auc: 0.970495\tvalid_1's binary_logloss: 0.157156\n",
      "[77]\ttraining's auc: 0.999441\ttraining's binary_logloss: 0.0504614\tvalid_1's auc: 0.970334\tvalid_1's binary_logloss: 0.15742\n",
      "[78]\ttraining's auc: 0.999464\ttraining's binary_logloss: 0.0498286\tvalid_1's auc: 0.970548\tvalid_1's binary_logloss: 0.157041\n",
      "[79]\ttraining's auc: 0.999493\ttraining's binary_logloss: 0.0489785\tvalid_1's auc: 0.970638\tvalid_1's binary_logloss: 0.156829\n",
      "[80]\ttraining's auc: 0.999523\ttraining's binary_logloss: 0.0481247\tvalid_1's auc: 0.970658\tvalid_1's binary_logloss: 0.156366\n",
      "[81]\ttraining's auc: 0.999556\ttraining's binary_logloss: 0.0473544\tvalid_1's auc: 0.970752\tvalid_1's binary_logloss: 0.156147\n",
      "[82]\ttraining's auc: 0.999574\ttraining's binary_logloss: 0.0465918\tvalid_1's auc: 0.970709\tvalid_1's binary_logloss: 0.155855\n",
      "[83]\ttraining's auc: 0.999592\ttraining's binary_logloss: 0.0457994\tvalid_1's auc: 0.970685\tvalid_1's binary_logloss: 0.155804\n",
      "[84]\ttraining's auc: 0.999608\ttraining's binary_logloss: 0.0451597\tvalid_1's auc: 0.970797\tvalid_1's binary_logloss: 0.155459\n",
      "[85]\ttraining's auc: 0.999626\ttraining's binary_logloss: 0.0444801\tvalid_1's auc: 0.970647\tvalid_1's binary_logloss: 0.155562\n",
      "[86]\ttraining's auc: 0.999649\ttraining's binary_logloss: 0.0438698\tvalid_1's auc: 0.970691\tvalid_1's binary_logloss: 0.155209\n",
      "[87]\ttraining's auc: 0.99966\ttraining's binary_logloss: 0.0432934\tvalid_1's auc: 0.970763\tvalid_1's binary_logloss: 0.154721\n",
      "[88]\ttraining's auc: 0.999676\ttraining's binary_logloss: 0.0426051\tvalid_1's auc: 0.97085\tvalid_1's binary_logloss: 0.154423\n",
      "[89]\ttraining's auc: 0.99969\ttraining's binary_logloss: 0.0420139\tvalid_1's auc: 0.970817\tvalid_1's binary_logloss: 0.154333\n",
      "[90]\ttraining's auc: 0.999698\ttraining's binary_logloss: 0.0415263\tvalid_1's auc: 0.970956\tvalid_1's binary_logloss: 0.154091\n",
      "[91]\ttraining's auc: 0.999732\ttraining's binary_logloss: 0.0408528\tvalid_1's auc: 0.97134\tvalid_1's binary_logloss: 0.15332\n",
      "[92]\ttraining's auc: 0.999745\ttraining's binary_logloss: 0.0402114\tvalid_1's auc: 0.97141\tvalid_1's binary_logloss: 0.153119\n",
      "[93]\ttraining's auc: 0.999763\ttraining's binary_logloss: 0.0395764\tvalid_1's auc: 0.971284\tvalid_1's binary_logloss: 0.153338\n",
      "[94]\ttraining's auc: 0.999773\ttraining's binary_logloss: 0.0391117\tvalid_1's auc: 0.971087\tvalid_1's binary_logloss: 0.153646\n",
      "[95]\ttraining's auc: 0.999789\ttraining's binary_logloss: 0.0384625\tvalid_1's auc: 0.971287\tvalid_1's binary_logloss: 0.153316\n",
      "[96]\ttraining's auc: 0.999799\ttraining's binary_logloss: 0.0378362\tvalid_1's auc: 0.971239\tvalid_1's binary_logloss: 0.153393\n",
      "[97]\ttraining's auc: 0.999812\ttraining's binary_logloss: 0.0372602\tvalid_1's auc: 0.971186\tvalid_1's binary_logloss: 0.153365\n",
      "[98]\ttraining's auc: 0.999818\ttraining's binary_logloss: 0.0368643\tvalid_1's auc: 0.97134\tvalid_1's binary_logloss: 0.153041\n",
      "[99]\ttraining's auc: 0.999824\ttraining's binary_logloss: 0.0364058\tvalid_1's auc: 0.971242\tvalid_1's binary_logloss: 0.153098\n",
      "[100]\ttraining's auc: 0.999838\ttraining's binary_logloss: 0.0358117\tvalid_1's auc: 0.971354\tvalid_1's binary_logloss: 0.152852\n",
      "[101]\ttraining's auc: 0.999843\ttraining's binary_logloss: 0.0353607\tvalid_1's auc: 0.971418\tvalid_1's binary_logloss: 0.152837\n",
      "[102]\ttraining's auc: 0.999853\ttraining's binary_logloss: 0.0349615\tvalid_1's auc: 0.971483\tvalid_1's binary_logloss: 0.152494\n",
      "[103]\ttraining's auc: 0.999858\ttraining's binary_logloss: 0.0345592\tvalid_1's auc: 0.971532\tvalid_1's binary_logloss: 0.152311\n",
      "[104]\ttraining's auc: 0.999866\ttraining's binary_logloss: 0.0341076\tvalid_1's auc: 0.97155\tvalid_1's binary_logloss: 0.152259\n",
      "[105]\ttraining's auc: 0.999881\ttraining's binary_logloss: 0.0337031\tvalid_1's auc: 0.971602\tvalid_1's binary_logloss: 0.152175\n",
      "[106]\ttraining's auc: 0.999885\ttraining's binary_logloss: 0.0332911\tvalid_1's auc: 0.971611\tvalid_1's binary_logloss: 0.152146\n",
      "[107]\ttraining's auc: 0.99989\ttraining's binary_logloss: 0.0327197\tvalid_1's auc: 0.971704\tvalid_1's binary_logloss: 0.151867\n",
      "[108]\ttraining's auc: 0.999894\ttraining's binary_logloss: 0.0322823\tvalid_1's auc: 0.971801\tvalid_1's binary_logloss: 0.15167\n",
      "[109]\ttraining's auc: 0.999899\ttraining's binary_logloss: 0.0317715\tvalid_1's auc: 0.971915\tvalid_1's binary_logloss: 0.151414\n",
      "[110]\ttraining's auc: 0.999907\ttraining's binary_logloss: 0.0313903\tvalid_1's auc: 0.971917\tvalid_1's binary_logloss: 0.151363\n",
      "[111]\ttraining's auc: 0.999911\ttraining's binary_logloss: 0.0310515\tvalid_1's auc: 0.972063\tvalid_1's binary_logloss: 0.150994\n",
      "[112]\ttraining's auc: 0.999915\ttraining's binary_logloss: 0.0306771\tvalid_1's auc: 0.972109\tvalid_1's binary_logloss: 0.150765\n",
      "[113]\ttraining's auc: 0.999918\ttraining's binary_logloss: 0.0303487\tvalid_1's auc: 0.972159\tvalid_1's binary_logloss: 0.150757\n",
      "[114]\ttraining's auc: 0.999925\ttraining's binary_logloss: 0.0299517\tvalid_1's auc: 0.971855\tvalid_1's binary_logloss: 0.151276\n",
      "[115]\ttraining's auc: 0.999932\ttraining's binary_logloss: 0.0295737\tvalid_1's auc: 0.971924\tvalid_1's binary_logloss: 0.151195\n",
      "[116]\ttraining's auc: 0.999935\ttraining's binary_logloss: 0.0292107\tvalid_1's auc: 0.97198\tvalid_1's binary_logloss: 0.150969\n",
      "[117]\ttraining's auc: 0.999939\ttraining's binary_logloss: 0.0287619\tvalid_1's auc: 0.972163\tvalid_1's binary_logloss: 0.150711\n",
      "[118]\ttraining's auc: 0.999943\ttraining's binary_logloss: 0.0283341\tvalid_1's auc: 0.972297\tvalid_1's binary_logloss: 0.15018\n",
      "[119]\ttraining's auc: 0.999946\ttraining's binary_logloss: 0.0278588\tvalid_1's auc: 0.972286\tvalid_1's binary_logloss: 0.150086\n",
      "[120]\ttraining's auc: 0.999947\ttraining's binary_logloss: 0.027542\tvalid_1's auc: 0.972302\tvalid_1's binary_logloss: 0.149907\n",
      "[121]\ttraining's auc: 0.999956\ttraining's binary_logloss: 0.0271297\tvalid_1's auc: 0.972358\tvalid_1's binary_logloss: 0.149852\n",
      "[122]\ttraining's auc: 0.999959\ttraining's binary_logloss: 0.0267005\tvalid_1's auc: 0.972438\tvalid_1's binary_logloss: 0.15003\n",
      "[123]\ttraining's auc: 0.999963\ttraining's binary_logloss: 0.0263586\tvalid_1's auc: 0.972375\tvalid_1's binary_logloss: 0.150092\n",
      "[124]\ttraining's auc: 0.999964\ttraining's binary_logloss: 0.0260877\tvalid_1's auc: 0.972367\tvalid_1's binary_logloss: 0.150128\n",
      "[125]\ttraining's auc: 0.999972\ttraining's binary_logloss: 0.0256704\tvalid_1's auc: 0.972326\tvalid_1's binary_logloss: 0.150102\n",
      "[126]\ttraining's auc: 0.999973\ttraining's binary_logloss: 0.0254117\tvalid_1's auc: 0.972358\tvalid_1's binary_logloss: 0.150028\n",
      "[127]\ttraining's auc: 0.999976\ttraining's binary_logloss: 0.0249666\tvalid_1's auc: 0.972516\tvalid_1's binary_logloss: 0.149741\n",
      "[128]\ttraining's auc: 0.999979\ttraining's binary_logloss: 0.0246268\tvalid_1's auc: 0.972559\tvalid_1's binary_logloss: 0.149952\n",
      "[129]\ttraining's auc: 0.99998\ttraining's binary_logloss: 0.0243166\tvalid_1's auc: 0.972603\tvalid_1's binary_logloss: 0.149774\n",
      "[130]\ttraining's auc: 0.999981\ttraining's binary_logloss: 0.02405\tvalid_1's auc: 0.972566\tvalid_1's binary_logloss: 0.149798\n",
      "[131]\ttraining's auc: 0.999983\ttraining's binary_logloss: 0.023677\tvalid_1's auc: 0.972662\tvalid_1's binary_logloss: 0.149443\n",
      "[132]\ttraining's auc: 0.999984\ttraining's binary_logloss: 0.0233698\tvalid_1's auc: 0.972677\tvalid_1's binary_logloss: 0.149431\n",
      "[133]\ttraining's auc: 0.999984\ttraining's binary_logloss: 0.0230663\tvalid_1's auc: 0.972505\tvalid_1's binary_logloss: 0.150058\n",
      "[134]\ttraining's auc: 0.999985\ttraining's binary_logloss: 0.0227555\tvalid_1's auc: 0.972422\tvalid_1's binary_logloss: 0.150187\n",
      "[135]\ttraining's auc: 0.999987\ttraining's binary_logloss: 0.0224373\tvalid_1's auc: 0.97244\tvalid_1's binary_logloss: 0.150112\n",
      "[136]\ttraining's auc: 0.99999\ttraining's binary_logloss: 0.0221623\tvalid_1's auc: 0.972543\tvalid_1's binary_logloss: 0.14988\n",
      "[137]\ttraining's auc: 0.999991\ttraining's binary_logloss: 0.0219072\tvalid_1's auc: 0.972556\tvalid_1's binary_logloss: 0.149709\n",
      "[138]\ttraining's auc: 0.999991\ttraining's binary_logloss: 0.0215496\tvalid_1's auc: 0.972689\tvalid_1's binary_logloss: 0.149711\n",
      "[139]\ttraining's auc: 0.999992\ttraining's binary_logloss: 0.0212848\tvalid_1's auc: 0.972693\tvalid_1's binary_logloss: 0.149861\n",
      "[140]\ttraining's auc: 0.999993\ttraining's binary_logloss: 0.0210217\tvalid_1's auc: 0.972771\tvalid_1's binary_logloss: 0.149633\n",
      "[141]\ttraining's auc: 0.999994\ttraining's binary_logloss: 0.0207274\tvalid_1's auc: 0.972787\tvalid_1's binary_logloss: 0.149471\n",
      "[142]\ttraining's auc: 0.999994\ttraining's binary_logloss: 0.0205335\tvalid_1's auc: 0.9728\tvalid_1's binary_logloss: 0.149598\n",
      "[143]\ttraining's auc: 0.999995\ttraining's binary_logloss: 0.0202046\tvalid_1's auc: 0.972829\tvalid_1's binary_logloss: 0.149383\n",
      "[144]\ttraining's auc: 0.999995\ttraining's binary_logloss: 0.0198983\tvalid_1's auc: 0.97283\tvalid_1's binary_logloss: 0.149614\n",
      "[145]\ttraining's auc: 0.999995\ttraining's binary_logloss: 0.0196957\tvalid_1's auc: 0.972679\tvalid_1's binary_logloss: 0.149728\n",
      "[146]\ttraining's auc: 0.999996\ttraining's binary_logloss: 0.0195175\tvalid_1's auc: 0.972689\tvalid_1's binary_logloss: 0.149653\n",
      "[147]\ttraining's auc: 0.999996\ttraining's binary_logloss: 0.0193134\tvalid_1's auc: 0.972751\tvalid_1's binary_logloss: 0.149737\n",
      "[148]\ttraining's auc: 0.999996\ttraining's binary_logloss: 0.0191181\tvalid_1's auc: 0.972849\tvalid_1's binary_logloss: 0.1496\n",
      "[149]\ttraining's auc: 0.999996\ttraining's binary_logloss: 0.0189055\tvalid_1's auc: 0.972827\tvalid_1's binary_logloss: 0.149758\n",
      "[150]\ttraining's auc: 0.999996\ttraining's binary_logloss: 0.0186238\tvalid_1's auc: 0.972894\tvalid_1's binary_logloss: 0.149866\n",
      "[151]\ttraining's auc: 0.999997\ttraining's binary_logloss: 0.0184023\tvalid_1's auc: 0.972794\tvalid_1's binary_logloss: 0.150125\n",
      "[152]\ttraining's auc: 0.999997\ttraining's binary_logloss: 0.0182174\tvalid_1's auc: 0.972789\tvalid_1's binary_logloss: 0.150128\n",
      "[153]\ttraining's auc: 0.999997\ttraining's binary_logloss: 0.018019\tvalid_1's auc: 0.972769\tvalid_1's binary_logloss: 0.150195\n",
      "[154]\ttraining's auc: 0.999997\ttraining's binary_logloss: 0.0177907\tvalid_1's auc: 0.972899\tvalid_1's binary_logloss: 0.150072\n",
      "[155]\ttraining's auc: 0.999998\ttraining's binary_logloss: 0.0175042\tvalid_1's auc: 0.973026\tvalid_1's binary_logloss: 0.149912\n",
      "[156]\ttraining's auc: 0.999998\ttraining's binary_logloss: 0.0172657\tvalid_1's auc: 0.973096\tvalid_1's binary_logloss: 0.149835\n",
      "[157]\ttraining's auc: 0.999999\ttraining's binary_logloss: 0.0170786\tvalid_1's auc: 0.973049\tvalid_1's binary_logloss: 0.149879\n",
      "[158]\ttraining's auc: 0.999998\ttraining's binary_logloss: 0.0169429\tvalid_1's auc: 0.972959\tvalid_1's binary_logloss: 0.15015\n",
      "[159]\ttraining's auc: 0.999999\ttraining's binary_logloss: 0.016753\tvalid_1's auc: 0.97306\tvalid_1's binary_logloss: 0.150036\n",
      "[160]\ttraining's auc: 0.999999\ttraining's binary_logloss: 0.0165135\tvalid_1's auc: 0.973038\tvalid_1's binary_logloss: 0.150121\n",
      "[161]\ttraining's auc: 0.999999\ttraining's binary_logloss: 0.0162456\tvalid_1's auc: 0.973174\tvalid_1's binary_logloss: 0.150019\n",
      "[162]\ttraining's auc: 0.999999\ttraining's binary_logloss: 0.0160534\tvalid_1's auc: 0.973239\tvalid_1's binary_logloss: 0.150108\n",
      "[163]\ttraining's auc: 1\ttraining's binary_logloss: 0.0157696\tvalid_1's auc: 0.973286\tvalid_1's binary_logloss: 0.150115\n",
      "[164]\ttraining's auc: 1\ttraining's binary_logloss: 0.0155732\tvalid_1's auc: 0.973295\tvalid_1's binary_logloss: 0.15006\n",
      "[165]\ttraining's auc: 1\ttraining's binary_logloss: 0.0153636\tvalid_1's auc: 0.973326\tvalid_1's binary_logloss: 0.150051\n",
      "[166]\ttraining's auc: 1\ttraining's binary_logloss: 0.0151389\tvalid_1's auc: 0.973407\tvalid_1's binary_logloss: 0.150135\n",
      "[167]\ttraining's auc: 1\ttraining's binary_logloss: 0.0149758\tvalid_1's auc: 0.973418\tvalid_1's binary_logloss: 0.150251\n",
      "[168]\ttraining's auc: 1\ttraining's binary_logloss: 0.014814\tvalid_1's auc: 0.973471\tvalid_1's binary_logloss: 0.15017\n",
      "[169]\ttraining's auc: 1\ttraining's binary_logloss: 0.0145904\tvalid_1's auc: 0.973509\tvalid_1's binary_logloss: 0.150182\n",
      "[170]\ttraining's auc: 1\ttraining's binary_logloss: 0.014378\tvalid_1's auc: 0.97357\tvalid_1's binary_logloss: 0.150271\n",
      "[171]\ttraining's auc: 1\ttraining's binary_logloss: 0.014215\tvalid_1's auc: 0.97357\tvalid_1's binary_logloss: 0.150222\n",
      "[172]\ttraining's auc: 1\ttraining's binary_logloss: 0.0140667\tvalid_1's auc: 0.973547\tvalid_1's binary_logloss: 0.150557\n",
      "[173]\ttraining's auc: 1\ttraining's binary_logloss: 0.0138541\tvalid_1's auc: 0.973644\tvalid_1's binary_logloss: 0.150368\n",
      "[174]\ttraining's auc: 1\ttraining's binary_logloss: 0.01362\tvalid_1's auc: 0.97367\tvalid_1's binary_logloss: 0.150318\n",
      "[175]\ttraining's auc: 1\ttraining's binary_logloss: 0.0134976\tvalid_1's auc: 0.973597\tvalid_1's binary_logloss: 0.15062\n",
      "[176]\ttraining's auc: 1\ttraining's binary_logloss: 0.0133616\tvalid_1's auc: 0.973693\tvalid_1's binary_logloss: 0.150484\n",
      "[177]\ttraining's auc: 1\ttraining's binary_logloss: 0.0131968\tvalid_1's auc: 0.973545\tvalid_1's binary_logloss: 0.150858\n",
      "[178]\ttraining's auc: 1\ttraining's binary_logloss: 0.0130248\tvalid_1's auc: 0.973547\tvalid_1's binary_logloss: 0.151104\n",
      "[179]\ttraining's auc: 1\ttraining's binary_logloss: 0.0128742\tvalid_1's auc: 0.973579\tvalid_1's binary_logloss: 0.151097\n",
      "[180]\ttraining's auc: 1\ttraining's binary_logloss: 0.0127155\tvalid_1's auc: 0.973657\tvalid_1's binary_logloss: 0.151078\n",
      "[181]\ttraining's auc: 1\ttraining's binary_logloss: 0.0125648\tvalid_1's auc: 0.973545\tvalid_1's binary_logloss: 0.151421\n",
      "[182]\ttraining's auc: 1\ttraining's binary_logloss: 0.0124108\tvalid_1's auc: 0.973518\tvalid_1's binary_logloss: 0.151492\n",
      "[183]\ttraining's auc: 1\ttraining's binary_logloss: 0.0122825\tvalid_1's auc: 0.973355\tvalid_1's binary_logloss: 0.152088\n",
      "[184]\ttraining's auc: 1\ttraining's binary_logloss: 0.0121202\tvalid_1's auc: 0.973397\tvalid_1's binary_logloss: 0.152243\n",
      "[185]\ttraining's auc: 1\ttraining's binary_logloss: 0.0119813\tvalid_1's auc: 0.973516\tvalid_1's binary_logloss: 0.152341\n",
      "[186]\ttraining's auc: 1\ttraining's binary_logloss: 0.0117816\tvalid_1's auc: 0.97354\tvalid_1's binary_logloss: 0.152629\n",
      "[187]\ttraining's auc: 1\ttraining's binary_logloss: 0.0116697\tvalid_1's auc: 0.973549\tvalid_1's binary_logloss: 0.152853\n",
      "[188]\ttraining's auc: 1\ttraining's binary_logloss: 0.01156\tvalid_1's auc: 0.973511\tvalid_1's binary_logloss: 0.15317\n",
      "[189]\ttraining's auc: 1\ttraining's binary_logloss: 0.0113933\tvalid_1's auc: 0.973648\tvalid_1's binary_logloss: 0.153013\n",
      "[190]\ttraining's auc: 1\ttraining's binary_logloss: 0.0112488\tvalid_1's auc: 0.973851\tvalid_1's binary_logloss: 0.152702\n",
      "[191]\ttraining's auc: 1\ttraining's binary_logloss: 0.0111381\tvalid_1's auc: 0.973762\tvalid_1's binary_logloss: 0.15302\n",
      "[192]\ttraining's auc: 1\ttraining's binary_logloss: 0.010977\tvalid_1's auc: 0.973881\tvalid_1's binary_logloss: 0.152738\n",
      "[193]\ttraining's auc: 1\ttraining's binary_logloss: 0.0108254\tvalid_1's auc: 0.974066\tvalid_1's binary_logloss: 0.152356\n",
      "[194]\ttraining's auc: 1\ttraining's binary_logloss: 0.0106874\tvalid_1's auc: 0.974142\tvalid_1's binary_logloss: 0.152313\n",
      "[195]\ttraining's auc: 1\ttraining's binary_logloss: 0.010574\tvalid_1's auc: 0.974149\tvalid_1's binary_logloss: 0.152431\n",
      "[196]\ttraining's auc: 1\ttraining's binary_logloss: 0.0104347\tvalid_1's auc: 0.974238\tvalid_1's binary_logloss: 0.152378\n",
      "[197]\ttraining's auc: 1\ttraining's binary_logloss: 0.0103325\tvalid_1's auc: 0.974193\tvalid_1's binary_logloss: 0.152784\n",
      "[198]\ttraining's auc: 1\ttraining's binary_logloss: 0.010181\tvalid_1's auc: 0.974297\tvalid_1's binary_logloss: 0.152612\n",
      "[199]\ttraining's auc: 1\ttraining's binary_logloss: 0.0100804\tvalid_1's auc: 0.974292\tvalid_1's binary_logloss: 0.152805\n",
      "[200]\ttraining's auc: 1\ttraining's binary_logloss: 0.00993268\tvalid_1's auc: 0.974294\tvalid_1's binary_logloss: 0.152993\n",
      "[201]\ttraining's auc: 1\ttraining's binary_logloss: 0.00980969\tvalid_1's auc: 0.974375\tvalid_1's binary_logloss: 0.152947\n",
      "[202]\ttraining's auc: 1\ttraining's binary_logloss: 0.0096681\tvalid_1's auc: 0.974401\tvalid_1's binary_logloss: 0.153157\n",
      "[203]\ttraining's auc: 1\ttraining's binary_logloss: 0.00956412\tvalid_1's auc: 0.974348\tvalid_1's binary_logloss: 0.153331\n",
      "[204]\ttraining's auc: 1\ttraining's binary_logloss: 0.00946956\tvalid_1's auc: 0.974216\tvalid_1's binary_logloss: 0.153691\n",
      "[205]\ttraining's auc: 1\ttraining's binary_logloss: 0.00938287\tvalid_1's auc: 0.974263\tvalid_1's binary_logloss: 0.153621\n",
      "[206]\ttraining's auc: 1\ttraining's binary_logloss: 0.00926127\tvalid_1's auc: 0.974296\tvalid_1's binary_logloss: 0.153547\n",
      "[207]\ttraining's auc: 1\ttraining's binary_logloss: 0.00916847\tvalid_1's auc: 0.974372\tvalid_1's binary_logloss: 0.153438\n",
      "[208]\ttraining's auc: 1\ttraining's binary_logloss: 0.00901384\tvalid_1's auc: 0.974346\tvalid_1's binary_logloss: 0.153661\n",
      "[209]\ttraining's auc: 1\ttraining's binary_logloss: 0.00892092\tvalid_1's auc: 0.97446\tvalid_1's binary_logloss: 0.153673\n",
      "[210]\ttraining's auc: 1\ttraining's binary_logloss: 0.00881132\tvalid_1's auc: 0.974581\tvalid_1's binary_logloss: 0.153462\n",
      "[211]\ttraining's auc: 1\ttraining's binary_logloss: 0.00872156\tvalid_1's auc: 0.974468\tvalid_1's binary_logloss: 0.153835\n",
      "[212]\ttraining's auc: 1\ttraining's binary_logloss: 0.00864707\tvalid_1's auc: 0.97439\tvalid_1's binary_logloss: 0.15412\n",
      "[213]\ttraining's auc: 1\ttraining's binary_logloss: 0.00853479\tvalid_1's auc: 0.974334\tvalid_1's binary_logloss: 0.154264\n",
      "[214]\ttraining's auc: 1\ttraining's binary_logloss: 0.00845029\tvalid_1's auc: 0.97431\tvalid_1's binary_logloss: 0.154347\n",
      "[215]\ttraining's auc: 1\ttraining's binary_logloss: 0.00832418\tvalid_1's auc: 0.974411\tvalid_1's binary_logloss: 0.154198\n",
      "[216]\ttraining's auc: 1\ttraining's binary_logloss: 0.00819034\tvalid_1's auc: 0.974397\tvalid_1's binary_logloss: 0.154485\n",
      "[217]\ttraining's auc: 1\ttraining's binary_logloss: 0.00806329\tvalid_1's auc: 0.974408\tvalid_1's binary_logloss: 0.154812\n",
      "[218]\ttraining's auc: 1\ttraining's binary_logloss: 0.00795617\tvalid_1's auc: 0.974256\tvalid_1's binary_logloss: 0.15537\n",
      "[219]\ttraining's auc: 1\ttraining's binary_logloss: 0.00783609\tvalid_1's auc: 0.974372\tvalid_1's binary_logloss: 0.155403\n",
      "[220]\ttraining's auc: 1\ttraining's binary_logloss: 0.00775312\tvalid_1's auc: 0.974435\tvalid_1's binary_logloss: 0.155569\n",
      "[221]\ttraining's auc: 1\ttraining's binary_logloss: 0.00766368\tvalid_1's auc: 0.974357\tvalid_1's binary_logloss: 0.155833\n",
      "[222]\ttraining's auc: 1\ttraining's binary_logloss: 0.00758044\tvalid_1's auc: 0.974211\tvalid_1's binary_logloss: 0.156139\n",
      "[223]\ttraining's auc: 1\ttraining's binary_logloss: 0.00751244\tvalid_1's auc: 0.974272\tvalid_1's binary_logloss: 0.156127\n",
      "[224]\ttraining's auc: 1\ttraining's binary_logloss: 0.00745452\tvalid_1's auc: 0.974041\tvalid_1's binary_logloss: 0.156636\n",
      "[225]\ttraining's auc: 1\ttraining's binary_logloss: 0.00739131\tvalid_1's auc: 0.97412\tvalid_1's binary_logloss: 0.156674\n",
      "[226]\ttraining's auc: 1\ttraining's binary_logloss: 0.00730972\tvalid_1's auc: 0.974198\tvalid_1's binary_logloss: 0.156537\n",
      "[227]\ttraining's auc: 1\ttraining's binary_logloss: 0.00720531\tvalid_1's auc: 0.974314\tvalid_1's binary_logloss: 0.156616\n",
      "[228]\ttraining's auc: 1\ttraining's binary_logloss: 0.0071162\tvalid_1's auc: 0.974258\tvalid_1's binary_logloss: 0.156512\n",
      "[229]\ttraining's auc: 1\ttraining's binary_logloss: 0.00705044\tvalid_1's auc: 0.974249\tvalid_1's binary_logloss: 0.156797\n",
      "[230]\ttraining's auc: 1\ttraining's binary_logloss: 0.00696227\tvalid_1's auc: 0.974202\tvalid_1's binary_logloss: 0.157181\n",
      "[231]\ttraining's auc: 1\ttraining's binary_logloss: 0.00686857\tvalid_1's auc: 0.974308\tvalid_1's binary_logloss: 0.157058\n",
      "[232]\ttraining's auc: 1\ttraining's binary_logloss: 0.00678423\tvalid_1's auc: 0.97437\tvalid_1's binary_logloss: 0.156933\n",
      "[233]\ttraining's auc: 1\ttraining's binary_logloss: 0.00667802\tvalid_1's auc: 0.974475\tvalid_1's binary_logloss: 0.156776\n",
      "[234]\ttraining's auc: 1\ttraining's binary_logloss: 0.00658642\tvalid_1's auc: 0.974504\tvalid_1's binary_logloss: 0.156911\n",
      "[235]\ttraining's auc: 1\ttraining's binary_logloss: 0.00650428\tvalid_1's auc: 0.974542\tvalid_1's binary_logloss: 0.156972\n",
      "[236]\ttraining's auc: 1\ttraining's binary_logloss: 0.00639767\tvalid_1's auc: 0.974592\tvalid_1's binary_logloss: 0.156854\n",
      "[237]\ttraining's auc: 1\ttraining's binary_logloss: 0.00629346\tvalid_1's auc: 0.974628\tvalid_1's binary_logloss: 0.157065\n",
      "[238]\ttraining's auc: 1\ttraining's binary_logloss: 0.00621563\tvalid_1's auc: 0.974744\tvalid_1's binary_logloss: 0.156875\n",
      "[239]\ttraining's auc: 1\ttraining's binary_logloss: 0.00615618\tvalid_1's auc: 0.974855\tvalid_1's binary_logloss: 0.156848\n",
      "[240]\ttraining's auc: 1\ttraining's binary_logloss: 0.00609076\tvalid_1's auc: 0.974929\tvalid_1's binary_logloss: 0.156759\n",
      "[241]\ttraining's auc: 1\ttraining's binary_logloss: 0.00602026\tvalid_1's auc: 0.974978\tvalid_1's binary_logloss: 0.156667\n",
      "[242]\ttraining's auc: 1\ttraining's binary_logloss: 0.00596078\tvalid_1's auc: 0.97488\tvalid_1's binary_logloss: 0.156903\n",
      "[243]\ttraining's auc: 1\ttraining's binary_logloss: 0.00588693\tvalid_1's auc: 0.974922\tvalid_1's binary_logloss: 0.157156\n",
      "ROC AUC: 0.9886\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "lgbm_clf = LGBMClassifier(n_estimators=700)\n",
    "\n",
    "eval_set=[(X_tr, y_tr), (X_val, y_val)]\n",
    "lgbm_clf.fit(X_tr, y_tr, early_stopping_rounds=100, eval_metric=\"auc\", eval_set=eval_set)\n",
    "\n",
    "lgbm_roc_score = roc_auc_score(y_eval, lgbm_clf.predict_proba(X_eval)[:,1])\n",
    "print('ROC AUC: {0:.4f}'.format(lgbm_roc_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp\n",
    "\n",
    "lgbm_search_space = {'num_leaves': hp.quniform('num_leaves', 32, 64, 1),\n",
    "                     'max_depth': hp.quniform('max_depth', 100, 160, 1),\n",
    "                     'min_child_samples': hp.quniform('min_child_samples', 60, 100, 1),\n",
    "                     'subsample': hp.uniform('subsample', 0.7, 1),\n",
    "                     'learning_rate': hp.uniform('learning_rate', 0.01, 0.2)\n",
    "                    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.34290826  0.26645192  0.28359571 ...  0.81449046 -0.98844349\n",
      "  -0.67049112]\n",
      " [-1.15706607 -0.54720773  0.96287527 ...  0.11245938  0.77162973\n",
      "  -1.07374082]\n",
      " [-0.88568013 -0.14037791 -0.39568384 ...  0.11245938  0.24408735\n",
      "  -1.07374082]\n",
      " ...\n",
      " [ 1.35345714  1.33213275 -1.19619064 ... -0.03954279 -0.14820606\n",
      "   0.16588145]\n",
      " [-0.05601483 -0.01639147  0.26418807 ...  0.0939989   0.21361771\n",
      "  -1.07374082]\n",
      " [ 0.01407973  0.53767181  0.8898888  ... -0.38011276 -1.15961415\n",
      "  -0.65379096]] [0 0 0 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "X_Features = X_tr\n",
    "y_labels = y_tr\n",
    "print(X_Features, y_labels)\n",
    "\n",
    "def objective_func(search_space):\n",
    "    lgbm_clf =  LGBMClassifier(n_estimators=100, num_leaves=int(search_space['num_leaves']),\n",
    "                               max_depth=int(search_space['max_depth']),\n",
    "                               min_child_samples=int(search_space['min_child_samples']), \n",
    "                               subsample=search_space['subsample'],\n",
    "                               learning_rate=search_space['learning_rate'])\n",
    "\n",
    "    roc_auc_list = []\n",
    "    \n",
    "    kf = KFold(n_splits=3)\n",
    "    # X_train을 다시 학습과 검증용 데이터로 분리\n",
    "    for tr_index, val_index in kf.split(X_Features):\n",
    "        # kf.split(X_train)으로 추출된 학습과 검증 index값으로 학습과 검증 데이터 세트 분리 \n",
    "        X_tr, y_tr = X_Features[tr_index], y_labels[tr_index]\n",
    "        X_val, y_val = X_Features[val_index], y_labels[val_index]\n",
    "\n",
    "\n",
    "        # SMOTE 적용\n",
    "        # ----------\n",
    "        # sm = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "        # X_tr, y_tr=sm.fit_resample(X_tr,y_tr)\n",
    "\n",
    "        # early stopping은 30회로 설정하고 추출된 학습과 검증 데이터로 XGBClassifier 학습 수행. \n",
    "        # lgbm_clf.fit(X_tr, y_tr, early_stopping_rounds=30, eval_metric=\"auc\",\n",
    "        lgbm_clf.fit(X_tr, y_tr, eval_metric=\"auc\", eval_set=[(X_tr, y_tr), (X_val, y_val)])\n",
    "\n",
    "        # 1로 예측한 확률값 추출후 roc auc 계산하고 평균 roc auc 계산을 위해 list에 결과값 담음.\n",
    "        score = roc_auc_score(y_eval, lgbm_clf.predict_proba(X_eval)[:, 1]) \n",
    "        roc_auc_list.append(score)\n",
    "    \n",
    "    # 3개 k-fold로 계산된 roc_auc값의 평균값을 반환하되, \n",
    "    # HyperOpt는 목적함수의 최소값을 위한 입력값을 찾으므로 -1을 곱한 뒤 반환.\n",
    "    return -1*np.mean(roc_auc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom hyperopt import fmin, tpe, Trials\\n\\ntrials = Trials()\\n\\n# fmin()함수를 호출. max_evals지정된 횟수만큼 반복 후 목적함수의 최소값을 가지는 최적 입력값 추출. \\nbest = fmin(fn=objective_func, space=lgbm_search_space, algo=tpe.suggest,\\n            max_evals=50, # 최대 반복 횟수를 지정합니다.\\n            trials=trials, rstate=np.random.default_rng(seed=30))\\n\\nprint('best:', best)\\n\\n\""
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from hyperopt import fmin, tpe, Trials\n",
    "\n",
    "trials = Trials()\n",
    "\n",
    "# fmin()함수를 호출. max_evals지정된 횟수만큼 반복 후 목적함수의 최소값을 가지는 최적 입력값 추출. \n",
    "best = fmin(fn=objective_func, space=lgbm_search_space, algo=tpe.suggest,\n",
    "            max_evals=50, # 최대 반복 횟수를 지정합니다.\n",
    "            trials=trials, rstate=np.random.default_rng(seed=30))\n",
    "\n",
    "print('best:', best)\n",
    "\n",
    "'''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 전처리 테스트1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_transform_pre1(df, drop_column, groupby_column):\n",
    "    df = df.drop('cstno', axis=1)\n",
    "\n",
    "    for col_name in drop_column:\n",
    "        df = df.drop(col_name, axis=1)\n",
    "\n",
    "    if 'imcome_cat' not in drop_column:\n",
    "        df['imcome_cat']=df['imcome_cat'].replace({'Less than $40K':40000, '$40K - $60K':50000, '$60K - $80K':70000, '$80K - $120K':100000, '$120K +':120000, 'Unknown':63000})\n",
    "\n",
    "    df = df.groupby(groupby_column).apply(lambda x: x.fillna(x.mean(numeric_only=True)))\n",
    "    df = df.reset_index(drop=True)\n",
    "    df.dropna(axis=0, inplace=True)\n",
    "        \n",
    "    df = encode_onehot(df)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def proc_null_groupby_test():\n",
    "    from itertools import combinations\n",
    "\n",
    "    model_comparison = {}  #Dictionary to store the comparison metrics of models\n",
    "    model_eval_comparison = {}                        \n",
    "\n",
    "\n",
    "    # 전처리 테스트 함수\n",
    "    # -----------------\n",
    "    # def drop_null_column_pre(df, drop_list):\n",
    "    #     for col_name in drop_list:\n",
    "    #         df = df.drop(col_name, axis=1)\n",
    "\n",
    "    #     return df\n",
    "\n",
    "\n",
    "            \n",
    "    # 전처리 테스트 예측\n",
    "    # -----------------\n",
    "\n",
    "    # 데이터 로드 및 고객번호 삭제\n",
    "    fit_df = pd.read_csv(\"./data/bank_churner.csv\") # 학습을 위한 데이터 로드\n",
    "    eval_df = pd.read_csv(\"./data/test_churner.csv\")\n",
    "    tot_cnt = fit_df.shape\n",
    "\n",
    "    fit_df_org = fit_df.copy()\n",
    "    eval_df_org = eval_df.copy()\n",
    "    fit_df = fit_df.drop('cstno', axis=1)\n",
    "\n",
    "    fit_df_columns = fit_df.columns\n",
    "    best_auc = 0\n",
    "\n",
    "    # 결측치 및 다중공선성 처리\n",
    "    # -----------------------\n",
    "    result_list = []\n",
    "    drop_target_columns = ['sex','imcome_cat', 'tot_amt_ratio_q4_q1', 'mean_util_pct', 'tot_trans_cnt_for_12m','age','mean_open_to_buy','tot_trans_amt_for_12m']\n",
    "    for j in range(1, len(drop_target_columns)+1):\n",
    "        for i in combinations(drop_target_columns, j):\n",
    "            result_list.append(list(i))\n",
    "\n",
    "    # result_list = [['sex'], ['sex', 'age']]\n",
    "\n",
    "    for drop_no, drop_column in enumerate(result_list):\n",
    "        for group_no, groupby_column in enumerate(fit_df_columns):\n",
    "            start_time = time.time()\n",
    "            if groupby_column == 'is_churned' or groupby_column in drop_column:\n",
    "                continue\n",
    "\n",
    "            fit_df = fit_df_org\n",
    "            eval_df = eval_df_org\n",
    "            tot_cnt = fit_df.shape\n",
    "            \n",
    "            # print(f'drop_column: {drop_column}, groupby_column: {groupby_column}')\n",
    "            \n",
    "        # -----------------------------------------------------------------------------------    \n",
    "            # 평가 for Competition\n",
    "            # -----------------------------------------------------------------------------------\n",
    "\n",
    "            # 전처리 단계\n",
    "            # -----------\n",
    "            fit_df = test_transform_pre1(fit_df, drop_column, groupby_column)\n",
    "            eval_df = test_transform_pre1(eval_df, drop_column, groupby_column)\n",
    "            after_drop_cnt = len(fit_df)\n",
    "            \n",
    "            \n",
    "            # 평가를 위한 데이터 분리\n",
    "            # ---------------------\n",
    "            X_train=fit_df.drop(['is_churned'],axis=1)\n",
    "            y_train=fit_df['is_churned']\n",
    "            \n",
    "            X_eval=eval_df.drop(['is_churned'],axis=1)\n",
    "            y_eval=eval_df['is_churned']\n",
    "\n",
    "\n",
    "            # 중요 Feature Column 선택\n",
    "            # -----------------------\n",
    "            X_new, selected_columns = select_feature(X_train, y_train, 'ExtraTrees')\n",
    "            X_eval = X_eval[selected_columns]\n",
    "\n",
    "\n",
    "            # Train and Test 데이터 생성 및 가공\n",
    "            # ---------------------------------\n",
    "            X_train, y_train, X_test_temp, y_test_temp = proc_split_smote(X_new, y_train)\n",
    "            after_smote_cnt = X_train.shape\n",
    "\n",
    "\n",
    "            # Standardization 적용\n",
    "            # --------------------\n",
    "            X_train, X_eval = proc_standardization(X_train, X_eval.values)   \n",
    "\n",
    "\n",
    "            # 최종 평가\n",
    "            # --------\n",
    "            proc_type='E'\n",
    "            # eval_auc = fit_predict(proc_type, drop_no, model_eval_comparison, X_train_for_evaluation, y_train_for_evaluation, X_eval, y_eval)\n",
    "            eval_auc = fit_predict_eval(proc_type, drop_no, group_no, model_eval_comparison, X_train, y_train, X_eval, y_eval)\n",
    "            \n",
    "            if eval_auc > best_auc:\n",
    "                best_type = f'{proc_type}_{drop_no}_{group_no}'\n",
    "                best_auc = eval_auc\n",
    "                \n",
    "\n",
    "\n",
    "            # 최종 평가 로그 출력\n",
    "            # ------------------\n",
    "            cur_datetime = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "            end_time = time.time()\n",
    "            delta_time = end_time - start_time\n",
    "            # print(f'[평  가] {cur_datetime}, {str(datetime.timedelta(seconds=delta_time)).split(\".\")[0]}, AUC: {test_auc:0.6f}, 처리 건수: {len(eval_df)}, 최종 평가 건수: {len(X_eval)}')\n",
    "            print(f'[테스트] {cur_datetime}, {str(datetime.timedelta(seconds=delta_time)).split(\".\")[0]}, [G{proc_type}_{drop_no}_{group_no}], best-type: [{best_type}], Best-AUC: {best_auc:0.6f}, AUC: {eval_auc:0.6f}, tot_cnt: {tot_cnt}, after_drop_cnt: {after_drop_cnt}, after_smote_cnt: {after_smote_cnt}, groupby_column: {groupby_column}, drop_column: {drop_column}')\n",
    "\n",
    "            # print_eval_result(model_eval_comparison)\n",
    "\n",
    "\n",
    "# 테스트시 아래의 주석 풀고 실행\n",
    "# ----------------------------\n",
    "# proc_null_groupby_test()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 전처리 테스트2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proc_null_drop_test():\n",
    "    from itertools import combinations\n",
    "\n",
    "    model_comparison = {}  #Dictionary to store the comparison metrics of models\n",
    "    model_eval_comparison = {}                        \n",
    "\n",
    "    def test_transform_pre2(df, drop_list):\n",
    "        \n",
    "        # 데이터 변환\n",
    "        # ---------- \n",
    "        df = df.drop('cstno', axis=1)\n",
    "\n",
    "\n",
    "        # 결측치 처리\n",
    "        # -----------\n",
    "        for col_name in drop_list:\n",
    "            df = df.drop(col_name, axis=1)\n",
    "\n",
    "        if 'imcome_cat' not in drop_list:\n",
    "            df['imcome_cat']=df['imcome_cat'].replace({'Less than $40K':40000, '$40K - $60K':50000, '$60K - $80K':70000, '$80K - $120K':100000, '$120K +':120000, 'Unknown':63000})\n",
    "\n",
    "        df = df.fillna(df.mean(numeric_only=True))\n",
    "        df = df.reset_index(drop=True)\n",
    "        df.dropna(axis=0, inplace=True)\n",
    "            \n",
    "\n",
    "        # One-Hot Encoding\n",
    "        # ----------------\n",
    "        df = encode_onehot(df)  \n",
    "    \n",
    "        return df\n",
    "\n",
    "            \n",
    "    # -----------\n",
    "    # 예측\n",
    "    # -----------\n",
    "\n",
    "    # 데이터 로드 및 고객번호 삭제\n",
    "    fit_df = pd.read_csv(\"./data/bank_churner.csv\") # 학습을 위한 데이터 로드\n",
    "    eval_df = pd.read_csv(\"./data/test_churner.csv\")\n",
    "    tot_cnt = fit_df.shape\n",
    "\n",
    "    fit_df_org = fit_df.copy()\n",
    "    eval_df_org = eval_df.copy()\n",
    "\n",
    "    best_auc = 0\n",
    "\n",
    "    # Null 처리\n",
    "    result_list = []\n",
    "    drop_target_columns = ['sex','imcome_cat', 'tot_amt_ratio_q4_q1', 'mean_util_pct', 'tot_trans_cnt_for_12m','age','mean_open_to_buy','tot_trans_amt_for_12m']\n",
    "    for j in range(1, len(drop_target_columns)+1):\n",
    "        for i in combinations(drop_target_columns, j):\n",
    "            result_list.append(list(i))\n",
    "\n",
    "    # result_list = [['sex'], ['sex', 'age', 'imcome_cat']]\n",
    "\n",
    "    for drop_no, drop_column in enumerate(result_list):\n",
    "        start_time = time.time()\n",
    "\n",
    "        fit_df = fit_df_org\n",
    "        eval_df = eval_df_org\n",
    "        \n",
    "        # -----------------------------------------------------------------------------------    \n",
    "        # 평가 for Competition\n",
    "        # -----------------------------------------------------------------------------------\n",
    "\n",
    "        # 전처리 단계\n",
    "        # -----------\n",
    "        fit_df = test_transform_pre2(fit_df, drop_column)\n",
    "        eval_df = test_transform_pre2(eval_df, drop_column)\n",
    "        after_drop_cnt = len(fit_df)\n",
    "        \n",
    "        \n",
    "        # 평가를 위한 데이터 분리\n",
    "        # ---------------------\n",
    "        X_train=fit_df.drop(['is_churned'],axis=1)\n",
    "        y_train=fit_df['is_churned']\n",
    "        X_train_cnt = X_train.shape\n",
    "        \n",
    "        X_eval=eval_df.drop(['is_churned'],axis=1)\n",
    "        y_eval=eval_df['is_churned']\n",
    "\n",
    "\n",
    "        # 중요 Feature Column 선택\n",
    "        # -----------------------\n",
    "        X_new, selected_columns = select_feature(X_train, y_train, 'ExtraTrees')\n",
    "        X_eval = X_eval[selected_columns]\n",
    "\n",
    "\n",
    "        # Train and Test 데이터 생성 및 가공\n",
    "        # ---------------------------------\n",
    "        X_train, y_train, X_test_temp, y_test_temp = proc_split_smote(X_new, y_train)\n",
    "        after_smote_cnt = X_train.shape\n",
    "\n",
    "        # Evaluation 데이터 생성 및 가공\n",
    "        # ---------------------------------\n",
    "        X_train, X_eval = proc_standardization(X_train, X_eval.values)   \n",
    "\n",
    "\n",
    "        # 최종 평가\n",
    "        # --------\n",
    "        proc_type='E'\n",
    "        group_no=1\n",
    "        # eval_auc = fit_predict(proc_type, drop_no, model_eval_comparison, X_train_for_evaluation, y_train_for_evaluation, X_eval, y_eval)\n",
    "        eval_auc = fit_predict_eval(proc_type, drop_no, group_no, model_eval_comparison, X_train, y_train, X_eval, y_eval)\n",
    "        \n",
    "        if eval_auc > best_auc:\n",
    "            best_type = f'{proc_type}_{drop_no}_{group_no}'\n",
    "            best_auc = eval_auc\n",
    "            \n",
    "\n",
    "\n",
    "        # 최종 평가 로그 출력\n",
    "        # ------------------\n",
    "        cur_datetime = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "        end_time = time.time()\n",
    "        delta_time = end_time - start_time\n",
    "        # print(f'[평  가] {cur_datetime}, {str(datetime.timedelta(seconds=delta_time)).split(\".\")[0]}, AUC: {test_auc:0.6f}, 처리 건수: {len(eval_df)}, 최종 평가 건수: {len(X_eval)}')\n",
    "        print(f'[테스트] {cur_datetime}, {str(datetime.timedelta(seconds=delta_time)).split(\".\")[0]}, [{proc_type}_{drop_no}_{group_no}], best-type: [{best_type}], Best-AUC: {best_auc:0.6f}, AUC: {eval_auc:0.6f}, tot_cnt: {tot_cnt}, after_drop_cnt: {after_drop_cnt}, after_smote_cnt: {after_smote_cnt}, X_train_cnt: {X_train_cnt}, drop_column: {drop_column}')\n",
    "\n",
    "\n",
    "        # print_eval_result(model_eval_comparison)\n",
    "\n",
    "\n",
    "# 테스트시 아래의 주석 풀고 실행\n",
    "# ----------------------------\n",
    "# proc_null_drop_test()        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
