# 최초 root / adminuser

# 파일럿 환경의 로그 확인
  - Hadoop 에코시스템 서버들의 로그 위치 : /var/log/디렉터리(cloudera, Hadoop, Oozie 등)
  - Redis 서버 로그 위치 : /var/log/redis_6379.log
  - Storm 서버 로그 위치 : /home/pilot-pjt/storm/logs
  - Zeppelin 서버 로그 위치 : /home/pilot-pjt/zeppelin-0.8.2-bin-all/logs
  

# 의존성 : 시작 순서
  - zookeeper -> hadoop -> yarn
### 2-5 빅데이터 클러스터 구성 02
## 설치 위치
# HDFS(하둡)
- 설치 위치
  - NameNode : server01.hadoop.com
  - SecondaryNameNode : server01.hadoop.com
  - Balancer : server01.hadoop.com
  - HttpFS : None
  - NFS Gateway : None
  - DataNode : server02.hadoop.com

# Cloudera Management Service
- 설치 위치
  - Service Monitor : server01.hadoop.com
  - Activity Monitor : None
  - Host Monitor : server01.hadoop.com
  - Event Server : server01.hadoop.com
  - Alert Publisher : server01.hadoop.com 
  
# YARN
- 설치 위치
  - ResourceManger : server01.hadoop.com
  - JobHistory Server : server01.hadoop.com
  - NodeManager : server02.hadoop.com

# 주키퍼
- 설치 위치
  - Server : server02.hadoop.com

## 환경 설정
# Hadoop 
  - 복제 계수 : 3 -> 1
  - 접근권한 해제(HDFS 권한 검사) : 체크박스를 해제
  - HDFS 블록 크기 : 128MiB -> 64MiB

# YARN
  - yarn.scheduler.max : 1GiB -> 1.5GiB
  - yarn.nodemanger.resource.memory-mb : 1GiB -> 5GiB
  - Scheduler 클래스(yarn.resourcemanager.scheduler.class : FifoScheduler로 변경 


# 실무에서 Hadoop 디렉토리 하위 경로의 복제계수를 10으로 변경하면 조회시 속도 향상. 물론 자원의 소비는 감안
$ hadoop fs -setrep 10 -R /user/hadoop/

### 2-5. 빅데이터 클러스터 구성
## HDFS 명령어 사용(server02.hadoop.com)
$ hdfs dfs -put Sample.txt /tmp
$ hdfs dfs -ls /tmp
$ hdfs dfs -cat /tmp/Sample.txt
$ hdfs dfs -mv /tmp/Sample.txt /tmp/Sample2.txt
$ hdfs dfs -get /tmp/Sample2.txt   # HDFS에 저장된 파일을 로컬 파일시스템으로 가져오기
$ hdfs dfs -rm /tmp/Sample2.txt    # HDFS에 저장된 파일 삭제(휴지통)
$ hdfs dfs -rm -skipTrash /tmp/Sample2.txt    # HDFS에 저장된 파일 삭제

$ hdfs dfs -stat '%b %o %r %n' /tmp/Sample.txt  # hdfs 저장된 파일 상태 확인
                                                # 파일크기(%b), 파일 블록크기(%o), 복제수(%r), 소유자명(%u), 파일명(%n)
$ hdfs fsck /         # HDFS 파일 시스템 상태 검사, 전체크기, 디렉러리 수, 파일수, 노드수 등 파일시스템의 전체 상태를 보여줌
$ hdfs dfsadmin -report  # 하둡 파일싯템의 기본 정보 및 통계를 보여줌

# HDFS 파일의 비정상 상태
$ hdfs dfsadmin -safemode leave    # 안전모드 상태로 전환됐다면 강제로 안전모드를 해제
$ hdfs fsck / -delete              # 손상된 파일을 강제로 삭제
$hdfs fsck / -move                 # 손상된 파일을 /lost+found 디렉터리로 옮김


## 주키퍼(zookeeper) 명령어 사용
$ zookeeper-client     # 주키퍼 클라이언트 실행

# 주키퍼 Z노드 등록/조회/삭제
[zk: localhost:2181(CONNECTED) 0] create /pilot-pjt bigdata # Z노드 생성
[zk: localhost:2181(CONNECTED) 0] ls /                      # Z노드 조회  
[zk: localhost:2181(CONNECTED) 0] get /pilot-pjt
[zk: localhost:2181(CONNECTED) 0] delete /pilot-pjt         # Z노드 삭제

### 스마트카 로그 시뮬레이터 - 설치 및 실행
# 1. 작업폴더 생성
  - $ cd /home
  - $ mkdir /home/pilot-pjt
  - $ mkdir /home/pilot-pjt/car-batch-log
  - $ mkdir /home/pilot-pjt/driver-realtime-log
  - chmod 777 -R /home/pilot-pjt

# 2. java 컴파일과 실행환경을 1.7에서 1.8로 변경
  - $ rm /usr/bin/java
  - $ rm /usr/bin/javac
  - $ ln -s /usr/java/jdk1.8.0_181-cloudera/bin/javac /usr/bin/javac
  - $ ln -s /usr/java/jdk1.8.0_181-cloudera/bin/java  /usr/bin/java
  - $ java -version
  
# 3. 시뮬레이터 실행
  - 실시간 로그(Driver Log)
    - $ java -cp bigdata.smartcar.loggen-1.0.jar com.wikibook.bigdata.smartcar.loggen.DriverLogMain 20160101 3  
  - 배치 로그(Car Log)
    - $ java -cp bigdata.smartcar.loggen-1.0.jar com.wikibook.bigdata.smartcar.loggen.CarLogMain 20160101 3  
  
### 3.2 수집에 활용할 기술 : 플럼(flume)
# 플럼 설치
  - 설치 위치 : server02.hadoop.com

# 플럼 환경 설정
  - java heap : 50MiB -> 100MiB

# 플럼 동작 
# Source -> Channer -> Sink
# Source -> Interceptor -> Channel -> Sink(2개)

# 플럼 동작 
  - Flume [구성] - 구성파일 편집


### 3.3 수집에 활용할 기술 : 카프카(kafka)
# 설치 위치
  - kafka Broker : server02.hadoop.com
  - kafka MirrorMaker : None
  - Gateway : None

# 환경 설정
  - Data Retention Time : 7일 -> 10분
  
# 카프카 토픽 생성
  - $ kafka-topics --create --zookeeper server02.hadoop.com:2128 --replication-factor 1 --partitions 1 --topic SmartCar-Topic 

# 카프카 Producer 사용
  - kafka-console-producer --broker-list server02.hadoop.com:9092 -topic SmartCar-Topic
  
# 카프카 Consumer1 사용
  - kafka-console-consumer --bootstrap-server server02.hadoop.com:9092 --topic SmartCar-Topic --partition 0 --from-beginning

# 카프카 Consumer2 사용  
  - kafka-console-consumer --bootstrap-server server02.hadoop.com:9092 --topic SmartCar-Topic --partition 0 --from-beginning  
  
# Provider(N) -> 카프카 Broker(Topic1, Topic2) -> Consumer(N개)


3.7  수집 파일럿 실행 5단계
## SmartCar 로그 시뮬레이터 작동
$ cd /home/pilot-pjt/working

$ java -cp bigdata.smartcar.loggen-1.0.jar com.wikibook.bigdata.smartcar.loggen.CarLogMain 20160101 3 &

$ java -cp bigdata.smartcar.loggen-1.0.jar com.wikibook.bigdata.smartcar.loggen.DriverLogMain 20160101 3 &

$ mv /home/pilot-pjt/working/SmartCar/SmartCarStatusInfo_20160101.txt /home/pilot-pjt-working/car-batch-log/


### 5.4 실시간 적재 파일럿 실행 2단계 - 환경구성
## HBase
# HBase 설치
  - Master : server01.hadoop.com  
  - HBase REST Server : None
  - HBase Thrift Server : server01.hadoop.com  
  - RegionServer : server01.hadoop.com  


# HBase 구성
  - HBase Thrift Http 서버 설정  : "HBase(서비스 전체)" 항목의 체크박스에 Check
  

# HBase 사용
$ hbase shell
> create 'smartcar_test_table', 'cf'
> put 'smartcar_test_table', 'row-key1', 'cf:model', 'Z0001'
> put 'smartcar_test_table', 'row-key1', 'cf:no', 	'12345'
> get 'smartcar_test_table', 'row-key1'

> disable 'smart_test_table'
> drop 'smart_test_table'
> exit

# HBase 웹 관리자 화면
- http://server02.hadoop.com:16010

# HBase는 자원 소모가 높은 서버이므로 사용하지 않을때에는 일시정지.

# 간단한 HBase 명령어
$ hbase shell
  > create 'smartcar_test_table', 'cf'    # 테이블 및 컬럼패밀리 생성
  > put 'smartcar_test_table', 'row-ke1','cf:model','z0001'  # 데이터 insert
  > get 'smartcar_test_table', 'row-ke1'  # 데이터 조회
  > disable 'smartcar_test_table'            # 테이블 삭제전 disable
  > drop 'smartcar_test_table'               # 테이블 drop
  
  > list_snapshots
  > delete_snapshots 'snapshot 이름'
  > list                              # 테이블 리스트 
  > disable 'table_name'
  > drop 'table_name'
  > count 'table_name'
  > get 'table_name', 'key'
  > deleteall 'table_name','key'
  > scan 'table_name', {STARTROW=>'1234', ENDROW=>'1235'}
  > scan 'table_name', {STARTROW=>'1234', LIMIT=>10}
  > scan 'table 이름', {COLUMNS=>'패밀리이름:컬럼이름', LIMIT=>10, FILTER=>"ValueFilter(=, 'binary:조건값')"
  > scan 'table 이름', {LIMIT=>10, COLUMNS=>['패밀리네임'], FILTER => "(SingleColumnValueFilter('패밀리네임', '필드명',=,'binary:조건값1',true, true)) AND (SingleColumnValueFilter('패밀리네임', '필드명',=,'binary:조건값2',true,true))"}
  > scan 'table 이름', {LIMIT=>10, COLUMNS=>['패밀리네임:필드명'], TIMERANGE=> [start_timestamp, end_timestamp]} 


## Redis 설치
$ yum install -y gcc*
$ yum install -y tcl

$ cd /home/pilot-pjt
$ wget http://download.redis.io/releases/redis-5.0.7.tar.gz
$ tar -xvf redis-5.0.7.tar.gz

$ cd /home/pilot-pjt/redis-5.0.7
$ make
$ make install
$ cd /home/pilot-pjt/redis-5.0.7/utils
$ chmod 755 install_server.shell
$ ./install_server.sh

# Redis 설치 확인
$ vi /var/log/redis_6379.log

$ service redis_6379 status [start/stop]

# Redis 서버에 원격접근 가능토록 설정
$ vi /etc/redis/6379.conf

  -> bind 127.0.0.1 부분을 주석처리
  -> protected-mod yes -> no
$ service redis_6379 restart

# Redis CLI 로 데이터 저장/조회
$ redis-cli
> set key:1 Hello!BigData
> get key:1
> del key:1
> quit

## Storm 설치 (Server02)
$ cd /home/pilot-pjt
$ wget https://archive.apache.org/dist/storm/apache-storm-1.2.3/apache-storm-1.2.3.tar.gz
$ tar -xvf apache-storm-1.2.3-tar.gz
$ ln -s apache-storm-1.2.3 storm

# Storm 환경설정
$ cd /home/pilot-pjt/storm/conf

$ vi storm.yaml
  > storm.zookeeper.servers:                       # zookeeper 정보
  >  - "server02.hadoop.com"

  > storm.local.dir: "/home/pilot-pjt/storm/data"  # 스톰 작동을 위한 데이터 저장소

  > nimbus.seeds: ["server02.hadoop.com"]          # Nimbus 정보

  > supervisor.slots.ports:                        # Worker의 포트로써 포트의 갯수만큼 Worker가 만들어짐
     - 6700

  > ui.port: 8088                                  # Storm UI 접속 포트

# Storm 로그 레벨 조정 (info(INFO) -> error
$ cd /home/pilot-pjt/storm/log4j2
$ vi cluster.xml    # info 를 ERROR 로 변경
$ vi worker.xml     # INFO 를 ERROR 로 변경

# Storm을 편리하게 사용하기 위한 설정
$ vi /root/.bash_profile
  > PATH=$PATH:/home/pilot-pjt/storm/bin

$ source /root/.bash_profile

## Storm 설치
# Java 환경 설정(jdk1.8)
$ java -version
$ rm /usr/bin/java
$ rm /usr/bin/javac
$ ln -s /usr/java/jdk1.8.0_181-cloudera/bin/javac /usr/bin/javac
$ ln -s /usr/java/jdk1.8.0_181-cloudera/bin/java /usr/bin/java

# 자동 기동 스크립트 설정 (storm-nimbus, storm-supervisor, storm-ui)
https://gist.github.com/yulrizka 에서 스크립트 다운로드후 /etc/rc.d/init.d 에 저장

$ chmod 755 /etc/rc.d/init.d/storm-nimbus
$ chmod 755 /etc/rc.d/init.d/storm-supervisor
$ chmod 755 /etc/rc.d/init.d/storm-ui

# 서비스 등록 스크립트에 대한 Log 및 Pid 디렉터리를 만듬
$ mkdir /var/log/storm
$ mkdir /var/run/storm

$ service storm-nimbus [storm-supervisor/storm-ui] start/stop/status

# Storm UI 접속 및 상태 모니터링
- http://server02.hadoop.com:8088

# 스톰도 주키퍼 의존도가 높다. 주키퍼의 z노드인 /storm의 위치에 스톰의 주요 설정값이 관리되고 있음.

# Storm 기동 순서 : storm-nimbus -> storm-supervisor -> storm-ui (중지는 반대로)



# HBase Region 스플릿
- 저사양 파일럿 환경 : 리전 스플릿 수를 2로 설정(yarn 기반)
$ hbase org.apache.hadoop.hbase.util.RegionSplitter DriverCarInfo HexStringSplit -c 2 -f cf1



5.5 실시간 적재 파일럿 실행 3단계 - 적재 기능
# Storm Topology 배포
1. bigdata.smartcar.storm-1.0.jar 를 /home/pilot-pjt/working 에 업로드
2. storm 명령을 통해 DriverCarInfo라는 이름으로 배포. 배포하기 전 Storm 실행 확인
$ cd /home/pilot-pjt/working
$ storm jar bigdata.smartcar.storm-1.0.jar com.wikibook.bigdata.smartcar.storm.SmartCarDriverTopology DriverCarInfo


# Storm Topology 제거 
$ storm kill "배포시 사용했던 Topology 이름" -> $ storm kill "DriverCarInfo"

# storm topology 확인
- http://server02.hadoop.com:8088 로 확인
 

# 적재 테스트
1. 로그 시뮬레이터 작동

2. HBase 적재 확인
$ hbase shell
  > count 'DriverCarInfo'   # DriverCarInfo 테이블에 적재된 데이터 로우 수를 1000 단위로 출력
  > scan 'DriverCarInfo', {LIMIT=>20}  # 20개 데이터만 조회
  > scan 'DriverCarInfo', {STARTROW=>'00001030106102-Z0020', LIMIT=>1}
  > scan 'DriverCarInfo', {COLUMNS=>['cf1:car_number','cf1:area_numbr'], FILTER=>"RowFilter(=,'regexstring:30106102') AND SingleColumnValueFilter('cf1', 'area_numbr' ,=, 'regexstring:D04')"}  

3. Hbase 웹관리자에 접속해서 적재한 데이터가 분산 적재되는지 확인
- http://server02.hadoop.com:16010/


# Redis에 적재된 데이터 확인
$ redis-cli
$ 127.0.0.1:6379> smembers 20160103

5.6 실시가 적재 파일럿 실행 4단계 - 적재 테스트
# Redis 클라이언트 애플리케이션 작동
- bigdata.smartcar.redis-1.0.jar를 /home/pilot-pjt-working 으로 업로드

- 레디스 클라이언트 애플리케이션 실행 - redis에 있는 데이터를 가져와서 과속한 차량에 경고, 메시지를 보낼 수 있음
$ cd /home/pilot-pjt/working
$ java -cp bigdata.smartcar.redis-1.0.jar com.wikibook.bigdata.smartcar.redis.OverSpeedCarInfo 20160103

# 실시간 로그 시뮬레이터 중지
$ ps -ef | grep smartcar.log/redis_6379
$ kill -9 [pid]

# 적재 테스트가 종료되면 원할한 자원 관리를 위해 수집/적재 서비스를 정지 시킴.
# 아래 순서로 정지
- 플럼 서비스 : CM홈 -> [Flume] -> [정지]
- 카프카 서비스: CM홈 -> [Kafka] -> [정지]
- 스톰 서비스: server02 접속
$ service storm-ui stop
$ service storm-supervisor stop
$ service storm-nimbus stop
- 레디스 서비스: server02에 ssh 접속 
$ service redis_6379 stop
- HBase 서비스: CM홈 -> [HBase] -> [정지]



## pig
- 실무로 배우는 빅데이터 기술(확장편): https://bit.ly/bigdata2nd




HIVE 암호 : hive/lqvbwxaLFz