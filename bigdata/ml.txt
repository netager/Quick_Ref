## 사이킷런의 기반 프레임 워크 익히기 - 주요 API/모듈 및 내장 예제 데이터 세트 소개
# 붓꽃 데이터 분류 예측 프로세스
  - 학습데이터 -> 모델학습 -> 테스트데이터 -> 학습된 모델로 테스트 데이터 예측 -> 평가 

# 사이킷런 기반 프레임워크 - Estimator 와 fit(), predict()
  - Esstimator - 학습(fit()), 예측(predict())
    - 분류(Classifier) - 분류구현 클래스
      - DecisionTreeClassifier
      - RandomForestClassifier
      - GradientBoostingClassifier
      - GaussianNB
      - SVC
    - 회귀(Regressor) - 회귀구현 클래스 
      - LinearRegression
	  - Ridge
	  - Lasso
	  - RandomForestRegressor
	  - GradientBoostingRegressor 
	
# 사이킷런의 주요 모듈
  - 예제 데이터 
    - sklearn.datasets - 사이킷런에 내장되어 예제로 제공하는 데이터 세트 
  - 데이터 분리, 검증 & 파라미터 튜닝 
    - sklearn.model_selection - 교차검증을 위한 학습용/테스트용 분리, 그리드 서치(Grid Search)로 최적 파라미터 추출 등이 API 제공 
  - 피처 처리 
    - sklearn.preprocessing - 데이터 전처리에 필요한 다양한 가공 기능 제공(문자열을 숫자형 코드 값으로 인코딩, 정규화, 스케일링 등)
    - sklearn.feature_selection - 알고리즘에 큰 영향을 미치는 피처를 우선순위 대로 셀렉션 작업을 수행하는 다양한 기능 제공 
    - sklearn.feature_extraction - 텍스트 데이터나 이미지 데이터의 벡터화된 피처를 추출하는데 사용됨. 예를 들어 텍스트 데이터에서 
	                               Count Vectorizer 나 Tf-Idf Vectorizer 등을 생성하는 기능 제공 
                                 - 텍스트 데이터의 피처 추출은 sklearn.feature_extraction.text 모듈에, 이미지 데이터의 피처 추출은 
                                   sklearn.feature_extraction.image 모듈에 지원 API가 있음.
  - 피처 처리 & 차원 축소 
    - sklearn.decomposition - 차원 축소와 관련한 알고리즘을 지원하는 모듈임. PCA, NMF, Truncated SVD 등을 통해 차원 축소 기능을 수행할 수 있음.

  - 평가 
    - sklearn.metrics - 분류, 회귀, 클러스터링, 페어와이즈(Pairwise)에 대한 다양한 성능 측정 방법 제공 
                      - Accuracy, Precision, Recall, ROC-AUC, RMSE 등 제공 
  - ML 알고리즘 - 다양한 알고리즘을 가지고 있음. 아래 예시보다 더 많음.
    - sklearn.ensemble - 앙상블 알고리즘 제공
                       - 랜덤 포레스트, 에이다 부스트, 그래디언트 부스팅 등을 제공 
    - sklearn.linear_model - 주로 선형회귀, 릿지(Ridge), 라쏘(Lasso) 및 로지스틱 회귀 등 회귀 관려 알고리즘을 지원. 또한 SGD(Stochastic Gradient Descent) 관련
                             알고리즘도 제공 
    - sklearn.naive_bayes - 나이브 베이즈 알고리즘 제공. 가우시안 NB, 다항분포 NB 등.
    - sklearn.neighboors - 최근접 아웃 아로고리즘 제공. K-NN 등 
    - sklearn.svm - 서포트 벡터 머신 알고리즘 제공 
    - sklearn.tree - 의사 결정 트리 알고리즘 제공 
    - sklearn.cluster - 비지도 클러스터링 알고리즘 제공(K-평균, 계층형, DBSCAN 등)
  - 유틸리티 
    - sklearn.pipeline - 피처 처리 등의 변환과 ML 알고리즘 학습, 예측 등을 함께 묶어서 실행할 수 있는 유틸리티 제공   

# 사이킷런 내장 예제 데이터 셋 - 분류 및 회귀용 
  - datasets.load_boston() - 회귀 용도이며, 미국 보스턴의 집 피처들과 가격에 대한 데이터세트 
  - datasets.load_breast_cancer() - 분류 용도이며, 위스콘신 유방암 피처들과 악성/음성 레이블 데이터 세트 
  - datasets.load_diabetes() - 회귀 용도이며, 당뇨 데이터 세트 
  - datasets.load_digits() - 분류 용도이며, 0에서 9까지 숫자의 이미지 픽셀 데이터 세트 
  - datasets.load_iris() - 분류 용도이며, 붓꽃에 대한 피처를 가진 데이터 세트 

# 내장 예제 데이터 셋 구성 
  - iris_data 의 데이터 셋 확인

## 학습과 테스트 데이터 세트의 분리
# Model Selection(sklearn.model_selection) 소개 - 학습 데이터와 테스트 데이터 
  - 학습 데이터 세트 
    - 머신러닝 알고리즘 학습을 위해 사용
	- 데이터의 속성들과 결정값(레이블)값 모두를 가지고 있음 
	- 학습 데이터를 기반으로 머신러닝 알고리즘이 데이터 속성과 결정값의 패턴을 인지하고 학습 
  - 테스트 데이터 세트  
    - 테스트 데이터 세트에서 학습된 머신러닝 알고리즘을 테스트 
	- 테스트 데이터는 속성 데이터만 머신러닝 알고리즘에 제공하며, 머신러닝 알고리즘은 제공된 데이터를 기반으로 결정값을 예측 
	- 테스트 데이터는 학습 데이터와 별도로 데이터 세트로 제공되어야 함.

# 학습 데이터와 테스트 데이터 분리 - train_test_split()
  - sklearn.model_selection의 train_test_split() 함수
    : X_train, X_test, y_train, y_test = train_test_split(iris_data.data, iris_data.target, test_size=0.3, random_state=121)
    - test_size : 전체 데이터에서 테스트 데이터 세트 크기를 얼마로 샘플링할 것인가를 결정. 디폴트는 0.25, 즉 25%임.
    - train_size : 전체 데이터에서 학습용 데이터 세트 크기를 얼마로 샘플링할 것인가를 결정. test_size parameter를 사용하므로 잘 사용하지 않음.
	- shuffle : 데이터를 분리하기 전에 데이터를 미리 섞을지를 결정. 디폴트는 True. 데이터를 분산시켜서 좀 더 효율적인 학습 및 테스트 데이터 세트를
	            만드는데 사용.
	- random_state : random_state는 호출할 때마다 동일한 학습/테스트용 데이터 세트를 생성하기 위해 주어지는 난수 값입니다. 
	                 train_test_split()는 호출 시 무작위로 데이터를 분리하므로 random_state를 지정하지 않으면 수행할 때마다 다른 학습/테스트용 
					 데이터를 생성함.


## 교차검증 - K-Fold와 Stratified K-Fold 
# 교차 검증
  - 학습 데이터를 다시 분할하여 학습 데이터와 학습된 모델의 성능을 일차 평가하는 검증 데이터로 나눔
    - 학습데이터 세트 -> 분할 -> 학습데이터 세트 + 검증 데이터 세트
  - 모든 학습/검증 과정이 완료된 후 최종적으로 성능을 평가하기 위한 데이터 세트 - 테스트 데이터 세트 
  - 교차 검증은 필수 요소임. 데이터를 섞어서 다시 검증데이터를 생성하여 여러번 수행.  

# K 폴드 교차 검증 
  - K=5일때 총 5개의 폴드 세트에 5번의 학습과 검증 평가 반복 수행 
    - 학습 데이터를 5개로 나누어 1개를 검증 데이터로 사용. 돌아가면서 5번의 학습 및 검증을 수행

# K 폴드 교차 검증
  - 일반 K 폴드
  - Stratified K 폴드
    - 불균형한(imbalanced) 분포도를 가진 레이블(결정 클래스) 데이터 집합을 위한 K 폴드 방식 
    - 학습데이터와 검증 데이터 세트가 가지는 레이블 분포도가 유사하도록 검증 데이터 추출 	

## 교차검증 성능평가 cross_val_score()와 하이퍼 파라미터 튜닝을 위한 GridSearchCV
# 교차 검증을 보다 간편하게 - cross_val_score()
  - KFold 클래스를 이용한 교차 검증 방법
    1. 폴드 세트 설정
    2. for 루프에서 반복적으로 학습/검증 데이터 추출 및 학습과 예측 수행 
    3. 폴드 세트별로 예측 성능을 평균하여 최종 성능 평가 
  - cross_val_score() 함수로 폴드 세트 추출, 학습/예측, 평가를 한번에 수행 
    - cross_val_score(estimator, X, y=None, scoring=None, cv=None, n_jobs=1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs')

# GridSearchCV - 교차 검증과 최적 하이퍼 파라미터 튜닝을 한번에 
  - 사이킷런은 GridSearchCV를 이용해 Classifier나 Regressor와 같은 알고리즘에 사용되는 하이퍼 파라미터를 
    순차적으로 입력하면서 편리하게 최적의 파라미터를 도출할 수 있는 방안을 제공   
	- grid_parameters = {'max_depth':[1,2,3], 'min_samples_split': [2,3]}
	- cv 세트가 3이라면 6(파라미터 순차 적용 횟수) X 3(CV 세트수) -> 학습/검증 총 수행횟수(18)

	